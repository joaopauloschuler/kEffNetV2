{"cells":[{"cell_type":"markdown","metadata":{"id":"2JXWocLnz38N"},"source":["You might need to install this on your system:\n","\n","apt-get install python3-opencv git"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6503,"status":"ok","timestamp":1647372217242,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"},"user_tz":180},"id":"PQKpflNl7m63","outputId":"3c43532a-e115-4291-9762-f41fa6222c73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'k'...\n","remote: Enumerating objects: 1598, done.\u001b[K\n","remote: Counting objects: 100% (1047/1047), done.\u001b[K\n","remote: Compressing objects: 100% (687/687), done.\u001b[K\n","remote: Total 1598 (delta 758), reused 616 (delta 355), pack-reused 551\u001b[K\n","Receiving objects: 100% (1598/1598), 15.08 MiB | 13.47 MiB/s, done.\n","Resolving deltas: 100% (1114/1114), done.\n","Processing /content/k\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from cai==0.1.6) (1.3.5)\n","Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from cai==0.1.6) (0.18.3)\n","Requirement already satisfied: opencv-python>=4.1.2.30 in /usr/local/lib/python3.7/dist-packages (from cai==0.1.6) (4.1.2.30)\n","Requirement already satisfied: scikit-learn>=0.21.0numpy in /usr/local/lib/python3.7/dist-packages (from cai==0.1.6) (1.0.2)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.2.30->cai==0.1.6) (1.21.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->cai==0.1.6) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->cai==0.1.6) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.22.0->cai==0.1.6) (1.15.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->cai==0.1.6) (7.1.2)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->cai==0.1.6) (3.2.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->cai==0.1.6) (1.2.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->cai==0.1.6) (2021.11.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->cai==0.1.6) (2.4.1)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->cai==0.1.6) (1.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->cai==0.1.6) (2.6.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->cai==0.1.6) (3.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->cai==0.1.6) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->cai==0.1.6) (1.3.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0numpy->cai==0.1.6) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0numpy->cai==0.1.6) (3.1.0)\n","Building wheels for collected packages: cai\n","  Building wheel for cai (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cai: filename=cai-0.1.6-py3-none-any.whl size=60100 sha256=ebce4ed3688d6669dc297bacc3f33f69730bfc5dc43fa74ebb9f5889b632c9a6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7f54ybhn/wheels/c1/8a/57/56dbba25eff58e52e5365435c4fa102ad8d6f9787d3b4db13a\n","Successfully built cai\n","Installing collected packages: cai\n","Successfully installed cai-0.1.6\n"]}],"source":["import os\n","if not os.path.isdir('k'):\n"," !git clone -b development15 https://github.com/joaopauloschuler/k-neural-api.git k\n","else:\n"," !cd k && git pull\n","!cd k && pip install ."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4315,"status":"ok","timestamp":1647372221548,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"},"user_tz":180},"id":"2FWmCCX96ndE","outputId":"f69c0974-daaa-426d-d166-f4786ee4b076"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow version: 2.8.0\n","Keras version: 2.8.0\n","CPU cores: 8\n","RAM: 54.767017984 GB\n","[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["import cai.layers\n","import cai.datasets\n","import cai.models\n","import cai.densenet\n","import cai.efficientnet\n","import numpy as np\n","from tensorflow import keras\n","import gc\n","import multiprocessing\n","import random\n","import tensorflow as tf\n","print(\"Tensorflow version:\", tf.version.VERSION)\n","print(\"Keras version:\", keras.__version__)\n","print(\"CPU cores:\", multiprocessing.cpu_count())\n","import psutil\n","print('RAM:', (psutil.virtual_memory().total / 1e9),'GB')\n","print(tf.config.list_physical_devices('GPU'))\n","import matplotlib.pylab as plt"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"quolyeIQGVOe","executionInfo":{"status":"ok","timestamp":1647372221549,"user_tz":180,"elapsed":15,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"e02ac43a-a3bb-4e8b-d318-7206882d7d36"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Mar 15 19:23:39 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    24W / 300W |      2MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZH7GTLCqGbIf","executionInfo":{"status":"ok","timestamp":1647372261344,"user_tz":180,"elapsed":39804,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"8ed00f8c-3e88-4518-bfa7-23f9cda735a6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"v5C5xGzHD9lu","executionInfo":{"status":"ok","timestamp":1647372261346,"user_tz":180,"elapsed":27,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}}},"outputs":[],"source":["from tensorflow.python.profiler.model_analyzer import profile\n","from tensorflow.python.profiler.option_builder import ProfileOptionBuilder\n","\n","def get_flops(model):\n","  forward_pass = tf.function(\n","      model.call,\n","      input_signature=[tf.TensorSpec(shape=(1,) + model.input_shape[1:])])\n","\n","  graph_info = profile(forward_pass.get_concrete_function().graph,\n","                          options=ProfileOptionBuilder.float_operation())\n","\n","  # The //2 is necessary since `profile` counts multiply and accumulate\n","  # as two flops, here we report the total number of multiply accumulate ops\n","  flops = graph_info.total_float_ops // 2\n","  return flops"]},{"cell_type":"markdown","metadata":{"id":"fl4NUmiLLs2J"},"source":["# Download Files and Create Validation and Test Datasets"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"E7hD0zwbcKIq","executionInfo":{"status":"ok","timestamp":1647372268250,"user_tz":180,"elapsed":6927,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3cd54a03-fe44-40cb-fc52-f14dc032a06a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading:  https://zenodo.org/record/53169/files/Kather_texture_2016_image_tiles_5000.zip?download=1  to  colorectal_5000.zip\n","Decompressing into:  colorectal_5000\n","Creating folder colorectal_5000/val\n","Creating folder colorectal_5000/val/06_MUCOSA\n","Creating folder colorectal_5000/val/01_TUMOR\n","Creating folder colorectal_5000/val/03_COMPLEX\n","Creating folder colorectal_5000/val/07_ADIPOSE\n","Creating folder colorectal_5000/val/02_STROMA\n","Creating folder colorectal_5000/val/04_LYMPHO\n","Creating folder colorectal_5000/val/05_DEBRIS\n","Creating folder colorectal_5000/val/08_EMPTY\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/06_MUCOSA to colorectal_5000/val/06_MUCOSA.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/01_TUMOR to colorectal_5000/val/01_TUMOR.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/03_COMPLEX to colorectal_5000/val/03_COMPLEX.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/07_ADIPOSE to colorectal_5000/val/07_ADIPOSE.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/02_STROMA to colorectal_5000/val/02_STROMA.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/04_LYMPHO to colorectal_5000/val/04_LYMPHO.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/05_DEBRIS to colorectal_5000/val/05_DEBRIS.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/08_EMPTY to colorectal_5000/val/08_EMPTY.\n","Creating folder colorectal_5000/test\n","Creating folder colorectal_5000/test/06_MUCOSA\n","Creating folder colorectal_5000/test/01_TUMOR\n","Creating folder colorectal_5000/test/03_COMPLEX\n","Creating folder colorectal_5000/test/07_ADIPOSE\n","Creating folder colorectal_5000/test/02_STROMA\n","Creating folder colorectal_5000/test/04_LYMPHO\n","Creating folder colorectal_5000/test/05_DEBRIS\n","Creating folder colorectal_5000/test/08_EMPTY\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/06_MUCOSA to colorectal_5000/test/06_MUCOSA.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/01_TUMOR to colorectal_5000/test/01_TUMOR.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/03_COMPLEX to colorectal_5000/test/03_COMPLEX.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/07_ADIPOSE to colorectal_5000/test/07_ADIPOSE.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/02_STROMA to colorectal_5000/test/02_STROMA.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/04_LYMPHO to colorectal_5000/test/04_LYMPHO.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/05_DEBRIS to colorectal_5000/test/05_DEBRIS.\n","63 files have been moved from colorectal_5000/Kather_texture_2016_image_tiles_5000/08_EMPTY to colorectal_5000/test/08_EMPTY.\n"]}],"source":["verbose=True\n","root_folder = 'colorectal_5000'\n","train_dir = root_folder + '/Kather_texture_2016_image_tiles_5000'\n","val_dir = root_folder + '/val'\n","test_dir = root_folder + '/test'\n","\n","url_zip_file = 'https://zenodo.org/record/53169/files/Kather_texture_2016_image_tiles_5000.zip?download=1'\n","local_zip_file = 'colorectal_5000.zip'\n","expected_folder_name = root_folder\n","\n","if not os.path.isdir(root_folder):\n","  cai.datasets.download_zip_and_extract(url_zip_file, local_zip_file, expected_folder_name, verbose)\n","  cai.datasets.extract_subset_every(train_dir, val_dir, move_every=10, shift=0, verbose=verbose)\n","  cai.datasets.extract_subset_every(train_dir, test_dir, move_every=9, shift=0, verbose=verbose)"]},{"cell_type":"code","source":["!ls -l colorectal_5000/Kather_texture_2016_image_tiles_5000/01_TUMOR/ | wc -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLtfSYvRZv6W","executionInfo":{"status":"ok","timestamp":1647372268251,"user_tz":180,"elapsed":28,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"7cbd4609-d8d8-47b5-b513-fda814a72c37"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["500\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"-6WYfTY_h8zn","executionInfo":{"status":"ok","timestamp":1647372268251,"user_tz":180,"elapsed":14,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}}},"outputs":[],"source":["num_classes = 8\n","batch_size = 64\n","epochs = 1000\n","target_size_x = 224\n","target_size_y = 224\n","seed = 12\n","lab=False\n","bipolar=False\n","smart_resize=True"]},{"cell_type":"code","source":["# load train dataset\n","x_train, aux_x_val, aux_x_test, y_train, aux_y_val, aux_y_test, class_weight, classes = \\\n","  cai.datasets.load_images_from_folders(seed=seed, root_dir=train_dir, lab=lab, \n","  verbose=verbose, bipolar=bipolar, base_model_name='train',\n","  training_size=1.0, validation_size=0.0, test_size=0.0,\n","  target_size=(target_size_x, target_size_y), \n","  has_training=True, has_validation=False, has_testing=False, \n","  smart_resize=smart_resize)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RfkMQrXEDfxD","executionInfo":{"status":"ok","timestamp":1647372290043,"user_tz":180,"elapsed":21804,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"dfe1e7f4-5d85-4d6d-e971-1366a866c75c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading  8  classes.\n","smart resize is enabled.\n","loading train images\n","train shape is: (3992, 224, 224, 3)\n","Channel  0  min: 0.0  max: 1.0\n","Channel  1  min: 0.0  max: 1.0\n","Channel  2  min: 0.0  max: 1.0\n","Loaded.\n"]}]},{"cell_type":"code","source":["# load validation dataset\n","aux_x_train, x_val, aux_x_test, aux_y_train, y_val, aux_y_test, class_weight, classes = \\\n","  cai.datasets.load_images_from_folders(seed=seed, root_dir=val_dir, lab=lab, \n","  verbose=verbose, bipolar=bipolar, base_model_name='val',\n","  training_size=0.0, validation_size=1.0, test_size=0.0,\n","  target_size=(target_size_x, target_size_y), \n","  has_training=False, has_validation=True, has_testing=False, \n","  smart_resize=smart_resize)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1psVhRRMESZg","executionInfo":{"status":"ok","timestamp":1647372290741,"user_tz":180,"elapsed":708,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"8de1f19d-743b-47c0-8fcb-bf8aac6bfa42"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading  8  classes.\n","smart resize is enabled.\n","loading validation images\n","validation shape is: (504, 224, 224, 3)\n","Loaded.\n"]}]},{"cell_type":"code","source":["# Duplicate Validation by Flipping Horizontally\n","x_val = np.concatenate( (x_val, np.flip(x_val, 2)), axis=0)\n","y_val = np.concatenate( (y_val, y_val), axis=0)\n","\n","# Duplicate Validation Again by Flipping Vertically\n","x_val = np.concatenate( (x_val, np.flip(x_val, 1)), axis=0)\n","y_val = np.concatenate( (y_val, y_val), axis=0)\n","\n","print(\"x_val_shape:\", x_val.shape)\n","print(\"y_val_shape:\", y_val.shape)"],"metadata":{"id":"t6QhGcJB4ceh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647372291333,"user_tz":180,"elapsed":596,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"3009a169-c7ae-45bd-b86a-6e29ef6b344d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["x_val_shape: (2016, 224, 224, 3)\n","y_val_shape: (2016, 8)\n"]}]},{"cell_type":"code","source":["# load test dataset\n","aux_x_train, aux_x_val, x_test, aux_y_train, aux_y_val, y_test, class_weight, classes = \\\n","  cai.datasets.load_images_from_folders(seed=seed, root_dir=test_dir, lab=lab, \n","  verbose=verbose, bipolar=bipolar, base_model_name='test',\n","  training_size=0.0, validation_size=0.0, test_size=1.0,\n","  target_size=(target_size_x, target_size_y), \n","  has_training=False, has_validation=False, has_testing=True, \n","  smart_resize=smart_resize)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p9ftIAzOIXwn","executionInfo":{"status":"ok","timestamp":1647372292121,"user_tz":180,"elapsed":796,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"0804cda6-72e6-4537-edbc-cd9f4b8d7fdd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading  8  classes.\n","smart resize is enabled.\n","loading test images\n","test shape is: (504, 224, 224, 3)\n","Loaded.\n"]}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"qN8LdqheVEkj","executionInfo":{"status":"ok","timestamp":1647372292123,"user_tz":180,"elapsed":24,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}}},"outputs":[],"source":["train_datagen = cai.util.create_image_generator(vertical_flip=True,\n","  rotation_range=179, width_shift_range=0.3, height_shift_range=0.3,\n","  channel_shift_range=0.0)\n","valid_datagen = cai.util.create_image_generator_no_augmentation()\n","test_datagen = cai.util.create_image_generator_no_augmentation()\n","cpus_num = max([multiprocessing.cpu_count(), 8])\n","\n","def cyclical_adv_lrscheduler25(epoch):\n","    \"\"\"CAI Cyclical and Advanced Learning Rate Scheduler.\n","    # Arguments\n","        epoch: integer with current epoch count.\n","    # Returns\n","        float with desired learning rate.\n","    \"\"\"\n","    base_learning = 0.001\n","    local_epoch = epoch % 25\n","    result = base_learning\n","    if local_epoch < 7:\n","       result = base_learning * (1 + 0.5*local_epoch)\n","    else:\n","       result = (base_learning * 4) * ( 0.85**(local_epoch-7) )\n","\n","    if result < 2.5245e-04:\n","      result = 2.5245e-04\n","    return result"]},{"cell_type":"code","source":["learning_rate_test = []\n","for epoch in range(epochs):\n","  learning_rate_test.append( cyclical_adv_lrscheduler25(epoch) )\n","plt.figure()\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Epochs\")\n","plt.ylim([0.0000,0.005])\n","plt.plot(learning_rate_test)"],"metadata":{"id":"-98DQjaJmPC3","colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"status":"ok","timestamp":1647372292125,"user_tz":180,"elapsed":25,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"818250f8-abaf-47d2-a03c-04e07e669876"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f143c2263d0>]"]},"metadata":{},"execution_count":14},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"8A7b9F3TVQUG","executionInfo":{"status":"ok","timestamp":1647372292127,"user_tz":180,"elapsed":18,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}}},"outputs":[],"source":["def work_on_keffnet(show_model=False, run_fit=False, test_results=False, calc_f1=False):\n","  monitor='val_loss'\n","  if (show_model):\n","    input_shape = (target_size_x, target_size_y, 3)\n","  else:\n","    input_shape = (None, None, 3)\n","  for kType in [cai.layers.D6v3_4ch()]:\n","      basefilename = '/content/drive/MyDrive/output/JP30N14-'+str(kType)\n","      best_result_file_name = basefilename+'-best_result.hdf5'\n","      print('Running: '+basefilename)\n","      if kType == -1:\n","        model = cai.efficientnet.EfficientNetB0(\n","          include_top=True,\n","          input_shape=input_shape,\n","          classes=num_classes)\n","      else:\n","        model = cai.efficientnet.kEfficientNetB0(\n","          include_top=True,\n","          input_shape=input_shape,\n","          classes=num_classes,\n","          # skip_stride_cnt=0,\n","          kType=kType)\n","        \n","      optimizer = keras.optimizers.RMSprop()\n","      model.compile(\n","        loss='categorical_crossentropy',\n","        optimizer=optimizer,\n","        metrics=['accuracy'])\n","\n","      if (show_model):\n","        model.summary(line_length=180)\n","        print('model flops:',get_flops(model))\n","\n","      save_best = keras.callbacks.ModelCheckpoint(\n","            filepath=best_result_file_name,\n","            monitor=monitor,\n","            verbose=1,\n","            save_best_only=True,\n","            save_weights_only=False,\n","            mode='min',\n","            save_freq='epoch')\n","\n","      if (run_fit): \n","            train_flow = train_datagen.flow(\n","                x_train, y_train,\n","                batch_size=batch_size,\n","                shuffle=True,\n","                seed=seed\n","            )\n","            validation_flow = valid_datagen.flow(\n","                x_val, y_val,\n","                batch_size=batch_size,\n","                shuffle=False,\n","                seed=seed\n","            )\n","            history = model.fit(\n","              x = train_flow,\n","              epochs=epochs,\n","              batch_size=batch_size,\n","              validation_data=validation_flow,\n","              callbacks=[save_best, tf.keras.callbacks.LearningRateScheduler(cyclical_adv_lrscheduler25)],\n","              workers=cpus_num,\n","              max_queue_size=128\n","            )\n","            plt.figure()\n","            plt.ylabel(\"Accuracy (training and validation)\")\n","            plt.xlabel(\"Epochs\")\n","            plt.ylim([0,1])\n","            plt.plot(history.history[\"accuracy\"])\n","            plt.plot(history.history[\"val_accuracy\"])\n","      if (test_results):\n","        test_flow = test_datagen.flow(\n","            x_test, y_test,\n","            batch_size=batch_size,\n","            shuffle=False,\n","            seed=seed\n","        )\n","        print('Best Model Results: '+best_result_file_name)\n","        model = cai.models.load_kereas_model(best_result_file_name)\n","        evaluated = model.evaluate(\n","            x=test_flow,\n","            batch_size=batch_size,\n","            use_multiprocessing=False,\n","            workers=cpus_num\n","        )\n","        for metric, name in zip(evaluated,[\"loss\",\"acc\"]):\n","              print(name,metric)\n","      if (calc_f1):\n","        cai.datasets.test_flips_on_saved_model(x_test, y_test, best_result_file_name, has_flip_x=True, has_flip_y=True, has_bw=True, center_crop=0.15)\n","      print('Finished: '+basefilename)"]},{"cell_type":"markdown","metadata":{"id":"HRSxTd5GeU5p"},"source":["# Show Models"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"EfjO1XESTCrY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647372302203,"user_tz":180,"elapsed":10092,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"02e9bd7b-94d5-4c3a-847e-f055581d5f42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running: /content/drive/MyDrive/output/JP30N14-45\n","Model: \"kEffNet-b0\"\n","____________________________________________________________________________________________________________________________________________________________________________________\n"," Layer (type)                                              Output Shape                            Param #              Connected to                                                \n","====================================================================================================================================================================================\n"," input_1 (InputLayer)                                      [(None, 224, 224, 3)]                   0                    []                                                          \n","                                                                                                                                                                                    \n"," k_stem_conv_pad (ZeroPadding2D)                           (None, 225, 225, 3)                     0                    ['input_1[0][0]']                                           \n","                                                                                                                                                                                    \n"," k_stem_conv (Conv2D)                                      (None, 112, 112, 32)                    864                  ['k_stem_conv_pad[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_stem_bn (BatchNormalization)                            (None, 112, 112, 32)                    128                  ['k_stem_conv[0][0]']                                       \n","                                                                                                                                                                                    \n"," k_stem_activation (Activation)                            (None, 112, 112, 32)                    0                    ['k_stem_bn[0][0]']                                         \n","                                                                                                                                                                                    \n"," k_block1a__0dwconv (DepthwiseConv2D)                      (None, 112, 112, 32)                    288                  ['k_stem_activation[0][0]']                                 \n","                                                                                                                                                                                    \n"," k_block1a__0bn (BatchNormalization)                       (None, 112, 112, 32)                    128                  ['k_block1a__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block1a__0activation (Activation)                       (None, 112, 112, 32)                    0                    ['k_block1a__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block1a__0se_squeeze (GlobalAveragePooling2D)           (None, 32)                              0                    ['k_block1a__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block1a__0se_reshape (Reshape)                          (None, 1, 1, 32)                        0                    ['k_block1a__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block1a__0se_reduce_c1_m8_conv (Conv2D)                 (None, 1, 1, 8)                         40                   ['k_block1a__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block1a__0se_reduce_c1_m8 (Activation)                  (None, 1, 1, 8)                         0                    ['k_block1a__0se_reduce_c1_m8_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block1a__0se_reduce_i2 (InterleaveChannels)             (None, 1, 1, 8)                         0                    ['k_block1a__0se_reduce_c1_m8[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block1a__0se_reduce_c2_m2_conv (Conv2D)                 (None, 1, 1, 8)                         40                   ['k_block1a__0se_reduce_i2[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block1a__0se_reduce_c2_m2 (Activation)                  (None, 1, 1, 8)                         0                    ['k_block1a__0se_reduce_c2_m2_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block1a__0se_reduce_iga (Add)                           (None, 1, 1, 8)                         0                    ['k_block1a__0se_reduce_c2_m2[0][0]',                       \n","                                                                                                                         'k_block1a__0se_reduce_c1_m8[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block1a__0se_expand_c1_m2_conv (Conv2D)                 (None, 1, 1, 32)                        160                  ['k_block1a__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block1a__0se_expand_c1_m2 (Activation)                  (None, 1, 1, 32)                        0                    ['k_block1a__0se_expand_c1_m2_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block1a__0se_excite (Multiply)                          (None, 112, 112, 32)                    0                    ['k_block1a__0activation[0][0]',                            \n","                                                                                                                         'k_block1a__0se_expand_c1_m2[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block1a__0project_conv_c1_m8_conv (Conv2D)              (None, 112, 112, 16)                    64                   ['k_block1a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block1a__0project_conv_c1_m8_bn (BatchNormalization)    (None, 112, 112, 16)                    64                   ['k_block1a__0project_conv_c1_m8_conv[0][0]']               \n","                                                                                                                                                                                    \n"," k_block1a__0project_conv_i4 (InterleaveChannels)          (None, 112, 112, 16)                    0                    ['k_block1a__0project_conv_c1_m8_bn[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block1a__0project_conv_c2_m4_conv (Conv2D)              (None, 112, 112, 16)                    64                   ['k_block1a__0project_conv_i4[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block1a__0project_conv_c2_m4_bn (BatchNormalization)    (None, 112, 112, 16)                    64                   ['k_block1a__0project_conv_c2_m4_conv[0][0]']               \n","                                                                                                                                                                                    \n"," k_block1a__0project_conv_iga (Add)                        (None, 112, 112, 16)                    0                    ['k_block1a__0project_conv_c2_m4_bn[0][0]',                 \n","                                                                                                                         'k_block1a__0project_conv_c1_m8_bn[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block2a__0expand_c1_m4_conv (Conv2D)                    (None, 112, 112, 96)                    384                  ['k_block1a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block2a__0expand_c1_m4_bn (BatchNormalization)          (None, 112, 112, 96)                    384                  ['k_block2a__0expand_c1_m4_conv[0][0]']                     \n","                                                                                                                                                                                    \n"," k_block2a__0expand_c1_m4 (Activation)                     (None, 112, 112, 96)                    0                    ['k_block2a__0expand_c1_m4_bn[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block2a__0dwconv_pad (ZeroPadding2D)                    (None, 113, 113, 96)                    0                    ['k_block2a__0expand_c1_m4[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block2a__0dwconv (DepthwiseConv2D)                      (None, 56, 56, 96)                      864                  ['k_block2a__0dwconv_pad[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block2a__0bn (BatchNormalization)                       (None, 56, 56, 96)                      384                  ['k_block2a__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block2a__0activation (Activation)                       (None, 56, 56, 96)                      0                    ['k_block2a__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block2a__0se_squeeze (GlobalAveragePooling2D)           (None, 96)                              0                    ['k_block2a__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block2a__0se_reshape (Reshape)                          (None, 1, 1, 96)                        0                    ['k_block2a__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block2a__0se_reduce_c1_m4_conv (Conv2D)                 (None, 1, 1, 4)                         100                  ['k_block2a__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block2a__0se_reduce_c1_m4 (Activation)                  (None, 1, 1, 4)                         0                    ['k_block2a__0se_reduce_c1_m4_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block2a__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 4)                         20                   ['k_block2a__0se_reduce_c1_m4[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block2a__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 4)                         0                    ['k_block2a__0se_reduce_c2_dum_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block2a__0se_reduce_iga (Add)                           (None, 1, 1, 4)                         0                    ['k_block2a__0se_reduce_c2_dum[0][0]',                      \n","                                                                                                                         'k_block2a__0se_reduce_c1_m4[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block2a__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 96)                        480                  ['k_block2a__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block2a__0se_expand_um (Activation)                     (None, 1, 1, 96)                        0                    ['k_block2a__0se_expand_um_conv[0][0]']                     \n","                                                                                                                                                                                    \n"," k_block2a__0se_excite (Multiply)                          (None, 56, 56, 96)                      0                    ['k_block2a__0activation[0][0]',                            \n","                                                                                                                         'k_block2a__0se_expand_um[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block2a__0project_conv_c1_m24_conv (Conv2D)             (None, 56, 56, 24)                      96                   ['k_block2a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block2a__0project_conv_c1_m24_bn (BatchNormalization)   (None, 56, 56, 24)                      96                   ['k_block2a__0project_conv_c1_m24_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block2a__0project_conv_i6 (InterleaveChannels)          (None, 56, 56, 24)                      0                    ['k_block2a__0project_conv_c1_m24_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block2a__0project_conv_c2_m6_conv (Conv2D)              (None, 56, 56, 24)                      96                   ['k_block2a__0project_conv_i6[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block2a__0project_conv_c2_m6_bn (BatchNormalization)    (None, 56, 56, 24)                      96                   ['k_block2a__0project_conv_c2_m6_conv[0][0]']               \n","                                                                                                                                                                                    \n"," k_block2a__0project_conv_iga (Add)                        (None, 56, 56, 24)                      0                    ['k_block2a__0project_conv_c2_m6_bn[0][0]',                 \n","                                                                                                                         'k_block2a__0project_conv_c1_m24_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block2b__0expand_c1_m6_conv (Conv2D)                    (None, 56, 56, 144)                     576                  ['k_block2a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block2b__0expand_c1_m6_bn (BatchNormalization)          (None, 56, 56, 144)                     576                  ['k_block2b__0expand_c1_m6_conv[0][0]']                     \n","                                                                                                                                                                                    \n"," k_block2b__0expand_c1_m6 (Activation)                     (None, 56, 56, 144)                     0                    ['k_block2b__0expand_c1_m6_bn[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block2b__0dwconv (DepthwiseConv2D)                      (None, 56, 56, 144)                     1296                 ['k_block2b__0expand_c1_m6[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block2b__0bn (BatchNormalization)                       (None, 56, 56, 144)                     576                  ['k_block2b__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block2b__0activation (Activation)                       (None, 56, 56, 144)                     0                    ['k_block2b__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block2b__0se_squeeze (GlobalAveragePooling2D)           (None, 144)                             0                    ['k_block2b__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block2b__0se_reshape (Reshape)                          (None, 1, 1, 144)                       0                    ['k_block2b__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block2b__0se_reduce_c1_m6_conv (Conv2D)                 (None, 1, 1, 6)                         150                  ['k_block2b__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block2b__0se_reduce_c1_m6 (Activation)                  (None, 1, 1, 6)                         0                    ['k_block2b__0se_reduce_c1_m6_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," copy_channels (CopyChannels)                              (None, 1, 1, 2)                         0                    ['k_block2b__0se_reduce_c1_m6[0][0]']                       \n","                                                                                                                                                                                    \n"," concatenate (Concatenate)                                 (None, 1, 1, 8)                         0                    ['k_block2b__0se_reduce_c1_m6[0][0]',                       \n","                                                                                                                         'copy_channels[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block2b__0se_reduce_c2_m2_conv (Conv2D)                 (None, 1, 1, 6)                         30                   ['concatenate[0][0]']                                       \n","                                                                                                                                                                                    \n"," k_block2b__0se_reduce_c2_m2 (Activation)                  (None, 1, 1, 6)                         0                    ['k_block2b__0se_reduce_c2_m2_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block2b__0se_reduce_iga (Add)                           (None, 1, 1, 6)                         0                    ['k_block2b__0se_reduce_c2_m2[0][0]',                       \n","                                                                                                                         'k_block2b__0se_reduce_c1_m6[0][0]']                       \n","                                                                                                                                                                                    \n"," copy_channels_1 (CopyChannels)                            (None, 1, 1, 2)                         0                    ['k_block2b__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," concatenate_1 (Concatenate)                               (None, 1, 1, 8)                         0                    ['k_block2b__0se_reduce_iga[0][0]',                         \n","                                                                                                                         'copy_channels_1[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block2b__0se_expand_c1_m2_conv (Conv2D)                 (None, 1, 1, 144)                       720                  ['concatenate_1[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block2b__0se_expand_c1_m2 (Activation)                  (None, 1, 1, 144)                       0                    ['k_block2b__0se_expand_c1_m2_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block2b__0se_excite (Multiply)                          (None, 56, 56, 144)                     0                    ['k_block2b__0activation[0][0]',                            \n","                                                                                                                         'k_block2b__0se_expand_c1_m2[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block2b__0project_conv_c1_m24_conv (Conv2D)             (None, 56, 56, 24)                      144                  ['k_block2b__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block2b__0project_conv_c1_m24_bn (BatchNormalization)   (None, 56, 56, 24)                      96                   ['k_block2b__0project_conv_c1_m24_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block2b__0project_conv_i6 (InterleaveChannels)          (None, 56, 56, 24)                      0                    ['k_block2b__0project_conv_c1_m24_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block2b__0project_conv_c2_m6_conv (Conv2D)              (None, 56, 56, 24)                      96                   ['k_block2b__0project_conv_i6[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block2b__0project_conv_c2_m6_bn (BatchNormalization)    (None, 56, 56, 24)                      96                   ['k_block2b__0project_conv_c2_m6_conv[0][0]']               \n","                                                                                                                                                                                    \n"," k_block2b__0project_conv_iga (Add)                        (None, 56, 56, 24)                      0                    ['k_block2b__0project_conv_c2_m6_bn[0][0]',                 \n","                                                                                                                         'k_block2b__0project_conv_c1_m24_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block2b__0drop (Dropout)                                (None, 56, 56, 24)                      0                    ['k_block2b__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block2b__0add (Add)                                     (None, 56, 56, 24)                      0                    ['k_block2b__0drop[0][0]',                                  \n","                                                                                                                         'k_block2a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block3a__0expand_c1_m6_conv (Conv2D)                    (None, 56, 56, 144)                     576                  ['k_block2b__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block3a__0expand_c1_m6_bn (BatchNormalization)          (None, 56, 56, 144)                     576                  ['k_block3a__0expand_c1_m6_conv[0][0]']                     \n","                                                                                                                                                                                    \n"," k_block3a__0expand_c1_m6 (Activation)                     (None, 56, 56, 144)                     0                    ['k_block3a__0expand_c1_m6_bn[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block3a__0dwconv_pad (ZeroPadding2D)                    (None, 59, 59, 144)                     0                    ['k_block3a__0expand_c1_m6[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block3a__0dwconv (DepthwiseConv2D)                      (None, 28, 28, 144)                     3600                 ['k_block3a__0dwconv_pad[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block3a__0bn (BatchNormalization)                       (None, 28, 28, 144)                     576                  ['k_block3a__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block3a__0activation (Activation)                       (None, 28, 28, 144)                     0                    ['k_block3a__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block3a__0se_squeeze (GlobalAveragePooling2D)           (None, 144)                             0                    ['k_block3a__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block3a__0se_reshape (Reshape)                          (None, 1, 1, 144)                       0                    ['k_block3a__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block3a__0se_reduce_c1_m6_conv (Conv2D)                 (None, 1, 1, 6)                         150                  ['k_block3a__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block3a__0se_reduce_c1_m6 (Activation)                  (None, 1, 1, 6)                         0                    ['k_block3a__0se_reduce_c1_m6_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," copy_channels_2 (CopyChannels)                            (None, 1, 1, 2)                         0                    ['k_block3a__0se_reduce_c1_m6[0][0]']                       \n","                                                                                                                                                                                    \n"," concatenate_2 (Concatenate)                               (None, 1, 1, 8)                         0                    ['k_block3a__0se_reduce_c1_m6[0][0]',                       \n","                                                                                                                         'copy_channels_2[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block3a__0se_reduce_c2_m2_conv (Conv2D)                 (None, 1, 1, 6)                         30                   ['concatenate_2[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block3a__0se_reduce_c2_m2 (Activation)                  (None, 1, 1, 6)                         0                    ['k_block3a__0se_reduce_c2_m2_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block3a__0se_reduce_iga (Add)                           (None, 1, 1, 6)                         0                    ['k_block3a__0se_reduce_c2_m2[0][0]',                       \n","                                                                                                                         'k_block3a__0se_reduce_c1_m6[0][0]']                       \n","                                                                                                                                                                                    \n"," copy_channels_3 (CopyChannels)                            (None, 1, 1, 2)                         0                    ['k_block3a__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," concatenate_3 (Concatenate)                               (None, 1, 1, 8)                         0                    ['k_block3a__0se_reduce_iga[0][0]',                         \n","                                                                                                                         'copy_channels_3[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block3a__0se_expand_c1_m2_conv (Conv2D)                 (None, 1, 1, 144)                       720                  ['concatenate_3[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block3a__0se_expand_c1_m2 (Activation)                  (None, 1, 1, 144)                       0                    ['k_block3a__0se_expand_c1_m2_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block3a__0se_excite (Multiply)                          (None, 28, 28, 144)                     0                    ['k_block3a__0activation[0][0]',                            \n","                                                                                                                         'k_block3a__0se_expand_c1_m2[0][0]']                       \n","                                                                                                                                                                                    \n"," copy_channels_4 (CopyChannels)                            (None, 28, 28, 16)                      0                    ['k_block3a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block3a__0project_conv_c1_p1_36_conv (Conv2D)           (None, 28, 28, 36)                      144                  ['k_block3a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block3a__0project_conv_c1_p2_conv (Conv2D)              (None, 28, 28, 4)                       16                   ['copy_channels_4[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block3a__0project_conv_c1_p1_36_bn (BatchNormalization)  (None, 28, 28, 36)                     144                  ['k_block3a__0project_conv_c1_p1_36_conv[0][0]']            \n","                                                                                                                                                                                    \n"," k_block3a__0project_conv_c1_p2_bn (BatchNormalization)    (None, 28, 28, 4)                       16                   ['k_block3a__0project_conv_c1_p2_conv[0][0]']               \n","                                                                                                                                                                                    \n"," k_block3a__0project_conv_c1_dc (Concatenate)              (None, 28, 28, 40)                      0                    ['k_block3a__0project_conv_c1_p1_36_bn[0][0]',              \n","                                                                                                                         'k_block3a__0project_conv_c1_p2_bn[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block3a__0project_conv_i10 (InterleaveChannels)         (None, 28, 28, 40)                      0                    ['k_block3a__0project_conv_c1_dc[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block3a__0project_conv_c2_m10_conv (Conv2D)             (None, 28, 28, 40)                      160                  ['k_block3a__0project_conv_i10[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block3a__0project_conv_c2_m10_bn (BatchNormalization)   (None, 28, 28, 40)                      160                  ['k_block3a__0project_conv_c2_m10_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block3a__0project_conv_iga (Add)                        (None, 28, 28, 40)                      0                    ['k_block3a__0project_conv_c2_m10_bn[0][0]',                \n","                                                                                                                         'k_block3a__0project_conv_c1_dc[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block3b__0expand_c1_m10_conv (Conv2D)                   (None, 28, 28, 240)                     960                  ['k_block3a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block3b__0expand_c1_m10_bn (BatchNormalization)         (None, 28, 28, 240)                     960                  ['k_block3b__0expand_c1_m10_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block3b__0expand_c1_m10 (Activation)                    (None, 28, 28, 240)                     0                    ['k_block3b__0expand_c1_m10_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block3b__0dwconv (DepthwiseConv2D)                      (None, 28, 28, 240)                     6000                 ['k_block3b__0expand_c1_m10[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block3b__0bn (BatchNormalization)                       (None, 28, 28, 240)                     960                  ['k_block3b__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block3b__0activation (Activation)                       (None, 28, 28, 240)                     0                    ['k_block3b__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block3b__0se_squeeze (GlobalAveragePooling2D)           (None, 240)                             0                    ['k_block3b__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block3b__0se_reshape (Reshape)                          (None, 1, 1, 240)                       0                    ['k_block3b__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block3b__0se_reduce_c1_m10_conv (Conv2D)                (None, 1, 1, 10)                        250                  ['k_block3b__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block3b__0se_reduce_c1_m10 (Activation)                 (None, 1, 1, 10)                        0                    ['k_block3b__0se_reduce_c1_m10_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block3b__0se_reduce_i2 (InterleaveChannels)             (None, 1, 1, 10)                        0                    ['k_block3b__0se_reduce_c1_m10[0][0]']                      \n","                                                                                                                                                                                    \n"," copy_channels_5 (CopyChannels)                            (None, 1, 1, 2)                         0                    ['k_block3b__0se_reduce_i2[0][0]']                          \n","                                                                                                                                                                                    \n"," concatenate_4 (Concatenate)                               (None, 1, 1, 12)                        0                    ['k_block3b__0se_reduce_i2[0][0]',                          \n","                                                                                                                         'copy_channels_5[0][0]']                                   \n","                                                                                                                                                                                    \n"," copy_channels_6 (CopyChannels)                            (None, 1, 1, 4)                         0                    ['concatenate_4[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block3b__0se_reduce_c2_p1_3_conv (Conv2D)               (None, 1, 1, 9)                         45                   ['concatenate_4[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block3b__0se_reduce_c2_p2_conv (Conv2D)                 (None, 1, 1, 1)                         5                    ['copy_channels_6[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block3b__0se_reduce_c2_p1_3 (Activation)                (None, 1, 1, 9)                         0                    ['k_block3b__0se_reduce_c2_p1_3_conv[0][0]']                \n","                                                                                                                                                                                    \n"," k_block3b__0se_reduce_c2_p2 (Activation)                  (None, 1, 1, 1)                         0                    ['k_block3b__0se_reduce_c2_p2_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block3b__0se_reduce_c2_dc (Concatenate)                 (None, 1, 1, 10)                        0                    ['k_block3b__0se_reduce_c2_p1_3[0][0]',                     \n","                                                                                                                         'k_block3b__0se_reduce_c2_p2[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block3b__0se_reduce_iga (Add)                           (None, 1, 1, 10)                        0                    ['k_block3b__0se_reduce_c2_dc[0][0]',                       \n","                                                                                                                         'k_block3b__0se_reduce_c1_m10[0][0]']                      \n","                                                                                                                                                                                    \n"," copy_channels_7 (CopyChannels)                            (None, 1, 1, 2)                         0                    ['k_block3b__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," concatenate_5 (Concatenate)                               (None, 1, 1, 12)                        0                    ['k_block3b__0se_reduce_iga[0][0]',                         \n","                                                                                                                         'copy_channels_7[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block3b__0se_expand_c1_m3_conv (Conv2D)                 (None, 1, 1, 240)                       1200                 ['concatenate_5[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block3b__0se_expand_c1_m3 (Activation)                  (None, 1, 1, 240)                       0                    ['k_block3b__0se_expand_c1_m3_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block3b__0se_excite (Multiply)                          (None, 28, 28, 240)                     0                    ['k_block3b__0activation[0][0]',                            \n","                                                                                                                         'k_block3b__0se_expand_c1_m3[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block3b__0project_conv_c1_m40_conv (Conv2D)             (None, 28, 28, 40)                      240                  ['k_block3b__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block3b__0project_conv_c1_m40_bn (BatchNormalization)   (None, 28, 28, 40)                      160                  ['k_block3b__0project_conv_c1_m40_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block3b__0project_conv_i10 (InterleaveChannels)         (None, 28, 28, 40)                      0                    ['k_block3b__0project_conv_c1_m40_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block3b__0project_conv_c2_m10_conv (Conv2D)             (None, 28, 28, 40)                      160                  ['k_block3b__0project_conv_i10[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block3b__0project_conv_c2_m10_bn (BatchNormalization)   (None, 28, 28, 40)                      160                  ['k_block3b__0project_conv_c2_m10_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block3b__0project_conv_iga (Add)                        (None, 28, 28, 40)                      0                    ['k_block3b__0project_conv_c2_m10_bn[0][0]',                \n","                                                                                                                         'k_block3b__0project_conv_c1_m40_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block3b__0drop (Dropout)                                (None, 28, 28, 40)                      0                    ['k_block3b__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block3b__0add (Add)                                     (None, 28, 28, 40)                      0                    ['k_block3b__0drop[0][0]',                                  \n","                                                                                                                         'k_block3a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4a__0expand_c1_m10_conv (Conv2D)                   (None, 28, 28, 240)                     960                  ['k_block3b__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block4a__0expand_c1_m10_bn (BatchNormalization)         (None, 28, 28, 240)                     960                  ['k_block4a__0expand_c1_m10_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block4a__0expand_c1_m10 (Activation)                    (None, 28, 28, 240)                     0                    ['k_block4a__0expand_c1_m10_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4a__0dwconv_pad (ZeroPadding2D)                    (None, 29, 29, 240)                     0                    ['k_block4a__0expand_c1_m10[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block4a__0dwconv (DepthwiseConv2D)                      (None, 14, 14, 240)                     2160                 ['k_block4a__0dwconv_pad[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4a__0bn (BatchNormalization)                       (None, 14, 14, 240)                     960                  ['k_block4a__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block4a__0activation (Activation)                       (None, 14, 14, 240)                     0                    ['k_block4a__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block4a__0se_squeeze (GlobalAveragePooling2D)           (None, 240)                             0                    ['k_block4a__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4a__0se_reshape (Reshape)                          (None, 1, 1, 240)                       0                    ['k_block4a__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4a__0se_reduce_c1_m10_conv (Conv2D)                (None, 1, 1, 10)                        250                  ['k_block4a__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4a__0se_reduce_c1_m10 (Activation)                 (None, 1, 1, 10)                        0                    ['k_block4a__0se_reduce_c1_m10_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block4a__0se_reduce_i2 (InterleaveChannels)             (None, 1, 1, 10)                        0                    ['k_block4a__0se_reduce_c1_m10[0][0]']                      \n","                                                                                                                                                                                    \n"," copy_channels_8 (CopyChannels)                            (None, 1, 1, 2)                         0                    ['k_block4a__0se_reduce_i2[0][0]']                          \n","                                                                                                                                                                                    \n"," concatenate_6 (Concatenate)                               (None, 1, 1, 12)                        0                    ['k_block4a__0se_reduce_i2[0][0]',                          \n","                                                                                                                         'copy_channels_8[0][0]']                                   \n","                                                                                                                                                                                    \n"," copy_channels_9 (CopyChannels)                            (None, 1, 1, 4)                         0                    ['concatenate_6[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block4a__0se_reduce_c2_p1_3_conv (Conv2D)               (None, 1, 1, 9)                         45                   ['concatenate_6[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block4a__0se_reduce_c2_p2_conv (Conv2D)                 (None, 1, 1, 1)                         5                    ['copy_channels_9[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block4a__0se_reduce_c2_p1_3 (Activation)                (None, 1, 1, 9)                         0                    ['k_block4a__0se_reduce_c2_p1_3_conv[0][0]']                \n","                                                                                                                                                                                    \n"," k_block4a__0se_reduce_c2_p2 (Activation)                  (None, 1, 1, 1)                         0                    ['k_block4a__0se_reduce_c2_p2_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block4a__0se_reduce_c2_dc (Concatenate)                 (None, 1, 1, 10)                        0                    ['k_block4a__0se_reduce_c2_p1_3[0][0]',                     \n","                                                                                                                         'k_block4a__0se_reduce_c2_p2[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block4a__0se_reduce_iga (Add)                           (None, 1, 1, 10)                        0                    ['k_block4a__0se_reduce_c2_dc[0][0]',                       \n","                                                                                                                         'k_block4a__0se_reduce_c1_m10[0][0]']                      \n","                                                                                                                                                                                    \n"," copy_channels_10 (CopyChannels)                           (None, 1, 1, 2)                         0                    ['k_block4a__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," concatenate_7 (Concatenate)                               (None, 1, 1, 12)                        0                    ['k_block4a__0se_reduce_iga[0][0]',                         \n","                                                                                                                         'copy_channels_10[0][0]']                                  \n","                                                                                                                                                                                    \n"," k_block4a__0se_expand_c1_m3_conv (Conv2D)                 (None, 1, 1, 240)                       1200                 ['concatenate_7[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block4a__0se_expand_c1_m3 (Activation)                  (None, 1, 1, 240)                       0                    ['k_block4a__0se_expand_c1_m3_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block4a__0se_excite (Multiply)                          (None, 14, 14, 240)                     0                    ['k_block4a__0activation[0][0]',                            \n","                                                                                                                         'k_block4a__0se_expand_c1_m3[0][0]']                       \n","                                                                                                                                                                                    \n"," copy_channels_11 (CopyChannels)                           (None, 14, 14, 80)                      0                    ['k_block4a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block4a__0project_conv_c1_p1_60_conv (Conv2D)           (None, 14, 14, 60)                      240                  ['k_block4a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block4a__0project_conv_c1_p2_conv (Conv2D)              (None, 14, 14, 20)                      80                   ['copy_channels_11[0][0]']                                  \n","                                                                                                                                                                                    \n"," k_block4a__0project_conv_c1_p1_60_bn (BatchNormalization)  (None, 14, 14, 60)                     240                  ['k_block4a__0project_conv_c1_p1_60_conv[0][0]']            \n","                                                                                                                                                                                    \n"," k_block4a__0project_conv_c1_p2_bn (BatchNormalization)    (None, 14, 14, 20)                      80                   ['k_block4a__0project_conv_c1_p2_conv[0][0]']               \n","                                                                                                                                                                                    \n"," k_block4a__0project_conv_c1_dc (Concatenate)              (None, 14, 14, 80)                      0                    ['k_block4a__0project_conv_c1_p1_60_bn[0][0]',              \n","                                                                                                                         'k_block4a__0project_conv_c1_p2_bn[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block4a__0project_conv_i20 (InterleaveChannels)         (None, 14, 14, 80)                      0                    ['k_block4a__0project_conv_c1_dc[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block4a__0project_conv_c2_m20_conv (Conv2D)             (None, 14, 14, 80)                      320                  ['k_block4a__0project_conv_i20[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4a__0project_conv_c2_m20_bn (BatchNormalization)   (None, 14, 14, 80)                      320                  ['k_block4a__0project_conv_c2_m20_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block4a__0project_conv_iga (Add)                        (None, 14, 14, 80)                      0                    ['k_block4a__0project_conv_c2_m20_bn[0][0]',                \n","                                                                                                                         'k_block4a__0project_conv_c1_dc[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block4b__0expand_c1_m20_conv (Conv2D)                   (None, 14, 14, 480)                     1920                 ['k_block4a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4b__0expand_c1_m20_bn (BatchNormalization)         (None, 14, 14, 480)                     1920                 ['k_block4b__0expand_c1_m20_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block4b__0expand_c1_m20 (Activation)                    (None, 14, 14, 480)                     0                    ['k_block4b__0expand_c1_m20_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4b__0dwconv (DepthwiseConv2D)                      (None, 14, 14, 480)                     4320                 ['k_block4b__0expand_c1_m20[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block4b__0bn (BatchNormalization)                       (None, 14, 14, 480)                     1920                 ['k_block4b__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block4b__0activation (Activation)                       (None, 14, 14, 480)                     0                    ['k_block4b__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block4b__0se_squeeze (GlobalAveragePooling2D)           (None, 480)                             0                    ['k_block4b__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4b__0se_reshape (Reshape)                          (None, 1, 1, 480)                       0                    ['k_block4b__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4b__0se_reduce_c1_m20_conv (Conv2D)                (None, 1, 1, 20)                        500                  ['k_block4b__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4b__0se_reduce_c1_m20 (Activation)                 (None, 1, 1, 20)                        0                    ['k_block4b__0se_reduce_c1_m20_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block4b__0se_reduce_i5 (InterleaveChannels)             (None, 1, 1, 20)                        0                    ['k_block4b__0se_reduce_c1_m20[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4b__0se_reduce_c2_m5_conv (Conv2D)                 (None, 1, 1, 20)                        100                  ['k_block4b__0se_reduce_i5[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block4b__0se_reduce_c2_m5 (Activation)                  (None, 1, 1, 20)                        0                    ['k_block4b__0se_reduce_c2_m5_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block4b__0se_reduce_iga (Add)                           (None, 1, 1, 20)                        0                    ['k_block4b__0se_reduce_c2_m5[0][0]',                       \n","                                                                                                                         'k_block4b__0se_reduce_c1_m20[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4b__0se_expand_c1_m5_conv (Conv2D)                 (None, 1, 1, 480)                       2400                 ['k_block4b__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block4b__0se_expand_c1_m5 (Activation)                  (None, 1, 1, 480)                       0                    ['k_block4b__0se_expand_c1_m5_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block4b__0se_excite (Multiply)                          (None, 14, 14, 480)                     0                    ['k_block4b__0activation[0][0]',                            \n","                                                                                                                         'k_block4b__0se_expand_c1_m5[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block4b__0project_conv_c1_m80_conv (Conv2D)             (None, 14, 14, 80)                      480                  ['k_block4b__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block4b__0project_conv_c1_m80_bn (BatchNormalization)   (None, 14, 14, 80)                      320                  ['k_block4b__0project_conv_c1_m80_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block4b__0project_conv_i20 (InterleaveChannels)         (None, 14, 14, 80)                      0                    ['k_block4b__0project_conv_c1_m80_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block4b__0project_conv_c2_m20_conv (Conv2D)             (None, 14, 14, 80)                      320                  ['k_block4b__0project_conv_i20[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4b__0project_conv_c2_m20_bn (BatchNormalization)   (None, 14, 14, 80)                      320                  ['k_block4b__0project_conv_c2_m20_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block4b__0project_conv_iga (Add)                        (None, 14, 14, 80)                      0                    ['k_block4b__0project_conv_c2_m20_bn[0][0]',                \n","                                                                                                                         'k_block4b__0project_conv_c1_m80_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block4b__0drop (Dropout)                                (None, 14, 14, 80)                      0                    ['k_block4b__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4b__0add (Add)                                     (None, 14, 14, 80)                      0                    ['k_block4b__0drop[0][0]',                                  \n","                                                                                                                         'k_block4a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4c__0expand_c1_m20_conv (Conv2D)                   (None, 14, 14, 480)                     1920                 ['k_block4b__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block4c__0expand_c1_m20_bn (BatchNormalization)         (None, 14, 14, 480)                     1920                 ['k_block4c__0expand_c1_m20_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block4c__0expand_c1_m20 (Activation)                    (None, 14, 14, 480)                     0                    ['k_block4c__0expand_c1_m20_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4c__0dwconv (DepthwiseConv2D)                      (None, 14, 14, 480)                     4320                 ['k_block4c__0expand_c1_m20[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block4c__0bn (BatchNormalization)                       (None, 14, 14, 480)                     1920                 ['k_block4c__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block4c__0activation (Activation)                       (None, 14, 14, 480)                     0                    ['k_block4c__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block4c__0se_squeeze (GlobalAveragePooling2D)           (None, 480)                             0                    ['k_block4c__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4c__0se_reshape (Reshape)                          (None, 1, 1, 480)                       0                    ['k_block4c__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4c__0se_reduce_c1_m20_conv (Conv2D)                (None, 1, 1, 20)                        500                  ['k_block4c__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block4c__0se_reduce_c1_m20 (Activation)                 (None, 1, 1, 20)                        0                    ['k_block4c__0se_reduce_c1_m20_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block4c__0se_reduce_i5 (InterleaveChannels)             (None, 1, 1, 20)                        0                    ['k_block4c__0se_reduce_c1_m20[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4c__0se_reduce_c2_m5_conv (Conv2D)                 (None, 1, 1, 20)                        100                  ['k_block4c__0se_reduce_i5[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block4c__0se_reduce_c2_m5 (Activation)                  (None, 1, 1, 20)                        0                    ['k_block4c__0se_reduce_c2_m5_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block4c__0se_reduce_iga (Add)                           (None, 1, 1, 20)                        0                    ['k_block4c__0se_reduce_c2_m5[0][0]',                       \n","                                                                                                                         'k_block4c__0se_reduce_c1_m20[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4c__0se_expand_c1_m5_conv (Conv2D)                 (None, 1, 1, 480)                       2400                 ['k_block4c__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block4c__0se_expand_c1_m5 (Activation)                  (None, 1, 1, 480)                       0                    ['k_block4c__0se_expand_c1_m5_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block4c__0se_excite (Multiply)                          (None, 14, 14, 480)                     0                    ['k_block4c__0activation[0][0]',                            \n","                                                                                                                         'k_block4c__0se_expand_c1_m5[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block4c__0project_conv_c1_m80_conv (Conv2D)             (None, 14, 14, 80)                      480                  ['k_block4c__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block4c__0project_conv_c1_m80_bn (BatchNormalization)   (None, 14, 14, 80)                      320                  ['k_block4c__0project_conv_c1_m80_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block4c__0project_conv_i20 (InterleaveChannels)         (None, 14, 14, 80)                      0                    ['k_block4c__0project_conv_c1_m80_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block4c__0project_conv_c2_m20_conv (Conv2D)             (None, 14, 14, 80)                      320                  ['k_block4c__0project_conv_i20[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4c__0project_conv_c2_m20_bn (BatchNormalization)   (None, 14, 14, 80)                      320                  ['k_block4c__0project_conv_c2_m20_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block4c__0project_conv_iga (Add)                        (None, 14, 14, 80)                      0                    ['k_block4c__0project_conv_c2_m20_bn[0][0]',                \n","                                                                                                                         'k_block4c__0project_conv_c1_m80_bn[0][0]']                \n","                                                                                                                                                                                    \n"," k_block4c__0drop (Dropout)                                (None, 14, 14, 80)                      0                    ['k_block4c__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block4c__0add (Add)                                     (None, 14, 14, 80)                      0                    ['k_block4c__0drop[0][0]',                                  \n","                                                                                                                         'k_block4b__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block5a__0expand_c1_m20_conv (Conv2D)                   (None, 14, 14, 480)                     1920                 ['k_block4c__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block5a__0expand_c1_m20_bn (BatchNormalization)         (None, 14, 14, 480)                     1920                 ['k_block5a__0expand_c1_m20_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block5a__0expand_c1_m20 (Activation)                    (None, 14, 14, 480)                     0                    ['k_block5a__0expand_c1_m20_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5a__0dwconv (DepthwiseConv2D)                      (None, 14, 14, 480)                     12000                ['k_block5a__0expand_c1_m20[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block5a__0bn (BatchNormalization)                       (None, 14, 14, 480)                     1920                 ['k_block5a__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block5a__0activation (Activation)                       (None, 14, 14, 480)                     0                    ['k_block5a__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block5a__0se_squeeze (GlobalAveragePooling2D)           (None, 480)                             0                    ['k_block5a__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block5a__0se_reshape (Reshape)                          (None, 1, 1, 480)                       0                    ['k_block5a__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block5a__0se_reduce_c1_m20_conv (Conv2D)                (None, 1, 1, 20)                        500                  ['k_block5a__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block5a__0se_reduce_c1_m20 (Activation)                 (None, 1, 1, 20)                        0                    ['k_block5a__0se_reduce_c1_m20_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block5a__0se_reduce_i5 (InterleaveChannels)             (None, 1, 1, 20)                        0                    ['k_block5a__0se_reduce_c1_m20[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5a__0se_reduce_c2_m5_conv (Conv2D)                 (None, 1, 1, 20)                        100                  ['k_block5a__0se_reduce_i5[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block5a__0se_reduce_c2_m5 (Activation)                  (None, 1, 1, 20)                        0                    ['k_block5a__0se_reduce_c2_m5_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block5a__0se_reduce_iga (Add)                           (None, 1, 1, 20)                        0                    ['k_block5a__0se_reduce_c2_m5[0][0]',                       \n","                                                                                                                         'k_block5a__0se_reduce_c1_m20[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5a__0se_expand_c1_m5_conv (Conv2D)                 (None, 1, 1, 480)                       2400                 ['k_block5a__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block5a__0se_expand_c1_m5 (Activation)                  (None, 1, 1, 480)                       0                    ['k_block5a__0se_expand_c1_m5_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block5a__0se_excite (Multiply)                          (None, 14, 14, 480)                     0                    ['k_block5a__0activation[0][0]',                            \n","                                                                                                                         'k_block5a__0se_expand_c1_m5[0][0]']                       \n","                                                                                                                                                                                    \n"," copy_channels_12 (CopyChannels)                           (None, 14, 14, 80)                      0                    ['k_block5a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," concatenate_8 (Concatenate)                               (None, 14, 14, 560)                     0                    ['k_block5a__0se_excite[0][0]',                             \n","                                                                                                                         'copy_channels_12[0][0]']                                  \n","                                                                                                                                                                                    \n"," k_block5a__0project_conv_c1_m112_conv (Conv2D)            (None, 14, 14, 112)                     560                  ['concatenate_8[0][0]']                                     \n","                                                                                                                                                                                    \n"," k_block5a__0project_conv_c1_m112_bn (BatchNormalization)  (None, 14, 14, 112)                     448                  ['k_block5a__0project_conv_c1_m112_conv[0][0]']             \n","                                                                                                                                                                                    \n"," k_block5a__0project_conv_i28 (InterleaveChannels)         (None, 14, 14, 112)                     0                    ['k_block5a__0project_conv_c1_m112_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block5a__0project_conv_c2_m28_conv (Conv2D)             (None, 14, 14, 112)                     448                  ['k_block5a__0project_conv_i28[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5a__0project_conv_c2_m28_bn (BatchNormalization)   (None, 14, 14, 112)                     448                  ['k_block5a__0project_conv_c2_m28_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block5a__0project_conv_iga (Add)                        (None, 14, 14, 112)                     0                    ['k_block5a__0project_conv_c2_m28_bn[0][0]',                \n","                                                                                                                         'k_block5a__0project_conv_c1_m112_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block5b__0expand_c1_m28_conv (Conv2D)                   (None, 14, 14, 672)                     2688                 ['k_block5a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5b__0expand_c1_m28_bn (BatchNormalization)         (None, 14, 14, 672)                     2688                 ['k_block5b__0expand_c1_m28_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block5b__0expand_c1_m28 (Activation)                    (None, 14, 14, 672)                     0                    ['k_block5b__0expand_c1_m28_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5b__0dwconv (DepthwiseConv2D)                      (None, 14, 14, 672)                     16800                ['k_block5b__0expand_c1_m28[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block5b__0bn (BatchNormalization)                       (None, 14, 14, 672)                     2688                 ['k_block5b__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block5b__0activation (Activation)                       (None, 14, 14, 672)                     0                    ['k_block5b__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block5b__0se_squeeze (GlobalAveragePooling2D)           (None, 672)                             0                    ['k_block5b__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block5b__0se_reshape (Reshape)                          (None, 1, 1, 672)                       0                    ['k_block5b__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block5b__0se_reduce_c1_m28_conv (Conv2D)                (None, 1, 1, 28)                        700                  ['k_block5b__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block5b__0se_reduce_c1_m28 (Activation)                 (None, 1, 1, 28)                        0                    ['k_block5b__0se_reduce_c1_m28_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block5b__0se_reduce_i7 (InterleaveChannels)             (None, 1, 1, 28)                        0                    ['k_block5b__0se_reduce_c1_m28[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5b__0se_reduce_c2_m7_conv (Conv2D)                 (None, 1, 1, 28)                        140                  ['k_block5b__0se_reduce_i7[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block5b__0se_reduce_c2_m7 (Activation)                  (None, 1, 1, 28)                        0                    ['k_block5b__0se_reduce_c2_m7_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block5b__0se_reduce_iga (Add)                           (None, 1, 1, 28)                        0                    ['k_block5b__0se_reduce_c2_m7[0][0]',                       \n","                                                                                                                         'k_block5b__0se_reduce_c1_m28[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5b__0se_expand_c1_m7_conv (Conv2D)                 (None, 1, 1, 672)                       3360                 ['k_block5b__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block5b__0se_expand_c1_m7 (Activation)                  (None, 1, 1, 672)                       0                    ['k_block5b__0se_expand_c1_m7_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block5b__0se_excite (Multiply)                          (None, 14, 14, 672)                     0                    ['k_block5b__0activation[0][0]',                            \n","                                                                                                                         'k_block5b__0se_expand_c1_m7[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block5b__0project_conv_c1_m112_conv (Conv2D)            (None, 14, 14, 112)                     672                  ['k_block5b__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block5b__0project_conv_c1_m112_bn (BatchNormalization)  (None, 14, 14, 112)                     448                  ['k_block5b__0project_conv_c1_m112_conv[0][0]']             \n","                                                                                                                                                                                    \n"," k_block5b__0project_conv_i28 (InterleaveChannels)         (None, 14, 14, 112)                     0                    ['k_block5b__0project_conv_c1_m112_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block5b__0project_conv_c2_m28_conv (Conv2D)             (None, 14, 14, 112)                     448                  ['k_block5b__0project_conv_i28[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5b__0project_conv_c2_m28_bn (BatchNormalization)   (None, 14, 14, 112)                     448                  ['k_block5b__0project_conv_c2_m28_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block5b__0project_conv_iga (Add)                        (None, 14, 14, 112)                     0                    ['k_block5b__0project_conv_c2_m28_bn[0][0]',                \n","                                                                                                                         'k_block5b__0project_conv_c1_m112_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block5b__0drop (Dropout)                                (None, 14, 14, 112)                     0                    ['k_block5b__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5b__0add (Add)                                     (None, 14, 14, 112)                     0                    ['k_block5b__0drop[0][0]',                                  \n","                                                                                                                         'k_block5a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5c__0expand_c1_m28_conv (Conv2D)                   (None, 14, 14, 672)                     2688                 ['k_block5b__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block5c__0expand_c1_m28_bn (BatchNormalization)         (None, 14, 14, 672)                     2688                 ['k_block5c__0expand_c1_m28_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block5c__0expand_c1_m28 (Activation)                    (None, 14, 14, 672)                     0                    ['k_block5c__0expand_c1_m28_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5c__0dwconv (DepthwiseConv2D)                      (None, 14, 14, 672)                     16800                ['k_block5c__0expand_c1_m28[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block5c__0bn (BatchNormalization)                       (None, 14, 14, 672)                     2688                 ['k_block5c__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block5c__0activation (Activation)                       (None, 14, 14, 672)                     0                    ['k_block5c__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block5c__0se_squeeze (GlobalAveragePooling2D)           (None, 672)                             0                    ['k_block5c__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block5c__0se_reshape (Reshape)                          (None, 1, 1, 672)                       0                    ['k_block5c__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block5c__0se_reduce_c1_m28_conv (Conv2D)                (None, 1, 1, 28)                        700                  ['k_block5c__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block5c__0se_reduce_c1_m28 (Activation)                 (None, 1, 1, 28)                        0                    ['k_block5c__0se_reduce_c1_m28_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block5c__0se_reduce_i7 (InterleaveChannels)             (None, 1, 1, 28)                        0                    ['k_block5c__0se_reduce_c1_m28[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5c__0se_reduce_c2_m7_conv (Conv2D)                 (None, 1, 1, 28)                        140                  ['k_block5c__0se_reduce_i7[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block5c__0se_reduce_c2_m7 (Activation)                  (None, 1, 1, 28)                        0                    ['k_block5c__0se_reduce_c2_m7_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block5c__0se_reduce_iga (Add)                           (None, 1, 1, 28)                        0                    ['k_block5c__0se_reduce_c2_m7[0][0]',                       \n","                                                                                                                         'k_block5c__0se_reduce_c1_m28[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5c__0se_expand_c1_m7_conv (Conv2D)                 (None, 1, 1, 672)                       3360                 ['k_block5c__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block5c__0se_expand_c1_m7 (Activation)                  (None, 1, 1, 672)                       0                    ['k_block5c__0se_expand_c1_m7_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block5c__0se_excite (Multiply)                          (None, 14, 14, 672)                     0                    ['k_block5c__0activation[0][0]',                            \n","                                                                                                                         'k_block5c__0se_expand_c1_m7[0][0]']                       \n","                                                                                                                                                                                    \n"," k_block5c__0project_conv_c1_m112_conv (Conv2D)            (None, 14, 14, 112)                     672                  ['k_block5c__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block5c__0project_conv_c1_m112_bn (BatchNormalization)  (None, 14, 14, 112)                     448                  ['k_block5c__0project_conv_c1_m112_conv[0][0]']             \n","                                                                                                                                                                                    \n"," k_block5c__0project_conv_i28 (InterleaveChannels)         (None, 14, 14, 112)                     0                    ['k_block5c__0project_conv_c1_m112_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block5c__0project_conv_c2_m28_conv (Conv2D)             (None, 14, 14, 112)                     448                  ['k_block5c__0project_conv_i28[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5c__0project_conv_c2_m28_bn (BatchNormalization)   (None, 14, 14, 112)                     448                  ['k_block5c__0project_conv_c2_m28_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block5c__0project_conv_iga (Add)                        (None, 14, 14, 112)                     0                    ['k_block5c__0project_conv_c2_m28_bn[0][0]',                \n","                                                                                                                         'k_block5c__0project_conv_c1_m112_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block5c__0drop (Dropout)                                (None, 14, 14, 112)                     0                    ['k_block5c__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block5c__0add (Add)                                     (None, 14, 14, 112)                     0                    ['k_block5c__0drop[0][0]',                                  \n","                                                                                                                         'k_block5b__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block6a__0expand_c1_m28_conv (Conv2D)                   (None, 14, 14, 672)                     2688                 ['k_block5c__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block6a__0expand_c1_m28_bn (BatchNormalization)         (None, 14, 14, 672)                     2688                 ['k_block6a__0expand_c1_m28_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block6a__0expand_c1_m28 (Activation)                    (None, 14, 14, 672)                     0                    ['k_block6a__0expand_c1_m28_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6a__0dwconv_pad (ZeroPadding2D)                    (None, 17, 17, 672)                     0                    ['k_block6a__0expand_c1_m28[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6a__0dwconv (DepthwiseConv2D)                      (None, 7, 7, 672)                       16800                ['k_block6a__0dwconv_pad[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6a__0bn (BatchNormalization)                       (None, 7, 7, 672)                       2688                 ['k_block6a__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block6a__0activation (Activation)                       (None, 7, 7, 672)                       0                    ['k_block6a__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block6a__0se_squeeze (GlobalAveragePooling2D)           (None, 672)                             0                    ['k_block6a__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6a__0se_reshape (Reshape)                          (None, 1, 1, 672)                       0                    ['k_block6a__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6a__0se_reduce_c1_m28_conv (Conv2D)                (None, 1, 1, 28)                        700                  ['k_block6a__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6a__0se_reduce_c1_m28 (Activation)                 (None, 1, 1, 28)                        0                    ['k_block6a__0se_reduce_c1_m28_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6a__0se_reduce_i7 (InterleaveChannels)             (None, 1, 1, 28)                        0                    ['k_block6a__0se_reduce_c1_m28[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6a__0se_reduce_c2_m7_conv (Conv2D)                 (None, 1, 1, 28)                        140                  ['k_block6a__0se_reduce_i7[0][0]']                          \n","                                                                                                                                                                                    \n"," k_block6a__0se_reduce_c2_m7 (Activation)                  (None, 1, 1, 28)                        0                    ['k_block6a__0se_reduce_c2_m7_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block6a__0se_reduce_iga (Add)                           (None, 1, 1, 28)                        0                    ['k_block6a__0se_reduce_c2_m7[0][0]',                       \n","                                                                                                                         'k_block6a__0se_reduce_c1_m28[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6a__0se_expand_c1_m7_conv (Conv2D)                 (None, 1, 1, 672)                       3360                 ['k_block6a__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6a__0se_expand_c1_m7 (Activation)                  (None, 1, 1, 672)                       0                    ['k_block6a__0se_expand_c1_m7_conv[0][0]']                  \n","                                                                                                                                                                                    \n"," k_block6a__0se_excite (Multiply)                          (None, 7, 7, 672)                       0                    ['k_block6a__0activation[0][0]',                            \n","                                                                                                                         'k_block6a__0se_expand_c1_m7[0][0]']                       \n","                                                                                                                                                                                    \n"," copy_channels_13 (CopyChannels)                           (None, 7, 7, 96)                        0                    ['k_block6a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block6a__0project_conv_c1_p1_168_conv (Conv2D)          (None, 7, 7, 168)                       672                  ['k_block6a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block6a__0project_conv_c1_p2_conv (Conv2D)              (None, 7, 7, 24)                        96                   ['copy_channels_13[0][0]']                                  \n","                                                                                                                                                                                    \n"," k_block6a__0project_conv_c1_p1_168_bn (BatchNormalization  (None, 7, 7, 168)                      672                  ['k_block6a__0project_conv_c1_p1_168_conv[0][0]']           \n"," )                                                                                                                                                                                  \n","                                                                                                                                                                                    \n"," k_block6a__0project_conv_c1_p2_bn (BatchNormalization)    (None, 7, 7, 24)                        96                   ['k_block6a__0project_conv_c1_p2_conv[0][0]']               \n","                                                                                                                                                                                    \n"," k_block6a__0project_conv_c1_dc (Concatenate)              (None, 7, 7, 192)                       0                    ['k_block6a__0project_conv_c1_p1_168_bn[0][0]',             \n","                                                                                                                         'k_block6a__0project_conv_c1_p2_bn[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6a__0project_conv_i48 (InterleaveChannels)         (None, 7, 7, 192)                       0                    ['k_block6a__0project_conv_c1_dc[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block6a__0project_conv_c2_m48_conv (Conv2D)             (None, 7, 7, 192)                       768                  ['k_block6a__0project_conv_i48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6a__0project_conv_c2_m48_bn (BatchNormalization)   (None, 7, 7, 192)                       768                  ['k_block6a__0project_conv_c2_m48_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block6a__0project_conv_iga (Add)                        (None, 7, 7, 192)                       0                    ['k_block6a__0project_conv_c2_m48_bn[0][0]',                \n","                                                                                                                         'k_block6a__0project_conv_c1_dc[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block6b__0expand_c1_m48_conv (Conv2D)                   (None, 7, 7, 1152)                      4608                 ['k_block6a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6b__0expand_c1_m48_bn (BatchNormalization)         (None, 7, 7, 1152)                      4608                 ['k_block6b__0expand_c1_m48_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block6b__0expand_c1_m48 (Activation)                    (None, 7, 7, 1152)                      0                    ['k_block6b__0expand_c1_m48_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6b__0dwconv (DepthwiseConv2D)                      (None, 7, 7, 1152)                      28800                ['k_block6b__0expand_c1_m48[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6b__0bn (BatchNormalization)                       (None, 7, 7, 1152)                      4608                 ['k_block6b__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block6b__0activation (Activation)                       (None, 7, 7, 1152)                      0                    ['k_block6b__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block6b__0se_squeeze (GlobalAveragePooling2D)           (None, 1152)                            0                    ['k_block6b__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6b__0se_reshape (Reshape)                          (None, 1, 1, 1152)                      0                    ['k_block6b__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6b__0se_reduce_c1_m48_conv (Conv2D)                (None, 1, 1, 48)                        1200                 ['k_block6b__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6b__0se_reduce_c1_m48 (Activation)                 (None, 1, 1, 48)                        0                    ['k_block6b__0se_reduce_c1_m48_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6b__0se_reduce_i12 (InterleaveChannels)            (None, 1, 1, 48)                        0                    ['k_block6b__0se_reduce_c1_m48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6b__0se_reduce_c2_m12_conv (Conv2D)                (None, 1, 1, 48)                        240                  ['k_block6b__0se_reduce_i12[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6b__0se_reduce_c2_m12 (Activation)                 (None, 1, 1, 48)                        0                    ['k_block6b__0se_reduce_c2_m12_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6b__0se_reduce_iga (Add)                           (None, 1, 1, 48)                        0                    ['k_block6b__0se_reduce_c2_m12[0][0]',                      \n","                                                                                                                         'k_block6b__0se_reduce_c1_m48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6b__0se_expand_c1_m12_conv (Conv2D)                (None, 1, 1, 1152)                      5760                 ['k_block6b__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6b__0se_expand_c1_m12 (Activation)                 (None, 1, 1, 1152)                      0                    ['k_block6b__0se_expand_c1_m12_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6b__0se_excite (Multiply)                          (None, 7, 7, 1152)                      0                    ['k_block6b__0activation[0][0]',                            \n","                                                                                                                         'k_block6b__0se_expand_c1_m12[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6b__0project_conv_c1_m192_conv (Conv2D)            (None, 7, 7, 192)                       1152                 ['k_block6b__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block6b__0project_conv_c1_m192_bn (BatchNormalization)  (None, 7, 7, 192)                       768                  ['k_block6b__0project_conv_c1_m192_conv[0][0]']             \n","                                                                                                                                                                                    \n"," k_block6b__0project_conv_i48 (InterleaveChannels)         (None, 7, 7, 192)                       0                    ['k_block6b__0project_conv_c1_m192_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block6b__0project_conv_c2_m48_conv (Conv2D)             (None, 7, 7, 192)                       768                  ['k_block6b__0project_conv_i48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6b__0project_conv_c2_m48_bn (BatchNormalization)   (None, 7, 7, 192)                       768                  ['k_block6b__0project_conv_c2_m48_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block6b__0project_conv_iga (Add)                        (None, 7, 7, 192)                       0                    ['k_block6b__0project_conv_c2_m48_bn[0][0]',                \n","                                                                                                                         'k_block6b__0project_conv_c1_m192_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block6b__0drop (Dropout)                                (None, 7, 7, 192)                       0                    ['k_block6b__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6b__0add (Add)                                     (None, 7, 7, 192)                       0                    ['k_block6b__0drop[0][0]',                                  \n","                                                                                                                         'k_block6a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6c__0expand_c1_m48_conv (Conv2D)                   (None, 7, 7, 1152)                      4608                 ['k_block6b__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block6c__0expand_c1_m48_bn (BatchNormalization)         (None, 7, 7, 1152)                      4608                 ['k_block6c__0expand_c1_m48_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block6c__0expand_c1_m48 (Activation)                    (None, 7, 7, 1152)                      0                    ['k_block6c__0expand_c1_m48_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6c__0dwconv (DepthwiseConv2D)                      (None, 7, 7, 1152)                      28800                ['k_block6c__0expand_c1_m48[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6c__0bn (BatchNormalization)                       (None, 7, 7, 1152)                      4608                 ['k_block6c__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block6c__0activation (Activation)                       (None, 7, 7, 1152)                      0                    ['k_block6c__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block6c__0se_squeeze (GlobalAveragePooling2D)           (None, 1152)                            0                    ['k_block6c__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6c__0se_reshape (Reshape)                          (None, 1, 1, 1152)                      0                    ['k_block6c__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6c__0se_reduce_c1_m48_conv (Conv2D)                (None, 1, 1, 48)                        1200                 ['k_block6c__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6c__0se_reduce_c1_m48 (Activation)                 (None, 1, 1, 48)                        0                    ['k_block6c__0se_reduce_c1_m48_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6c__0se_reduce_i12 (InterleaveChannels)            (None, 1, 1, 48)                        0                    ['k_block6c__0se_reduce_c1_m48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6c__0se_reduce_c2_m12_conv (Conv2D)                (None, 1, 1, 48)                        240                  ['k_block6c__0se_reduce_i12[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6c__0se_reduce_c2_m12 (Activation)                 (None, 1, 1, 48)                        0                    ['k_block6c__0se_reduce_c2_m12_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6c__0se_reduce_iga (Add)                           (None, 1, 1, 48)                        0                    ['k_block6c__0se_reduce_c2_m12[0][0]',                      \n","                                                                                                                         'k_block6c__0se_reduce_c1_m48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6c__0se_expand_c1_m12_conv (Conv2D)                (None, 1, 1, 1152)                      5760                 ['k_block6c__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6c__0se_expand_c1_m12 (Activation)                 (None, 1, 1, 1152)                      0                    ['k_block6c__0se_expand_c1_m12_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6c__0se_excite (Multiply)                          (None, 7, 7, 1152)                      0                    ['k_block6c__0activation[0][0]',                            \n","                                                                                                                         'k_block6c__0se_expand_c1_m12[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6c__0project_conv_c1_m192_conv (Conv2D)            (None, 7, 7, 192)                       1152                 ['k_block6c__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block6c__0project_conv_c1_m192_bn (BatchNormalization)  (None, 7, 7, 192)                       768                  ['k_block6c__0project_conv_c1_m192_conv[0][0]']             \n","                                                                                                                                                                                    \n"," k_block6c__0project_conv_i48 (InterleaveChannels)         (None, 7, 7, 192)                       0                    ['k_block6c__0project_conv_c1_m192_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block6c__0project_conv_c2_m48_conv (Conv2D)             (None, 7, 7, 192)                       768                  ['k_block6c__0project_conv_i48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6c__0project_conv_c2_m48_bn (BatchNormalization)   (None, 7, 7, 192)                       768                  ['k_block6c__0project_conv_c2_m48_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block6c__0project_conv_iga (Add)                        (None, 7, 7, 192)                       0                    ['k_block6c__0project_conv_c2_m48_bn[0][0]',                \n","                                                                                                                         'k_block6c__0project_conv_c1_m192_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block6c__0drop (Dropout)                                (None, 7, 7, 192)                       0                    ['k_block6c__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6c__0add (Add)                                     (None, 7, 7, 192)                       0                    ['k_block6c__0drop[0][0]',                                  \n","                                                                                                                         'k_block6b__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block6d__0expand_c1_m48_conv (Conv2D)                   (None, 7, 7, 1152)                      4608                 ['k_block6c__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block6d__0expand_c1_m48_bn (BatchNormalization)         (None, 7, 7, 1152)                      4608                 ['k_block6d__0expand_c1_m48_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block6d__0expand_c1_m48 (Activation)                    (None, 7, 7, 1152)                      0                    ['k_block6d__0expand_c1_m48_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6d__0dwconv (DepthwiseConv2D)                      (None, 7, 7, 1152)                      28800                ['k_block6d__0expand_c1_m48[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6d__0bn (BatchNormalization)                       (None, 7, 7, 1152)                      4608                 ['k_block6d__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block6d__0activation (Activation)                       (None, 7, 7, 1152)                      0                    ['k_block6d__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block6d__0se_squeeze (GlobalAveragePooling2D)           (None, 1152)                            0                    ['k_block6d__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6d__0se_reshape (Reshape)                          (None, 1, 1, 1152)                      0                    ['k_block6d__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6d__0se_reduce_c1_m48_conv (Conv2D)                (None, 1, 1, 48)                        1200                 ['k_block6d__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block6d__0se_reduce_c1_m48 (Activation)                 (None, 1, 1, 48)                        0                    ['k_block6d__0se_reduce_c1_m48_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6d__0se_reduce_i12 (InterleaveChannels)            (None, 1, 1, 48)                        0                    ['k_block6d__0se_reduce_c1_m48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6d__0se_reduce_c2_m12_conv (Conv2D)                (None, 1, 1, 48)                        240                  ['k_block6d__0se_reduce_i12[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6d__0se_reduce_c2_m12 (Activation)                 (None, 1, 1, 48)                        0                    ['k_block6d__0se_reduce_c2_m12_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6d__0se_reduce_iga (Add)                           (None, 1, 1, 48)                        0                    ['k_block6d__0se_reduce_c2_m12[0][0]',                      \n","                                                                                                                         'k_block6d__0se_reduce_c1_m48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6d__0se_expand_c1_m12_conv (Conv2D)                (None, 1, 1, 1152)                      5760                 ['k_block6d__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block6d__0se_expand_c1_m12 (Activation)                 (None, 1, 1, 1152)                      0                    ['k_block6d__0se_expand_c1_m12_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block6d__0se_excite (Multiply)                          (None, 7, 7, 1152)                      0                    ['k_block6d__0activation[0][0]',                            \n","                                                                                                                         'k_block6d__0se_expand_c1_m12[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6d__0project_conv_c1_m192_conv (Conv2D)            (None, 7, 7, 192)                       1152                 ['k_block6d__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block6d__0project_conv_c1_m192_bn (BatchNormalization)  (None, 7, 7, 192)                       768                  ['k_block6d__0project_conv_c1_m192_conv[0][0]']             \n","                                                                                                                                                                                    \n"," k_block6d__0project_conv_i48 (InterleaveChannels)         (None, 7, 7, 192)                       0                    ['k_block6d__0project_conv_c1_m192_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block6d__0project_conv_c2_m48_conv (Conv2D)             (None, 7, 7, 192)                       768                  ['k_block6d__0project_conv_i48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6d__0project_conv_c2_m48_bn (BatchNormalization)   (None, 7, 7, 192)                       768                  ['k_block6d__0project_conv_c2_m48_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block6d__0project_conv_iga (Add)                        (None, 7, 7, 192)                       0                    ['k_block6d__0project_conv_c2_m48_bn[0][0]',                \n","                                                                                                                         'k_block6d__0project_conv_c1_m192_bn[0][0]']               \n","                                                                                                                                                                                    \n"," k_block6d__0drop (Dropout)                                (None, 7, 7, 192)                       0                    ['k_block6d__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block6d__0add (Add)                                     (None, 7, 7, 192)                       0                    ['k_block6d__0drop[0][0]',                                  \n","                                                                                                                         'k_block6c__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block7a__0expand_c1_m48_conv (Conv2D)                   (None, 7, 7, 1152)                      4608                 ['k_block6d__0add[0][0]']                                   \n","                                                                                                                                                                                    \n"," k_block7a__0expand_c1_m48_bn (BatchNormalization)         (None, 7, 7, 1152)                      4608                 ['k_block7a__0expand_c1_m48_conv[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block7a__0expand_c1_m48 (Activation)                    (None, 7, 7, 1152)                      0                    ['k_block7a__0expand_c1_m48_bn[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block7a__0dwconv (DepthwiseConv2D)                      (None, 7, 7, 1152)                      10368                ['k_block7a__0expand_c1_m48[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block7a__0bn (BatchNormalization)                       (None, 7, 7, 1152)                      4608                 ['k_block7a__0dwconv[0][0]']                                \n","                                                                                                                                                                                    \n"," k_block7a__0activation (Activation)                       (None, 7, 7, 1152)                      0                    ['k_block7a__0bn[0][0]']                                    \n","                                                                                                                                                                                    \n"," k_block7a__0se_squeeze (GlobalAveragePooling2D)           (None, 1152)                            0                    ['k_block7a__0activation[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block7a__0se_reshape (Reshape)                          (None, 1, 1, 1152)                      0                    ['k_block7a__0se_squeeze[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block7a__0se_reduce_c1_m48_conv (Conv2D)                (None, 1, 1, 48)                        1200                 ['k_block7a__0se_reshape[0][0]']                            \n","                                                                                                                                                                                    \n"," k_block7a__0se_reduce_c1_m48 (Activation)                 (None, 1, 1, 48)                        0                    ['k_block7a__0se_reduce_c1_m48_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block7a__0se_reduce_i12 (InterleaveChannels)            (None, 1, 1, 48)                        0                    ['k_block7a__0se_reduce_c1_m48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block7a__0se_reduce_c2_m12_conv (Conv2D)                (None, 1, 1, 48)                        240                  ['k_block7a__0se_reduce_i12[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block7a__0se_reduce_c2_m12 (Activation)                 (None, 1, 1, 48)                        0                    ['k_block7a__0se_reduce_c2_m12_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block7a__0se_reduce_iga (Add)                           (None, 1, 1, 48)                        0                    ['k_block7a__0se_reduce_c2_m12[0][0]',                      \n","                                                                                                                         'k_block7a__0se_reduce_c1_m48[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block7a__0se_expand_c1_m12_conv (Conv2D)                (None, 1, 1, 1152)                      5760                 ['k_block7a__0se_reduce_iga[0][0]']                         \n","                                                                                                                                                                                    \n"," k_block7a__0se_expand_c1_m12 (Activation)                 (None, 1, 1, 1152)                      0                    ['k_block7a__0se_expand_c1_m12_conv[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block7a__0se_excite (Multiply)                          (None, 7, 7, 1152)                      0                    ['k_block7a__0activation[0][0]',                            \n","                                                                                                                         'k_block7a__0se_expand_c1_m12[0][0]']                      \n","                                                                                                                                                                                    \n"," copy_channels_14 (CopyChannels)                           (None, 7, 7, 128)                       0                    ['k_block7a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block7a__0project_conv_c1_p1_288_conv (Conv2D)          (None, 7, 7, 288)                       1152                 ['k_block7a__0se_excite[0][0]']                             \n","                                                                                                                                                                                    \n"," k_block7a__0project_conv_c1_p2_conv (Conv2D)              (None, 7, 7, 32)                        128                  ['copy_channels_14[0][0]']                                  \n","                                                                                                                                                                                    \n"," k_block7a__0project_conv_c1_p1_288_bn (BatchNormalization  (None, 7, 7, 288)                      1152                 ['k_block7a__0project_conv_c1_p1_288_conv[0][0]']           \n"," )                                                                                                                                                                                  \n","                                                                                                                                                                                    \n"," k_block7a__0project_conv_c1_p2_bn (BatchNormalization)    (None, 7, 7, 32)                        128                  ['k_block7a__0project_conv_c1_p2_conv[0][0]']               \n","                                                                                                                                                                                    \n"," k_block7a__0project_conv_c1_dc (Concatenate)              (None, 7, 7, 320)                       0                    ['k_block7a__0project_conv_c1_p1_288_bn[0][0]',             \n","                                                                                                                         'k_block7a__0project_conv_c1_p2_bn[0][0]']                 \n","                                                                                                                                                                                    \n"," k_block7a__0project_conv_i80 (InterleaveChannels)         (None, 7, 7, 320)                       0                    ['k_block7a__0project_conv_c1_dc[0][0]']                    \n","                                                                                                                                                                                    \n"," k_block7a__0project_conv_c2_m80_conv (Conv2D)             (None, 7, 7, 320)                       1280                 ['k_block7a__0project_conv_i80[0][0]']                      \n","                                                                                                                                                                                    \n"," k_block7a__0project_conv_c2_m80_bn (BatchNormalization)   (None, 7, 7, 320)                       1280                 ['k_block7a__0project_conv_c2_m80_conv[0][0]']              \n","                                                                                                                                                                                    \n"," k_block7a__0project_conv_iga (Add)                        (None, 7, 7, 320)                       0                    ['k_block7a__0project_conv_c2_m80_bn[0][0]',                \n","                                                                                                                         'k_block7a__0project_conv_c1_dc[0][0]']                    \n","                                                                                                                                                                                    \n"," k_top_conv_c1_m80_conv (Conv2D)                           (None, 7, 7, 1280)                      5120                 ['k_block7a__0project_conv_iga[0][0]']                      \n","                                                                                                                                                                                    \n"," k_top_conv_c1_m80_bn (BatchNormalization)                 (None, 7, 7, 1280)                      5120                 ['k_top_conv_c1_m80_conv[0][0]']                            \n","                                                                                                                                                                                    \n"," k_avg_pool (GlobalAveragePooling2D)                       (None, 1280)                            0                    ['k_top_conv_c1_m80_bn[0][0]']                              \n","                                                                                                                                                                                    \n"," k_top_dropout (Dropout)                                   (None, 1280)                            0                    ['k_avg_pool[0][0]']                                        \n","                                                                                                                                                                                    \n"," k_probs (Dense)                                           (None, 8)                               10248                ['k_top_dropout[0][0]']                                     \n","                                                                                                                                                                                    \n","====================================================================================================================================================================================\n","Total params: 397,888\n","Trainable params: 352,256\n","Non-trainable params: 45,632\n","____________________________________________________________________________________________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","model flops: 69699056\n","Finished: /content/drive/MyDrive/output/JP30N14-45\n"]}],"source":["work_on_keffnet(show_model=True, run_fit=False, test_results=False)"]},{"cell_type":"markdown","metadata":{"id":"x7RjCRzmxhce"},"source":["# Fitting"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"edbu3-Y6THos","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6a05fc56-9947-4dcc-a06b-4c3bafb64565","executionInfo":{"status":"ok","timestamp":1647403362955,"user_tz":180,"elapsed":234791,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running: /content/drive/MyDrive/output/JP30N14-45\n","Epoch 1/1000\n","63/63 [==============================] - ETA: 0s - loss: 2.0040 - accuracy: 0.4116\n","Epoch 1: val_loss improved from inf to 2.18867, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 83s 646ms/step - loss: 2.0040 - accuracy: 0.4116 - val_loss: 2.1887 - val_accuracy: 0.1250 - lr: 0.0010\n","Epoch 2/1000\n","63/63 [==============================] - ETA: 0s - loss: 1.5063 - accuracy: 0.5208\n","Epoch 2: val_loss did not improve from 2.18867\n","63/63 [==============================] - 28s 424ms/step - loss: 1.5063 - accuracy: 0.5208 - val_loss: 2.2840 - val_accuracy: 0.1250 - lr: 0.0015\n","Epoch 3/1000\n","63/63 [==============================] - ETA: 0s - loss: 1.2823 - accuracy: 0.5629\n","Epoch 3: val_loss did not improve from 2.18867\n","63/63 [==============================] - 28s 425ms/step - loss: 1.2823 - accuracy: 0.5629 - val_loss: 2.3487 - val_accuracy: 0.1250 - lr: 0.0020\n","Epoch 4/1000\n","63/63 [==============================] - ETA: 0s - loss: 1.1409 - accuracy: 0.6177\n","Epoch 4: val_loss did not improve from 2.18867\n","63/63 [==============================] - 29s 427ms/step - loss: 1.1409 - accuracy: 0.6177 - val_loss: 2.3325 - val_accuracy: 0.1250 - lr: 0.0025\n","Epoch 5/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.9825 - accuracy: 0.6423\n","Epoch 5: val_loss did not improve from 2.18867\n","63/63 [==============================] - 29s 425ms/step - loss: 0.9825 - accuracy: 0.6423 - val_loss: 2.4257 - val_accuracy: 0.1250 - lr: 0.0030\n","Epoch 6/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.9369 - accuracy: 0.6756\n","Epoch 6: val_loss did not improve from 2.18867\n","63/63 [==============================] - 28s 425ms/step - loss: 0.9369 - accuracy: 0.6756 - val_loss: 2.3816 - val_accuracy: 0.1250 - lr: 0.0035\n","Epoch 7/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.8798 - accuracy: 0.6851\n","Epoch 7: val_loss did not improve from 2.18867\n","63/63 [==============================] - 28s 424ms/step - loss: 0.8798 - accuracy: 0.6851 - val_loss: 3.2044 - val_accuracy: 0.1250 - lr: 0.0040\n","Epoch 8/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.8291 - accuracy: 0.7074\n","Epoch 8: val_loss did not improve from 2.18867\n","63/63 [==============================] - 29s 426ms/step - loss: 0.8291 - accuracy: 0.7074 - val_loss: 64.9061 - val_accuracy: 0.3934 - lr: 0.0040\n","Epoch 9/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7515\n","Epoch 9: val_loss did not improve from 2.18867\n","63/63 [==============================] - 29s 426ms/step - loss: 0.6764 - accuracy: 0.7515 - val_loss: 485.5677 - val_accuracy: 0.2054 - lr: 0.0034\n","Epoch 10/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.7610\n","Epoch 10: val_loss improved from 2.18867 to 2.00326, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 33s 476ms/step - loss: 0.6365 - accuracy: 0.7610 - val_loss: 2.0033 - val_accuracy: 0.5268 - lr: 0.0029\n","Epoch 11/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.7821\n","Epoch 11: val_loss did not improve from 2.00326\n","63/63 [==============================] - 29s 423ms/step - loss: 0.5942 - accuracy: 0.7821 - val_loss: 4.1465 - val_accuracy: 0.5074 - lr: 0.0025\n","Epoch 12/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.8134\n","Epoch 12: val_loss improved from 2.00326 to 0.89462, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 31s 478ms/step - loss: 0.5075 - accuracy: 0.8134 - val_loss: 0.8946 - val_accuracy: 0.7039 - lr: 0.0021\n","Epoch 13/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.8252\n","Epoch 13: val_loss did not improve from 0.89462\n","63/63 [==============================] - 29s 423ms/step - loss: 0.4761 - accuracy: 0.8252 - val_loss: 4.3547 - val_accuracy: 0.5000 - lr: 0.0018\n","Epoch 14/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.8379\n","Epoch 14: val_loss improved from 0.89462 to 0.87257, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 33s 480ms/step - loss: 0.4397 - accuracy: 0.8379 - val_loss: 0.8726 - val_accuracy: 0.7207 - lr: 0.0015\n","Epoch 15/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8505\n","Epoch 15: val_loss improved from 0.87257 to 0.57780, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 33s 479ms/step - loss: 0.4267 - accuracy: 0.8505 - val_loss: 0.5778 - val_accuracy: 0.7991 - lr: 0.0013\n","Epoch 16/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.8517\n","Epoch 16: val_loss did not improve from 0.57780\n","63/63 [==============================] - 29s 424ms/step - loss: 0.4357 - accuracy: 0.8517 - val_loss: 2.8917 - val_accuracy: 0.5615 - lr: 0.0011\n","Epoch 17/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8615\n","Epoch 17: val_loss improved from 0.57780 to 0.50437, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 33s 483ms/step - loss: 0.3838 - accuracy: 0.8615 - val_loss: 0.5044 - val_accuracy: 0.7837 - lr: 9.2647e-04\n","Epoch 18/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3928 - accuracy: 0.8660\n","Epoch 18: val_loss did not improve from 0.50437\n","63/63 [==============================] - 29s 426ms/step - loss: 0.3928 - accuracy: 0.8660 - val_loss: 0.7113 - val_accuracy: 0.7436 - lr: 7.8750e-04\n","Epoch 19/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.8587\n","Epoch 19: val_loss improved from 0.50437 to 0.42062, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 32s 477ms/step - loss: 0.3797 - accuracy: 0.8587 - val_loss: 0.4206 - val_accuracy: 0.8601 - lr: 6.6937e-04\n","Epoch 20/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8798\n","Epoch 20: val_loss improved from 0.42062 to 0.29410, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 32s 479ms/step - loss: 0.3608 - accuracy: 0.8798 - val_loss: 0.2941 - val_accuracy: 0.8963 - lr: 5.6897e-04\n","Epoch 21/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.8785\n","Epoch 21: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 424ms/step - loss: 0.3365 - accuracy: 0.8785 - val_loss: 0.4071 - val_accuracy: 0.8467 - lr: 4.8362e-04\n","Epoch 22/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.8828\n","Epoch 22: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 426ms/step - loss: 0.3454 - accuracy: 0.8828 - val_loss: 0.7922 - val_accuracy: 0.7396 - lr: 4.1108e-04\n","Epoch 23/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.8820\n","Epoch 23: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 427ms/step - loss: 0.3443 - accuracy: 0.8820 - val_loss: 0.7425 - val_accuracy: 0.7634 - lr: 3.4942e-04\n","Epoch 24/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.8830\n","Epoch 24: val_loss did not improve from 0.29410\n","63/63 [==============================] - 28s 423ms/step - loss: 0.3327 - accuracy: 0.8830 - val_loss: 0.7607 - val_accuracy: 0.7118 - lr: 2.9700e-04\n","Epoch 25/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3431 - accuracy: 0.8835\n","Epoch 25: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 427ms/step - loss: 0.3431 - accuracy: 0.8835 - val_loss: 0.3250 - val_accuracy: 0.8963 - lr: 2.5245e-04\n","Epoch 26/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.8750\n","Epoch 26: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 426ms/step - loss: 0.3512 - accuracy: 0.8750 - val_loss: 1.9087 - val_accuracy: 0.6260 - lr: 0.0010\n","Epoch 27/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.8685\n","Epoch 27: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 426ms/step - loss: 0.3784 - accuracy: 0.8685 - val_loss: 1.2725 - val_accuracy: 0.6979 - lr: 0.0015\n","Epoch 28/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.8552\n","Epoch 28: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 423ms/step - loss: 0.4043 - accuracy: 0.8552 - val_loss: 12.2385 - val_accuracy: 0.3854 - lr: 0.0020\n","Epoch 29/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.8497\n","Epoch 29: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 423ms/step - loss: 0.4343 - accuracy: 0.8497 - val_loss: 80.8177 - val_accuracy: 0.4797 - lr: 0.0025\n","Epoch 30/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.8424\n","Epoch 30: val_loss did not improve from 0.29410\n","63/63 [==============================] - 28s 426ms/step - loss: 0.4782 - accuracy: 0.8424 - val_loss: 114.4632 - val_accuracy: 0.3953 - lr: 0.0030\n","Epoch 31/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.8327\n","Epoch 31: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 425ms/step - loss: 0.4725 - accuracy: 0.8327 - val_loss: 1.8066 - val_accuracy: 0.5714 - lr: 0.0035\n","Epoch 32/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8229\n","Epoch 32: val_loss did not improve from 0.29410\n","63/63 [==============================] - 30s 425ms/step - loss: 0.5057 - accuracy: 0.8229 - val_loss: 145.0430 - val_accuracy: 0.4172 - lr: 0.0040\n","Epoch 33/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.8257\n","Epoch 33: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 423ms/step - loss: 0.4818 - accuracy: 0.8257 - val_loss: 599.6942 - val_accuracy: 0.1994 - lr: 0.0040\n","Epoch 34/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.8379\n","Epoch 34: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 426ms/step - loss: 0.4503 - accuracy: 0.8379 - val_loss: 278.7394 - val_accuracy: 0.4559 - lr: 0.0034\n","Epoch 35/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8615\n","Epoch 35: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 425ms/step - loss: 0.3856 - accuracy: 0.8615 - val_loss: 46.9722 - val_accuracy: 0.4782 - lr: 0.0029\n","Epoch 36/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.8667\n","Epoch 36: val_loss did not improve from 0.29410\n","63/63 [==============================] - 28s 422ms/step - loss: 0.3667 - accuracy: 0.8667 - val_loss: 4.4001 - val_accuracy: 0.5565 - lr: 0.0025\n","Epoch 37/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.8800\n","Epoch 37: val_loss did not improve from 0.29410\n","63/63 [==============================] - 28s 425ms/step - loss: 0.3507 - accuracy: 0.8800 - val_loss: 1.3761 - val_accuracy: 0.5888 - lr: 0.0021\n","Epoch 38/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3525 - accuracy: 0.8785\n","Epoch 38: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 426ms/step - loss: 0.3525 - accuracy: 0.8785 - val_loss: 1.0059 - val_accuracy: 0.7217 - lr: 0.0018\n","Epoch 39/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.8888\n","Epoch 39: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 427ms/step - loss: 0.3241 - accuracy: 0.8888 - val_loss: 0.5547 - val_accuracy: 0.8189 - lr: 0.0015\n","Epoch 40/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.8868\n","Epoch 40: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 425ms/step - loss: 0.3173 - accuracy: 0.8868 - val_loss: 0.3682 - val_accuracy: 0.8681 - lr: 0.0013\n","Epoch 41/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.9023\n","Epoch 41: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 428ms/step - loss: 0.2847 - accuracy: 0.9023 - val_loss: 1.8583 - val_accuracy: 0.6151 - lr: 0.0011\n","Epoch 42/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2884 - accuracy: 0.8978\n","Epoch 42: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2884 - accuracy: 0.8978 - val_loss: 0.9681 - val_accuracy: 0.6677 - lr: 9.2647e-04\n","Epoch 43/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.9023\n","Epoch 43: val_loss did not improve from 0.29410\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2637 - accuracy: 0.9023 - val_loss: 0.7474 - val_accuracy: 0.7411 - lr: 7.8750e-04\n","Epoch 44/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2727 - accuracy: 0.9088\n","Epoch 44: val_loss improved from 0.29410 to 0.25283, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 32s 482ms/step - loss: 0.2727 - accuracy: 0.9088 - val_loss: 0.2528 - val_accuracy: 0.9058 - lr: 6.6937e-04\n","Epoch 45/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.9096\n","Epoch 45: val_loss improved from 0.25283 to 0.23164, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 32s 479ms/step - loss: 0.2536 - accuracy: 0.9096 - val_loss: 0.2316 - val_accuracy: 0.9152 - lr: 5.6897e-04\n","Epoch 46/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.9091\n","Epoch 46: val_loss did not improve from 0.23164\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2614 - accuracy: 0.9091 - val_loss: 0.2600 - val_accuracy: 0.9013 - lr: 4.8362e-04\n","Epoch 47/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.9111\n","Epoch 47: val_loss did not improve from 0.23164\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2555 - accuracy: 0.9111 - val_loss: 0.7879 - val_accuracy: 0.7738 - lr: 4.1108e-04\n","Epoch 48/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.9161\n","Epoch 48: val_loss improved from 0.23164 to 0.21935, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 31s 479ms/step - loss: 0.2494 - accuracy: 0.9161 - val_loss: 0.2193 - val_accuracy: 0.9206 - lr: 3.4942e-04\n","Epoch 49/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9201\n","Epoch 49: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2232 - accuracy: 0.9201 - val_loss: 0.2363 - val_accuracy: 0.9107 - lr: 2.9700e-04\n","Epoch 50/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.9131\n","Epoch 50: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 427ms/step - loss: 0.2355 - accuracy: 0.9131 - val_loss: 0.2224 - val_accuracy: 0.9211 - lr: 2.5245e-04\n","Epoch 51/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.9076\n","Epoch 51: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 424ms/step - loss: 0.2600 - accuracy: 0.9076 - val_loss: 0.8928 - val_accuracy: 0.6964 - lr: 0.0010\n","Epoch 52/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.8995\n","Epoch 52: val_loss did not improve from 0.21935\n","63/63 [==============================] - 28s 424ms/step - loss: 0.2867 - accuracy: 0.8995 - val_loss: 0.5218 - val_accuracy: 0.7569 - lr: 0.0015\n","Epoch 53/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.8933\n","Epoch 53: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 427ms/step - loss: 0.3121 - accuracy: 0.8933 - val_loss: 4.8292 - val_accuracy: 0.5898 - lr: 0.0020\n","Epoch 54/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.8835\n","Epoch 54: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 426ms/step - loss: 0.3466 - accuracy: 0.8835 - val_loss: 0.2966 - val_accuracy: 0.8988 - lr: 0.0025\n","Epoch 55/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3625 - accuracy: 0.8778\n","Epoch 55: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 424ms/step - loss: 0.3625 - accuracy: 0.8778 - val_loss: 1.1158 - val_accuracy: 0.6453 - lr: 0.0030\n","Epoch 56/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3625 - accuracy: 0.8760\n","Epoch 56: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 423ms/step - loss: 0.3625 - accuracy: 0.8760 - val_loss: 1.1115 - val_accuracy: 0.7118 - lr: 0.0035\n","Epoch 57/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.8715\n","Epoch 57: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 426ms/step - loss: 0.3702 - accuracy: 0.8715 - val_loss: 5.3902 - val_accuracy: 0.5164 - lr: 0.0040\n","Epoch 58/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3708 - accuracy: 0.8720\n","Epoch 58: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 424ms/step - loss: 0.3708 - accuracy: 0.8720 - val_loss: 13.9158 - val_accuracy: 0.4469 - lr: 0.0040\n","Epoch 59/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8815\n","Epoch 59: val_loss did not improve from 0.21935\n","63/63 [==============================] - 28s 427ms/step - loss: 0.3579 - accuracy: 0.8815 - val_loss: 2.0975 - val_accuracy: 0.5813 - lr: 0.0034\n","Epoch 60/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 0.8903\n","Epoch 60: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 425ms/step - loss: 0.3120 - accuracy: 0.8903 - val_loss: 4.4054 - val_accuracy: 0.5665 - lr: 0.0029\n","Epoch 61/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.8940\n","Epoch 61: val_loss did not improve from 0.21935\n","63/63 [==============================] - 28s 425ms/step - loss: 0.3030 - accuracy: 0.8940 - val_loss: 0.3689 - val_accuracy: 0.8814 - lr: 0.0025\n","Epoch 62/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.9051\n","Epoch 62: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 424ms/step - loss: 0.2740 - accuracy: 0.9051 - val_loss: 2.0444 - val_accuracy: 0.6096 - lr: 0.0021\n","Epoch 63/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.9106\n","Epoch 63: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 427ms/step - loss: 0.2642 - accuracy: 0.9106 - val_loss: 0.6326 - val_accuracy: 0.7257 - lr: 0.0018\n","Epoch 64/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9146\n","Epoch 64: val_loss did not improve from 0.21935\n","63/63 [==============================] - 28s 425ms/step - loss: 0.2449 - accuracy: 0.9146 - val_loss: 0.6596 - val_accuracy: 0.8363 - lr: 0.0015\n","Epoch 65/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.9133\n","Epoch 65: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 427ms/step - loss: 0.2513 - accuracy: 0.9133 - val_loss: 0.6403 - val_accuracy: 0.7381 - lr: 0.0013\n","Epoch 66/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.9233\n","Epoch 66: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2365 - accuracy: 0.9233 - val_loss: 0.6295 - val_accuracy: 0.7718 - lr: 0.0011\n","Epoch 67/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9231\n","Epoch 67: val_loss did not improve from 0.21935\n","63/63 [==============================] - 28s 427ms/step - loss: 0.2125 - accuracy: 0.9231 - val_loss: 0.4840 - val_accuracy: 0.8080 - lr: 9.2647e-04\n","Epoch 68/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9269\n","Epoch 68: val_loss did not improve from 0.21935\n","63/63 [==============================] - 30s 429ms/step - loss: 0.2212 - accuracy: 0.9269 - val_loss: 0.2798 - val_accuracy: 0.9038 - lr: 7.8750e-04\n","Epoch 69/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.9216\n","Epoch 69: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 428ms/step - loss: 0.2268 - accuracy: 0.9216 - val_loss: 0.5372 - val_accuracy: 0.7614 - lr: 6.6937e-04\n","Epoch 70/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.9236\n","Epoch 70: val_loss did not improve from 0.21935\n","63/63 [==============================] - 28s 425ms/step - loss: 0.2041 - accuracy: 0.9236 - val_loss: 0.2951 - val_accuracy: 0.8983 - lr: 5.6897e-04\n","Epoch 71/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1944 - accuracy: 0.9331\n","Epoch 71: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 427ms/step - loss: 0.1944 - accuracy: 0.9331 - val_loss: 0.3652 - val_accuracy: 0.8418 - lr: 4.8362e-04\n","Epoch 72/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9274\n","Epoch 72: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 426ms/step - loss: 0.2005 - accuracy: 0.9274 - val_loss: 0.5089 - val_accuracy: 0.8140 - lr: 4.1108e-04\n","Epoch 73/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9339\n","Epoch 73: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1946 - accuracy: 0.9339 - val_loss: 0.3305 - val_accuracy: 0.8894 - lr: 3.4942e-04\n","Epoch 74/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.9266\n","Epoch 74: val_loss did not improve from 0.21935\n","63/63 [==============================] - 29s 427ms/step - loss: 0.2038 - accuracy: 0.9266 - val_loss: 0.3264 - val_accuracy: 0.9092 - lr: 2.9700e-04\n","Epoch 75/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1849 - accuracy: 0.9414\n","Epoch 75: val_loss improved from 0.21935 to 0.15040, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 32s 473ms/step - loss: 0.1849 - accuracy: 0.9414 - val_loss: 0.1504 - val_accuracy: 0.9449 - lr: 2.5245e-04\n","Epoch 76/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.9246\n","Epoch 76: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.2111 - accuracy: 0.9246 - val_loss: 0.2651 - val_accuracy: 0.9082 - lr: 0.0010\n","Epoch 77/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9196\n","Epoch 77: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2246 - accuracy: 0.9196 - val_loss: 1.7419 - val_accuracy: 0.6225 - lr: 0.0015\n","Epoch 78/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9208\n","Epoch 78: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 427ms/step - loss: 0.2346 - accuracy: 0.9208 - val_loss: 0.9342 - val_accuracy: 0.7217 - lr: 0.0020\n","Epoch 79/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.9128\n","Epoch 79: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 424ms/step - loss: 0.2563 - accuracy: 0.9128 - val_loss: 2.2889 - val_accuracy: 0.6513 - lr: 0.0025\n","Epoch 80/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.9018\n","Epoch 80: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 427ms/step - loss: 0.2827 - accuracy: 0.9018 - val_loss: 15.5414 - val_accuracy: 0.5005 - lr: 0.0030\n","Epoch 81/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 0.9033\n","Epoch 81: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2919 - accuracy: 0.9033 - val_loss: 2.8176 - val_accuracy: 0.5689 - lr: 0.0035\n","Epoch 82/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8830\n","Epoch 82: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 425ms/step - loss: 0.3312 - accuracy: 0.8830 - val_loss: 0.7665 - val_accuracy: 0.8160 - lr: 0.0040\n","Epoch 83/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.8975\n","Epoch 83: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 451ms/step - loss: 0.2948 - accuracy: 0.8975 - val_loss: 22.3862 - val_accuracy: 0.4058 - lr: 0.0040\n","Epoch 84/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.9041\n","Epoch 84: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.2813 - accuracy: 0.9041 - val_loss: 0.7631 - val_accuracy: 0.7966 - lr: 0.0034\n","Epoch 85/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.9041\n","Epoch 85: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 422ms/step - loss: 0.2827 - accuracy: 0.9041 - val_loss: 1.2898 - val_accuracy: 0.7312 - lr: 0.0029\n","Epoch 86/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9156\n","Epoch 86: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 426ms/step - loss: 0.2383 - accuracy: 0.9156 - val_loss: 0.5213 - val_accuracy: 0.8547 - lr: 0.0025\n","Epoch 87/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9176\n","Epoch 87: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2394 - accuracy: 0.9176 - val_loss: 1.2009 - val_accuracy: 0.6741 - lr: 0.0021\n","Epoch 88/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9203\n","Epoch 88: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 425ms/step - loss: 0.2348 - accuracy: 0.9203 - val_loss: 0.7198 - val_accuracy: 0.8413 - lr: 0.0018\n","Epoch 89/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9279\n","Epoch 89: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 426ms/step - loss: 0.1951 - accuracy: 0.9279 - val_loss: 0.7126 - val_accuracy: 0.7857 - lr: 0.0015\n","Epoch 90/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.9259\n","Epoch 90: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 427ms/step - loss: 0.2067 - accuracy: 0.9259 - val_loss: 2.0503 - val_accuracy: 0.6349 - lr: 0.0013\n","Epoch 91/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1895 - accuracy: 0.9324\n","Epoch 91: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1895 - accuracy: 0.9324 - val_loss: 1.2973 - val_accuracy: 0.6523 - lr: 0.0011\n","Epoch 92/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9299\n","Epoch 92: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1972 - accuracy: 0.9299 - val_loss: 1.6418 - val_accuracy: 0.7520 - lr: 9.2647e-04\n","Epoch 93/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9324\n","Epoch 93: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1896 - accuracy: 0.9324 - val_loss: 0.1840 - val_accuracy: 0.9340 - lr: 7.8750e-04\n","Epoch 94/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.9411\n","Epoch 94: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 427ms/step - loss: 0.1812 - accuracy: 0.9411 - val_loss: 0.2560 - val_accuracy: 0.9082 - lr: 6.6937e-04\n","Epoch 95/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.9431\n","Epoch 95: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.1687 - accuracy: 0.9431 - val_loss: 0.1832 - val_accuracy: 0.9311 - lr: 5.6897e-04\n","Epoch 96/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9376\n","Epoch 96: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1860 - accuracy: 0.9376 - val_loss: 0.2721 - val_accuracy: 0.9147 - lr: 4.8362e-04\n","Epoch 97/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9439\n","Epoch 97: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1628 - accuracy: 0.9439 - val_loss: 0.2748 - val_accuracy: 0.9077 - lr: 4.1108e-04\n","Epoch 98/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9449\n","Epoch 98: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1620 - accuracy: 0.9449 - val_loss: 0.4602 - val_accuracy: 0.8264 - lr: 3.4942e-04\n","Epoch 99/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.9431\n","Epoch 99: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 427ms/step - loss: 0.1631 - accuracy: 0.9431 - val_loss: 0.2263 - val_accuracy: 0.9241 - lr: 2.9700e-04\n","Epoch 100/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9449\n","Epoch 100: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 427ms/step - loss: 0.1647 - accuracy: 0.9449 - val_loss: 0.1907 - val_accuracy: 0.9330 - lr: 2.5245e-04\n","Epoch 101/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.9399\n","Epoch 101: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 429ms/step - loss: 0.1819 - accuracy: 0.9399 - val_loss: 0.3053 - val_accuracy: 0.8899 - lr: 0.0010\n","Epoch 102/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9346\n","Epoch 102: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1860 - accuracy: 0.9346 - val_loss: 1.8865 - val_accuracy: 0.7614 - lr: 0.0015\n","Epoch 103/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9274\n","Epoch 103: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 428ms/step - loss: 0.2209 - accuracy: 0.9274 - val_loss: 0.5825 - val_accuracy: 0.8358 - lr: 0.0020\n","Epoch 104/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9233\n","Epoch 104: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 427ms/step - loss: 0.2228 - accuracy: 0.9233 - val_loss: 12.7973 - val_accuracy: 0.5908 - lr: 0.0025\n","Epoch 105/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9191\n","Epoch 105: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 428ms/step - loss: 0.2408 - accuracy: 0.9191 - val_loss: 16.0552 - val_accuracy: 0.6443 - lr: 0.0030\n","Epoch 106/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.9126\n","Epoch 106: val_loss did not improve from 0.15040\n","63/63 [==============================] - 30s 429ms/step - loss: 0.2576 - accuracy: 0.9126 - val_loss: 23.4890 - val_accuracy: 0.4340 - lr: 0.0035\n","Epoch 107/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2734 - accuracy: 0.9058\n","Epoch 107: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2734 - accuracy: 0.9058 - val_loss: 0.8866 - val_accuracy: 0.8229 - lr: 0.0040\n","Epoch 108/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2871 - accuracy: 0.9086\n","Epoch 108: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 423ms/step - loss: 0.2871 - accuracy: 0.9086 - val_loss: 6.2283 - val_accuracy: 0.4970 - lr: 0.0040\n","Epoch 109/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.9161\n","Epoch 109: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 429ms/step - loss: 0.2470 - accuracy: 0.9161 - val_loss: 62.4081 - val_accuracy: 0.4712 - lr: 0.0034\n","Epoch 110/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.9191\n","Epoch 110: val_loss did not improve from 0.15040\n","63/63 [==============================] - 30s 429ms/step - loss: 0.2424 - accuracy: 0.9191 - val_loss: 18.1674 - val_accuracy: 0.6062 - lr: 0.0029\n","Epoch 111/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9201\n","Epoch 111: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.2234 - accuracy: 0.9201 - val_loss: 6.1765 - val_accuracy: 0.5744 - lr: 0.0025\n","Epoch 112/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1902 - accuracy: 0.9319\n","Epoch 112: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 428ms/step - loss: 0.1902 - accuracy: 0.9319 - val_loss: 1.3954 - val_accuracy: 0.6424 - lr: 0.0021\n","Epoch 113/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9291\n","Epoch 113: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.2151 - accuracy: 0.9291 - val_loss: 1.1143 - val_accuracy: 0.6791 - lr: 0.0018\n","Epoch 114/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9381\n","Epoch 114: val_loss did not improve from 0.15040\n","63/63 [==============================] - 30s 427ms/step - loss: 0.1830 - accuracy: 0.9381 - val_loss: 2.4908 - val_accuracy: 0.6806 - lr: 0.0015\n","Epoch 115/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9399\n","Epoch 115: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1776 - accuracy: 0.9399 - val_loss: 0.9788 - val_accuracy: 0.7192 - lr: 0.0013\n","Epoch 116/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9386\n","Epoch 116: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1659 - accuracy: 0.9386 - val_loss: 1.8919 - val_accuracy: 0.6270 - lr: 0.0011\n","Epoch 117/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9354\n","Epoch 117: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1880 - accuracy: 0.9354 - val_loss: 1.4138 - val_accuracy: 0.7817 - lr: 9.2647e-04\n","Epoch 118/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9499\n","Epoch 118: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 427ms/step - loss: 0.1501 - accuracy: 0.9499 - val_loss: 0.2400 - val_accuracy: 0.9231 - lr: 7.8750e-04\n","Epoch 119/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9466\n","Epoch 119: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1627 - accuracy: 0.9466 - val_loss: 0.2065 - val_accuracy: 0.9147 - lr: 6.6937e-04\n","Epoch 120/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9471\n","Epoch 120: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1402 - accuracy: 0.9471 - val_loss: 0.4663 - val_accuracy: 0.7793 - lr: 5.6897e-04\n","Epoch 121/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9504\n","Epoch 121: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1396 - accuracy: 0.9504 - val_loss: 0.3064 - val_accuracy: 0.8661 - lr: 4.8362e-04\n","Epoch 122/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.9464\n","Epoch 122: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 426ms/step - loss: 0.1420 - accuracy: 0.9464 - val_loss: 0.6304 - val_accuracy: 0.7574 - lr: 4.1108e-04\n","Epoch 123/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9491\n","Epoch 123: val_loss did not improve from 0.15040\n","63/63 [==============================] - 30s 428ms/step - loss: 0.1363 - accuracy: 0.9491 - val_loss: 0.2394 - val_accuracy: 0.9023 - lr: 3.4942e-04\n","Epoch 124/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9569\n","Epoch 124: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 427ms/step - loss: 0.1347 - accuracy: 0.9569 - val_loss: 0.2284 - val_accuracy: 0.9251 - lr: 2.9700e-04\n","Epoch 125/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9512\n","Epoch 125: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1418 - accuracy: 0.9512 - val_loss: 0.1722 - val_accuracy: 0.9385 - lr: 2.5245e-04\n","Epoch 126/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1597 - accuracy: 0.9461\n","Epoch 126: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 427ms/step - loss: 0.1597 - accuracy: 0.9461 - val_loss: 0.4634 - val_accuracy: 0.8576 - lr: 0.0010\n","Epoch 127/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.9406\n","Epoch 127: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 427ms/step - loss: 0.1666 - accuracy: 0.9406 - val_loss: 0.3566 - val_accuracy: 0.8869 - lr: 0.0015\n","Epoch 128/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.9391\n","Epoch 128: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.1736 - accuracy: 0.9391 - val_loss: 0.3719 - val_accuracy: 0.8790 - lr: 0.0020\n","Epoch 129/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.9259\n","Epoch 129: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 424ms/step - loss: 0.2145 - accuracy: 0.9259 - val_loss: 0.4044 - val_accuracy: 0.8656 - lr: 0.0025\n","Epoch 130/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9254\n","Epoch 130: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2114 - accuracy: 0.9254 - val_loss: 30.3057 - val_accuracy: 0.4886 - lr: 0.0030\n","Epoch 131/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9176\n","Epoch 131: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 424ms/step - loss: 0.2261 - accuracy: 0.9176 - val_loss: 0.6224 - val_accuracy: 0.8244 - lr: 0.0035\n","Epoch 132/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2519 - accuracy: 0.9178\n","Epoch 132: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 426ms/step - loss: 0.2519 - accuracy: 0.9178 - val_loss: 67.5614 - val_accuracy: 0.4727 - lr: 0.0040\n","Epoch 133/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.9131\n","Epoch 133: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.2433 - accuracy: 0.9131 - val_loss: 3.7999 - val_accuracy: 0.6811 - lr: 0.0040\n","Epoch 134/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9176\n","Epoch 134: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 426ms/step - loss: 0.2252 - accuracy: 0.9176 - val_loss: 20.0478 - val_accuracy: 0.5957 - lr: 0.0034\n","Epoch 135/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.9344\n","Epoch 135: val_loss did not improve from 0.15040\n","63/63 [==============================] - 30s 426ms/step - loss: 0.2047 - accuracy: 0.9344 - val_loss: 1.4671 - val_accuracy: 0.6404 - lr: 0.0029\n","Epoch 136/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9329\n","Epoch 136: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.1888 - accuracy: 0.9329 - val_loss: 0.3798 - val_accuracy: 0.8993 - lr: 0.0025\n","Epoch 137/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9314\n","Epoch 137: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1899 - accuracy: 0.9314 - val_loss: 37.3683 - val_accuracy: 0.6255 - lr: 0.0021\n","Epoch 138/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9399\n","Epoch 138: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 429ms/step - loss: 0.1690 - accuracy: 0.9399 - val_loss: 2.4047 - val_accuracy: 0.6582 - lr: 0.0018\n","Epoch 139/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9406\n","Epoch 139: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.1655 - accuracy: 0.9406 - val_loss: 0.9683 - val_accuracy: 0.7237 - lr: 0.0015\n","Epoch 140/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9439\n","Epoch 140: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.1663 - accuracy: 0.9439 - val_loss: 1.4610 - val_accuracy: 0.6468 - lr: 0.0013\n","Epoch 141/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.9449\n","Epoch 141: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 447ms/step - loss: 0.1588 - accuracy: 0.9449 - val_loss: 0.9149 - val_accuracy: 0.6587 - lr: 0.0011\n","Epoch 142/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.9484\n","Epoch 142: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 425ms/step - loss: 0.1510 - accuracy: 0.9484 - val_loss: 0.3558 - val_accuracy: 0.8725 - lr: 9.2647e-04\n","Epoch 143/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9504\n","Epoch 143: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 428ms/step - loss: 0.1368 - accuracy: 0.9504 - val_loss: 0.4837 - val_accuracy: 0.8254 - lr: 7.8750e-04\n","Epoch 144/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9527\n","Epoch 144: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1332 - accuracy: 0.9527 - val_loss: 0.2439 - val_accuracy: 0.9048 - lr: 6.6937e-04\n","Epoch 145/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9539\n","Epoch 145: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 426ms/step - loss: 0.1359 - accuracy: 0.9539 - val_loss: 0.5860 - val_accuracy: 0.7917 - lr: 5.6897e-04\n","Epoch 146/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9491\n","Epoch 146: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1405 - accuracy: 0.9491 - val_loss: 1.5731 - val_accuracy: 0.6885 - lr: 4.8362e-04\n","Epoch 147/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9534\n","Epoch 147: val_loss did not improve from 0.15040\n","63/63 [==============================] - 29s 421ms/step - loss: 0.1339 - accuracy: 0.9534 - val_loss: 0.1892 - val_accuracy: 0.9325 - lr: 4.1108e-04\n","Epoch 148/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9594\n","Epoch 148: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1194 - accuracy: 0.9594 - val_loss: 0.1777 - val_accuracy: 0.9340 - lr: 3.4942e-04\n","Epoch 149/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9569\n","Epoch 149: val_loss did not improve from 0.15040\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1294 - accuracy: 0.9569 - val_loss: 0.1512 - val_accuracy: 0.9464 - lr: 2.9700e-04\n","Epoch 150/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9522\n","Epoch 150: val_loss improved from 0.15040 to 0.13322, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 32s 478ms/step - loss: 0.1281 - accuracy: 0.9522 - val_loss: 0.1332 - val_accuracy: 0.9514 - lr: 2.5245e-04\n","Epoch 151/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.9534\n","Epoch 151: val_loss did not improve from 0.13322\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1354 - accuracy: 0.9534 - val_loss: 0.1459 - val_accuracy: 0.9410 - lr: 0.0010\n","Epoch 152/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.9544\n","Epoch 152: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1440 - accuracy: 0.9544 - val_loss: 0.2972 - val_accuracy: 0.8998 - lr: 0.0015\n","Epoch 153/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9399\n","Epoch 153: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1676 - accuracy: 0.9399 - val_loss: 1.1837 - val_accuracy: 0.8145 - lr: 0.0020\n","Epoch 154/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1868 - accuracy: 0.9376\n","Epoch 154: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1868 - accuracy: 0.9376 - val_loss: 74.7000 - val_accuracy: 0.5496 - lr: 0.0025\n","Epoch 155/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.9364\n","Epoch 155: val_loss did not improve from 0.13322\n","63/63 [==============================] - 29s 425ms/step - loss: 0.1901 - accuracy: 0.9364 - val_loss: 17.8843 - val_accuracy: 0.5982 - lr: 0.0030\n","Epoch 156/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.9354\n","Epoch 156: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 422ms/step - loss: 0.2039 - accuracy: 0.9354 - val_loss: 86.5843 - val_accuracy: 0.5823 - lr: 0.0035\n","Epoch 157/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.9243\n","Epoch 157: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 422ms/step - loss: 0.2215 - accuracy: 0.9243 - val_loss: 63.3520 - val_accuracy: 0.5809 - lr: 0.0040\n","Epoch 158/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.9198\n","Epoch 158: val_loss did not improve from 0.13322\n","63/63 [==============================] - 29s 423ms/step - loss: 0.2263 - accuracy: 0.9198 - val_loss: 3.6683 - val_accuracy: 0.5233 - lr: 0.0040\n","Epoch 159/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.9284\n","Epoch 159: val_loss did not improve from 0.13322\n","63/63 [==============================] - 29s 429ms/step - loss: 0.2046 - accuracy: 0.9284 - val_loss: 0.4499 - val_accuracy: 0.8562 - lr: 0.0034\n","Epoch 160/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9421\n","Epoch 160: val_loss did not improve from 0.13322\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1755 - accuracy: 0.9421 - val_loss: 1.9689 - val_accuracy: 0.7525 - lr: 0.0029\n","Epoch 161/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9399\n","Epoch 161: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1798 - accuracy: 0.9399 - val_loss: 1.7436 - val_accuracy: 0.7679 - lr: 0.0025\n","Epoch 162/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9449\n","Epoch 162: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1694 - accuracy: 0.9449 - val_loss: 0.3245 - val_accuracy: 0.8864 - lr: 0.0021\n","Epoch 163/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9476\n","Epoch 163: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 428ms/step - loss: 0.1530 - accuracy: 0.9476 - val_loss: 1.2960 - val_accuracy: 0.6582 - lr: 0.0018\n","Epoch 164/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9431\n","Epoch 164: val_loss did not improve from 0.13322\n","63/63 [==============================] - 29s 421ms/step - loss: 0.1591 - accuracy: 0.9431 - val_loss: 0.2848 - val_accuracy: 0.9117 - lr: 0.0015\n","Epoch 165/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9562\n","Epoch 165: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1284 - accuracy: 0.9562 - val_loss: 1.4859 - val_accuracy: 0.7753 - lr: 0.0013\n","Epoch 166/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1287 - accuracy: 0.9517\n","Epoch 166: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1287 - accuracy: 0.9517 - val_loss: 1.0901 - val_accuracy: 0.7614 - lr: 0.0011\n","Epoch 167/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9539\n","Epoch 167: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 426ms/step - loss: 0.1320 - accuracy: 0.9539 - val_loss: 2.0122 - val_accuracy: 0.8720 - lr: 9.2647e-04\n","Epoch 168/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9577\n","Epoch 168: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1134 - accuracy: 0.9577 - val_loss: 0.9209 - val_accuracy: 0.7927 - lr: 7.8750e-04\n","Epoch 169/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9579\n","Epoch 169: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1196 - accuracy: 0.9579 - val_loss: 0.2541 - val_accuracy: 0.9157 - lr: 6.6937e-04\n","Epoch 170/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.9584\n","Epoch 170: val_loss did not improve from 0.13322\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1201 - accuracy: 0.9584 - val_loss: 0.1837 - val_accuracy: 0.9449 - lr: 5.6897e-04\n","Epoch 171/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9592\n","Epoch 171: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1128 - accuracy: 0.9592 - val_loss: 0.2570 - val_accuracy: 0.9182 - lr: 4.8362e-04\n","Epoch 172/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9587\n","Epoch 172: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1162 - accuracy: 0.9587 - val_loss: 0.1700 - val_accuracy: 0.9425 - lr: 4.1108e-04\n","Epoch 173/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9589\n","Epoch 173: val_loss did not improve from 0.13322\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1188 - accuracy: 0.9589 - val_loss: 0.1377 - val_accuracy: 0.9534 - lr: 3.4942e-04\n","Epoch 174/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.9582\n","Epoch 174: val_loss improved from 0.13322 to 0.10965, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 31s 473ms/step - loss: 0.1109 - accuracy: 0.9582 - val_loss: 0.1097 - val_accuracy: 0.9534 - lr: 2.9700e-04\n","Epoch 175/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9577\n","Epoch 175: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1112 - accuracy: 0.9577 - val_loss: 0.1453 - val_accuracy: 0.9435 - lr: 2.5245e-04\n","Epoch 176/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9572\n","Epoch 176: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1236 - accuracy: 0.9572 - val_loss: 2.1732 - val_accuracy: 0.7842 - lr: 0.0010\n","Epoch 177/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9539\n","Epoch 177: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1327 - accuracy: 0.9539 - val_loss: 2.2899 - val_accuracy: 0.8244 - lr: 0.0015\n","Epoch 178/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9481\n","Epoch 178: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1485 - accuracy: 0.9481 - val_loss: 22.0571 - val_accuracy: 0.6285 - lr: 0.0020\n","Epoch 179/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9479\n","Epoch 179: val_loss did not improve from 0.10965\n","63/63 [==============================] - 29s 427ms/step - loss: 0.1592 - accuracy: 0.9479 - val_loss: 2.8170 - val_accuracy: 0.6126 - lr: 0.0025\n","Epoch 180/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9334\n","Epoch 180: val_loss did not improve from 0.10965\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1919 - accuracy: 0.9334 - val_loss: 5.4840 - val_accuracy: 0.5789 - lr: 0.0030\n","Epoch 181/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9344\n","Epoch 181: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1873 - accuracy: 0.9344 - val_loss: 1.3693 - val_accuracy: 0.7396 - lr: 0.0035\n","Epoch 182/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9366\n","Epoch 182: val_loss did not improve from 0.10965\n","63/63 [==============================] - 30s 461ms/step - loss: 0.1935 - accuracy: 0.9366 - val_loss: 1.4462 - val_accuracy: 0.7272 - lr: 0.0040\n","Epoch 183/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.9319\n","Epoch 183: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 421ms/step - loss: 0.2001 - accuracy: 0.9319 - val_loss: 35.0099 - val_accuracy: 0.5536 - lr: 0.0040\n","Epoch 184/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9336\n","Epoch 184: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1841 - accuracy: 0.9336 - val_loss: 26.4101 - val_accuracy: 0.4678 - lr: 0.0034\n","Epoch 185/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1716 - accuracy: 0.9451\n","Epoch 185: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1716 - accuracy: 0.9451 - val_loss: 0.3309 - val_accuracy: 0.8829 - lr: 0.0029\n","Epoch 186/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9399\n","Epoch 186: val_loss did not improve from 0.10965\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1781 - accuracy: 0.9399 - val_loss: 2.2669 - val_accuracy: 0.5432 - lr: 0.0025\n","Epoch 187/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.9454\n","Epoch 187: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 433ms/step - loss: 0.1502 - accuracy: 0.9454 - val_loss: 2.0067 - val_accuracy: 0.6429 - lr: 0.0021\n","Epoch 188/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9552\n","Epoch 188: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 419ms/step - loss: 0.1320 - accuracy: 0.9552 - val_loss: 0.3237 - val_accuracy: 0.8914 - lr: 0.0018\n","Epoch 189/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9542\n","Epoch 189: val_loss did not improve from 0.10965\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1383 - accuracy: 0.9542 - val_loss: 0.2269 - val_accuracy: 0.9266 - lr: 0.0015\n","Epoch 190/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9559\n","Epoch 190: val_loss did not improve from 0.10965\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1312 - accuracy: 0.9559 - val_loss: 0.3612 - val_accuracy: 0.8641 - lr: 0.0013\n","Epoch 191/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9574\n","Epoch 191: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1325 - accuracy: 0.9574 - val_loss: 0.6010 - val_accuracy: 0.8140 - lr: 0.0011\n","Epoch 192/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9579\n","Epoch 192: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1154 - accuracy: 0.9579 - val_loss: 0.1975 - val_accuracy: 0.9306 - lr: 9.2647e-04\n","Epoch 193/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9582\n","Epoch 193: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1170 - accuracy: 0.9582 - val_loss: 0.1767 - val_accuracy: 0.9251 - lr: 7.8750e-04\n","Epoch 194/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9597\n","Epoch 194: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1134 - accuracy: 0.9597 - val_loss: 1.6305 - val_accuracy: 0.8140 - lr: 6.6937e-04\n","Epoch 195/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9602\n","Epoch 195: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1097 - accuracy: 0.9602 - val_loss: 0.1744 - val_accuracy: 0.9549 - lr: 5.6897e-04\n","Epoch 196/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9612\n","Epoch 196: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1190 - accuracy: 0.9612 - val_loss: 0.1266 - val_accuracy: 0.9494 - lr: 4.8362e-04\n","Epoch 197/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9619\n","Epoch 197: val_loss did not improve from 0.10965\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1017 - accuracy: 0.9619 - val_loss: 0.2408 - val_accuracy: 0.9330 - lr: 4.1108e-04\n","Epoch 198/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.9607\n","Epoch 198: val_loss improved from 0.10965 to 0.09588, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 32s 474ms/step - loss: 0.1085 - accuracy: 0.9607 - val_loss: 0.0959 - val_accuracy: 0.9633 - lr: 3.4942e-04\n","Epoch 199/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9624\n","Epoch 199: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0986 - accuracy: 0.9624 - val_loss: 0.1866 - val_accuracy: 0.8988 - lr: 2.9700e-04\n","Epoch 200/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9659\n","Epoch 200: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0873 - accuracy: 0.9659 - val_loss: 0.1210 - val_accuracy: 0.9539 - lr: 2.5245e-04\n","Epoch 201/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9624\n","Epoch 201: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1121 - accuracy: 0.9624 - val_loss: 0.1465 - val_accuracy: 0.9439 - lr: 0.0010\n","Epoch 202/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9627\n","Epoch 202: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1113 - accuracy: 0.9627 - val_loss: 0.2256 - val_accuracy: 0.9311 - lr: 0.0015\n","Epoch 203/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.9514\n","Epoch 203: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1426 - accuracy: 0.9514 - val_loss: 19.3909 - val_accuracy: 0.6364 - lr: 0.0020\n","Epoch 204/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9514\n","Epoch 204: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1385 - accuracy: 0.9514 - val_loss: 0.9565 - val_accuracy: 0.7178 - lr: 0.0025\n","Epoch 205/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1528 - accuracy: 0.9476\n","Epoch 205: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 426ms/step - loss: 0.1528 - accuracy: 0.9476 - val_loss: 42.2178 - val_accuracy: 0.4866 - lr: 0.0030\n","Epoch 206/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.9421\n","Epoch 206: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1665 - accuracy: 0.9421 - val_loss: 20.1348 - val_accuracy: 0.6548 - lr: 0.0035\n","Epoch 207/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.9326\n","Epoch 207: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1941 - accuracy: 0.9326 - val_loss: 51.5822 - val_accuracy: 0.5317 - lr: 0.0040\n","Epoch 208/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.9339\n","Epoch 208: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 422ms/step - loss: 0.2032 - accuracy: 0.9339 - val_loss: 23.6126 - val_accuracy: 0.6052 - lr: 0.0040\n","Epoch 209/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9401\n","Epoch 209: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1755 - accuracy: 0.9401 - val_loss: 0.5241 - val_accuracy: 0.8775 - lr: 0.0034\n","Epoch 210/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9449\n","Epoch 210: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 421ms/step - loss: 0.1651 - accuracy: 0.9449 - val_loss: 33.4365 - val_accuracy: 0.6319 - lr: 0.0029\n","Epoch 211/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9474\n","Epoch 211: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1442 - accuracy: 0.9474 - val_loss: 2.4847 - val_accuracy: 0.7708 - lr: 0.0025\n","Epoch 212/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9476\n","Epoch 212: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1392 - accuracy: 0.9476 - val_loss: 1.3335 - val_accuracy: 0.6647 - lr: 0.0021\n","Epoch 213/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9554\n","Epoch 213: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1327 - accuracy: 0.9554 - val_loss: 3.9344 - val_accuracy: 0.7986 - lr: 0.0018\n","Epoch 214/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9589\n","Epoch 214: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 429ms/step - loss: 0.1362 - accuracy: 0.9589 - val_loss: 1.6205 - val_accuracy: 0.6930 - lr: 0.0015\n","Epoch 215/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9592\n","Epoch 215: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1290 - accuracy: 0.9592 - val_loss: 2.0205 - val_accuracy: 0.6766 - lr: 0.0013\n","Epoch 216/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.9554\n","Epoch 216: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1167 - accuracy: 0.9554 - val_loss: 0.4602 - val_accuracy: 0.8269 - lr: 0.0011\n","Epoch 217/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9562\n","Epoch 217: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 420ms/step - loss: 0.1197 - accuracy: 0.9562 - val_loss: 0.3729 - val_accuracy: 0.8730 - lr: 9.2647e-04\n","Epoch 218/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.9629\n","Epoch 218: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0991 - accuracy: 0.9629 - val_loss: 0.3500 - val_accuracy: 0.8239 - lr: 7.8750e-04\n","Epoch 219/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9602\n","Epoch 219: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1049 - accuracy: 0.9602 - val_loss: 0.1647 - val_accuracy: 0.9365 - lr: 6.6937e-04\n","Epoch 220/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9649\n","Epoch 220: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 420ms/step - loss: 0.1016 - accuracy: 0.9649 - val_loss: 0.1943 - val_accuracy: 0.9355 - lr: 5.6897e-04\n","Epoch 221/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9629\n","Epoch 221: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1053 - accuracy: 0.9629 - val_loss: 0.4829 - val_accuracy: 0.8393 - lr: 4.8362e-04\n","Epoch 222/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9639\n","Epoch 222: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0965 - accuracy: 0.9639 - val_loss: 0.6078 - val_accuracy: 0.8140 - lr: 4.1108e-04\n","Epoch 223/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9712\n","Epoch 223: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0892 - accuracy: 0.9712 - val_loss: 0.1365 - val_accuracy: 0.9563 - lr: 3.4942e-04\n","Epoch 224/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9644\n","Epoch 224: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0929 - accuracy: 0.9644 - val_loss: 0.0977 - val_accuracy: 0.9683 - lr: 2.9700e-04\n","Epoch 225/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9679\n","Epoch 225: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0964 - accuracy: 0.9679 - val_loss: 0.0960 - val_accuracy: 0.9653 - lr: 2.5245e-04\n","Epoch 226/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9632\n","Epoch 226: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0983 - accuracy: 0.9632 - val_loss: 6.5051 - val_accuracy: 0.8140 - lr: 0.0010\n","Epoch 227/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.9564\n","Epoch 227: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1266 - accuracy: 0.9564 - val_loss: 2.7963 - val_accuracy: 0.6220 - lr: 0.0015\n","Epoch 228/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 0.9597\n","Epoch 228: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 419ms/step - loss: 0.1135 - accuracy: 0.9597 - val_loss: 1.4476 - val_accuracy: 0.7163 - lr: 0.0020\n","Epoch 229/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9539\n","Epoch 229: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1343 - accuracy: 0.9539 - val_loss: 31.4120 - val_accuracy: 0.6463 - lr: 0.0025\n","Epoch 230/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9494\n","Epoch 230: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1548 - accuracy: 0.9494 - val_loss: 241.2673 - val_accuracy: 0.5040 - lr: 0.0030\n","Epoch 231/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9389\n","Epoch 231: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 420ms/step - loss: 0.1755 - accuracy: 0.9389 - val_loss: 0.3943 - val_accuracy: 0.8938 - lr: 0.0035\n","Epoch 232/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9361\n","Epoch 232: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1821 - accuracy: 0.9361 - val_loss: 32.0950 - val_accuracy: 0.5020 - lr: 0.0040\n","Epoch 233/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1988 - accuracy: 0.9364\n","Epoch 233: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1988 - accuracy: 0.9364 - val_loss: 0.7259 - val_accuracy: 0.8051 - lr: 0.0040\n","Epoch 234/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9456\n","Epoch 234: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1517 - accuracy: 0.9456 - val_loss: 0.9409 - val_accuracy: 0.7530 - lr: 0.0034\n","Epoch 235/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.9436\n","Epoch 235: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1632 - accuracy: 0.9436 - val_loss: 13.6586 - val_accuracy: 0.6314 - lr: 0.0029\n","Epoch 236/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9522\n","Epoch 236: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1327 - accuracy: 0.9522 - val_loss: 1.8469 - val_accuracy: 0.7922 - lr: 0.0025\n","Epoch 237/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9557\n","Epoch 237: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1320 - accuracy: 0.9557 - val_loss: 0.5501 - val_accuracy: 0.9092 - lr: 0.0021\n","Epoch 238/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9572\n","Epoch 238: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1242 - accuracy: 0.9572 - val_loss: 1.2998 - val_accuracy: 0.7688 - lr: 0.0018\n","Epoch 239/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9559\n","Epoch 239: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1192 - accuracy: 0.9559 - val_loss: 2.2596 - val_accuracy: 0.6384 - lr: 0.0015\n","Epoch 240/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9617\n","Epoch 240: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1065 - accuracy: 0.9617 - val_loss: 0.3247 - val_accuracy: 0.9112 - lr: 0.0013\n","Epoch 241/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9634\n","Epoch 241: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 426ms/step - loss: 0.1100 - accuracy: 0.9634 - val_loss: 0.7612 - val_accuracy: 0.8517 - lr: 0.0011\n","Epoch 242/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.9629\n","Epoch 242: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 421ms/step - loss: 0.1087 - accuracy: 0.9629 - val_loss: 1.0652 - val_accuracy: 0.7535 - lr: 9.2647e-04\n","Epoch 243/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9704\n","Epoch 243: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0882 - accuracy: 0.9704 - val_loss: 0.2178 - val_accuracy: 0.9191 - lr: 7.8750e-04\n","Epoch 244/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9679\n","Epoch 244: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0903 - accuracy: 0.9679 - val_loss: 0.5170 - val_accuracy: 0.8284 - lr: 6.6937e-04\n","Epoch 245/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9669\n","Epoch 245: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1005 - accuracy: 0.9669 - val_loss: 0.1888 - val_accuracy: 0.9365 - lr: 5.6897e-04\n","Epoch 246/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9719\n","Epoch 246: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0790 - accuracy: 0.9719 - val_loss: 0.2835 - val_accuracy: 0.9335 - lr: 4.8362e-04\n","Epoch 247/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9702\n","Epoch 247: val_loss did not improve from 0.09588\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0877 - accuracy: 0.9702 - val_loss: 0.1511 - val_accuracy: 0.9435 - lr: 4.1108e-04\n","Epoch 248/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9689\n","Epoch 248: val_loss did not improve from 0.09588\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0898 - accuracy: 0.9689 - val_loss: 0.1137 - val_accuracy: 0.9554 - lr: 3.4942e-04\n","Epoch 249/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9694\n","Epoch 249: val_loss improved from 0.09588 to 0.08930, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 31s 477ms/step - loss: 0.0810 - accuracy: 0.9694 - val_loss: 0.0893 - val_accuracy: 0.9678 - lr: 2.9700e-04\n","Epoch 250/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9702\n","Epoch 250: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0810 - accuracy: 0.9702 - val_loss: 0.0931 - val_accuracy: 0.9697 - lr: 2.5245e-04\n","Epoch 251/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9692\n","Epoch 251: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0972 - accuracy: 0.9692 - val_loss: 9.8141 - val_accuracy: 0.6736 - lr: 0.0010\n","Epoch 252/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.9629\n","Epoch 252: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1043 - accuracy: 0.9629 - val_loss: 0.8655 - val_accuracy: 0.8576 - lr: 0.0015\n","Epoch 253/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9612\n","Epoch 253: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 426ms/step - loss: 0.1219 - accuracy: 0.9612 - val_loss: 1.0218 - val_accuracy: 0.8150 - lr: 0.0020\n","Epoch 254/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9564\n","Epoch 254: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1303 - accuracy: 0.9564 - val_loss: 69.3214 - val_accuracy: 0.6106 - lr: 0.0025\n","Epoch 255/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9562\n","Epoch 255: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1304 - accuracy: 0.9562 - val_loss: 15.9539 - val_accuracy: 0.5957 - lr: 0.0030\n","Epoch 256/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9406\n","Epoch 256: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1837 - accuracy: 0.9406 - val_loss: 2.0233 - val_accuracy: 0.6845 - lr: 0.0035\n","Epoch 257/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9394\n","Epoch 257: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 426ms/step - loss: 0.1829 - accuracy: 0.9394 - val_loss: 44.4548 - val_accuracy: 0.5853 - lr: 0.0040\n","Epoch 258/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9431\n","Epoch 258: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1817 - accuracy: 0.9431 - val_loss: 3.5458 - val_accuracy: 0.6141 - lr: 0.0040\n","Epoch 259/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9474\n","Epoch 259: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1497 - accuracy: 0.9474 - val_loss: 1.8356 - val_accuracy: 0.7440 - lr: 0.0034\n","Epoch 260/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.9504\n","Epoch 260: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1544 - accuracy: 0.9504 - val_loss: 0.3255 - val_accuracy: 0.9122 - lr: 0.0029\n","Epoch 261/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9494\n","Epoch 261: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1449 - accuracy: 0.9494 - val_loss: 0.6616 - val_accuracy: 0.8532 - lr: 0.0025\n","Epoch 262/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.9597\n","Epoch 262: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 426ms/step - loss: 0.1285 - accuracy: 0.9597 - val_loss: 1.1686 - val_accuracy: 0.7937 - lr: 0.0021\n","Epoch 263/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9562\n","Epoch 263: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1234 - accuracy: 0.9562 - val_loss: 1.3015 - val_accuracy: 0.7783 - lr: 0.0018\n","Epoch 264/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9619\n","Epoch 264: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1173 - accuracy: 0.9619 - val_loss: 0.3112 - val_accuracy: 0.9077 - lr: 0.0015\n","Epoch 265/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9657\n","Epoch 265: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1035 - accuracy: 0.9657 - val_loss: 0.3269 - val_accuracy: 0.8968 - lr: 0.0013\n","Epoch 266/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9662\n","Epoch 266: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0950 - accuracy: 0.9662 - val_loss: 1.0019 - val_accuracy: 0.7862 - lr: 0.0011\n","Epoch 267/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9669\n","Epoch 267: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0945 - accuracy: 0.9669 - val_loss: 0.3839 - val_accuracy: 0.8656 - lr: 9.2647e-04\n","Epoch 268/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9717\n","Epoch 268: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0902 - accuracy: 0.9717 - val_loss: 0.9558 - val_accuracy: 0.7778 - lr: 7.8750e-04\n","Epoch 269/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9682\n","Epoch 269: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0940 - accuracy: 0.9682 - val_loss: 0.1037 - val_accuracy: 0.9573 - lr: 6.6937e-04\n","Epoch 270/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9689\n","Epoch 270: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0914 - accuracy: 0.9689 - val_loss: 0.2158 - val_accuracy: 0.9340 - lr: 5.6897e-04\n","Epoch 271/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9699\n","Epoch 271: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0823 - accuracy: 0.9699 - val_loss: 0.1555 - val_accuracy: 0.9479 - lr: 4.8362e-04\n","Epoch 272/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9702\n","Epoch 272: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0765 - accuracy: 0.9702 - val_loss: 0.1821 - val_accuracy: 0.9201 - lr: 4.1108e-04\n","Epoch 273/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9709\n","Epoch 273: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0779 - accuracy: 0.9709 - val_loss: 0.1191 - val_accuracy: 0.9563 - lr: 3.4942e-04\n","Epoch 274/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9770\n","Epoch 274: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0654 - accuracy: 0.9770 - val_loss: 0.1419 - val_accuracy: 0.9529 - lr: 2.9700e-04\n","Epoch 275/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9727\n","Epoch 275: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0761 - accuracy: 0.9727 - val_loss: 0.0981 - val_accuracy: 0.9658 - lr: 2.5245e-04\n","Epoch 276/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9719\n","Epoch 276: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0868 - accuracy: 0.9719 - val_loss: 3.5792 - val_accuracy: 0.6399 - lr: 0.0010\n","Epoch 277/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9694\n","Epoch 277: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0843 - accuracy: 0.9694 - val_loss: 0.2542 - val_accuracy: 0.9251 - lr: 0.0015\n","Epoch 278/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9622\n","Epoch 278: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1133 - accuracy: 0.9622 - val_loss: 0.3816 - val_accuracy: 0.9281 - lr: 0.0020\n","Epoch 279/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9552\n","Epoch 279: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 420ms/step - loss: 0.1328 - accuracy: 0.9552 - val_loss: 0.6031 - val_accuracy: 0.8234 - lr: 0.0025\n","Epoch 280/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9542\n","Epoch 280: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1343 - accuracy: 0.9542 - val_loss: 1.1112 - val_accuracy: 0.7783 - lr: 0.0030\n","Epoch 281/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9491\n","Epoch 281: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1382 - accuracy: 0.9491 - val_loss: 0.3546 - val_accuracy: 0.9013 - lr: 0.0035\n","Epoch 282/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9491\n","Epoch 282: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1572 - accuracy: 0.9491 - val_loss: 36.4597 - val_accuracy: 0.4856 - lr: 0.0040\n","Epoch 283/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9504\n","Epoch 283: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1478 - accuracy: 0.9504 - val_loss: 1.4367 - val_accuracy: 0.7178 - lr: 0.0040\n","Epoch 284/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9454\n","Epoch 284: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1565 - accuracy: 0.9454 - val_loss: 16.2152 - val_accuracy: 0.6399 - lr: 0.0034\n","Epoch 285/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9547\n","Epoch 285: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1293 - accuracy: 0.9547 - val_loss: 1.7450 - val_accuracy: 0.6915 - lr: 0.0029\n","Epoch 286/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1314 - accuracy: 0.9534\n","Epoch 286: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1314 - accuracy: 0.9534 - val_loss: 7.1599 - val_accuracy: 0.6498 - lr: 0.0025\n","Epoch 287/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9547\n","Epoch 287: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1284 - accuracy: 0.9547 - val_loss: 0.3924 - val_accuracy: 0.8730 - lr: 0.0021\n","Epoch 288/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9642\n","Epoch 288: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 419ms/step - loss: 0.1100 - accuracy: 0.9642 - val_loss: 0.4274 - val_accuracy: 0.9043 - lr: 0.0018\n","Epoch 289/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9647\n","Epoch 289: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1149 - accuracy: 0.9647 - val_loss: 0.2008 - val_accuracy: 0.9291 - lr: 0.0015\n","Epoch 290/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9637\n","Epoch 290: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0975 - accuracy: 0.9637 - val_loss: 1.5750 - val_accuracy: 0.6845 - lr: 0.0013\n","Epoch 291/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9669\n","Epoch 291: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0944 - accuracy: 0.9669 - val_loss: 0.4562 - val_accuracy: 0.8884 - lr: 0.0011\n","Epoch 292/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9674\n","Epoch 292: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0864 - accuracy: 0.9674 - val_loss: 0.3617 - val_accuracy: 0.9003 - lr: 9.2647e-04\n","Epoch 293/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9734\n","Epoch 293: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0765 - accuracy: 0.9734 - val_loss: 0.2685 - val_accuracy: 0.9226 - lr: 7.8750e-04\n","Epoch 294/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9732\n","Epoch 294: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0795 - accuracy: 0.9732 - val_loss: 0.5687 - val_accuracy: 0.8185 - lr: 6.6937e-04\n","Epoch 295/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9674\n","Epoch 295: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0923 - accuracy: 0.9674 - val_loss: 0.1481 - val_accuracy: 0.9509 - lr: 5.6897e-04\n","Epoch 296/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9755\n","Epoch 296: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0749 - accuracy: 0.9755 - val_loss: 0.1102 - val_accuracy: 0.9603 - lr: 4.8362e-04\n","Epoch 297/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9737\n","Epoch 297: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0699 - accuracy: 0.9737 - val_loss: 0.1838 - val_accuracy: 0.9380 - lr: 4.1108e-04\n","Epoch 298/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9767\n","Epoch 298: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0712 - accuracy: 0.9767 - val_loss: 0.2981 - val_accuracy: 0.9067 - lr: 3.4942e-04\n","Epoch 299/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9765\n","Epoch 299: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0739 - accuracy: 0.9765 - val_loss: 0.1593 - val_accuracy: 0.9519 - lr: 2.9700e-04\n","Epoch 300/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9762\n","Epoch 300: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0666 - accuracy: 0.9762 - val_loss: 0.1330 - val_accuracy: 0.9653 - lr: 2.5245e-04\n","Epoch 301/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9727\n","Epoch 301: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0836 - accuracy: 0.9727 - val_loss: 1.0725 - val_accuracy: 0.8115 - lr: 0.0010\n","Epoch 302/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9697\n","Epoch 302: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 420ms/step - loss: 0.0897 - accuracy: 0.9697 - val_loss: 1.1290 - val_accuracy: 0.8666 - lr: 0.0015\n","Epoch 303/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9649\n","Epoch 303: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 418ms/step - loss: 0.1015 - accuracy: 0.9649 - val_loss: 5.3695 - val_accuracy: 0.7619 - lr: 0.0020\n","Epoch 304/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9619\n","Epoch 304: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1204 - accuracy: 0.9619 - val_loss: 0.8996 - val_accuracy: 0.8562 - lr: 0.0025\n","Epoch 305/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9572\n","Epoch 305: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1274 - accuracy: 0.9572 - val_loss: 0.5749 - val_accuracy: 0.8681 - lr: 0.0030\n","Epoch 306/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9557\n","Epoch 306: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 421ms/step - loss: 0.1431 - accuracy: 0.9557 - val_loss: 0.3130 - val_accuracy: 0.9062 - lr: 0.0035\n","Epoch 307/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.9449\n","Epoch 307: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1558 - accuracy: 0.9449 - val_loss: 53.8280 - val_accuracy: 0.4152 - lr: 0.0040\n","Epoch 308/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.9471\n","Epoch 308: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1568 - accuracy: 0.9471 - val_loss: 1.3103 - val_accuracy: 0.7019 - lr: 0.0040\n","Epoch 309/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9529\n","Epoch 309: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 418ms/step - loss: 0.1414 - accuracy: 0.9529 - val_loss: 1.0297 - val_accuracy: 0.7981 - lr: 0.0034\n","Epoch 310/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9517\n","Epoch 310: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1383 - accuracy: 0.9517 - val_loss: 0.2903 - val_accuracy: 0.9196 - lr: 0.0029\n","Epoch 311/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9569\n","Epoch 311: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1279 - accuracy: 0.9569 - val_loss: 32.5570 - val_accuracy: 0.5729 - lr: 0.0025\n","Epoch 312/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9582\n","Epoch 312: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1101 - accuracy: 0.9582 - val_loss: 0.3496 - val_accuracy: 0.8943 - lr: 0.0021\n","Epoch 313/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9629\n","Epoch 313: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 421ms/step - loss: 0.1086 - accuracy: 0.9629 - val_loss: 0.3104 - val_accuracy: 0.9008 - lr: 0.0018\n","Epoch 314/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9704\n","Epoch 314: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0978 - accuracy: 0.9704 - val_loss: 0.8721 - val_accuracy: 0.8294 - lr: 0.0015\n","Epoch 315/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9704\n","Epoch 315: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0839 - accuracy: 0.9704 - val_loss: 2.5121 - val_accuracy: 0.6225 - lr: 0.0013\n","Epoch 316/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9692\n","Epoch 316: val_loss did not improve from 0.08930\n","63/63 [==============================] - 30s 426ms/step - loss: 0.0897 - accuracy: 0.9692 - val_loss: 0.6699 - val_accuracy: 0.8214 - lr: 0.0011\n","Epoch 317/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9697\n","Epoch 317: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0832 - accuracy: 0.9697 - val_loss: 0.4157 - val_accuracy: 0.8993 - lr: 9.2647e-04\n","Epoch 318/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9734\n","Epoch 318: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0771 - accuracy: 0.9734 - val_loss: 0.7809 - val_accuracy: 0.8438 - lr: 7.8750e-04\n","Epoch 319/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9697\n","Epoch 319: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0934 - accuracy: 0.9697 - val_loss: 0.3626 - val_accuracy: 0.8676 - lr: 6.6937e-04\n","Epoch 320/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9737\n","Epoch 320: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0639 - accuracy: 0.9737 - val_loss: 0.2777 - val_accuracy: 0.9330 - lr: 5.6897e-04\n","Epoch 321/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9780\n","Epoch 321: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 445ms/step - loss: 0.0646 - accuracy: 0.9780 - val_loss: 0.2264 - val_accuracy: 0.9474 - lr: 4.8362e-04\n","Epoch 322/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9785\n","Epoch 322: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0645 - accuracy: 0.9785 - val_loss: 0.1410 - val_accuracy: 0.9588 - lr: 4.1108e-04\n","Epoch 323/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9780\n","Epoch 323: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 420ms/step - loss: 0.0622 - accuracy: 0.9780 - val_loss: 0.5908 - val_accuracy: 0.8661 - lr: 3.4942e-04\n","Epoch 324/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9795\n","Epoch 324: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0633 - accuracy: 0.9795 - val_loss: 0.1000 - val_accuracy: 0.9683 - lr: 2.9700e-04\n","Epoch 325/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9780\n","Epoch 325: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0581 - accuracy: 0.9780 - val_loss: 0.0914 - val_accuracy: 0.9697 - lr: 2.5245e-04\n","Epoch 326/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9734\n","Epoch 326: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 418ms/step - loss: 0.0786 - accuracy: 0.9734 - val_loss: 0.7110 - val_accuracy: 0.7659 - lr: 0.0010\n","Epoch 327/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9732\n","Epoch 327: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0801 - accuracy: 0.9732 - val_loss: 2.1013 - val_accuracy: 0.8219 - lr: 0.0015\n","Epoch 328/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9714\n","Epoch 328: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0919 - accuracy: 0.9714 - val_loss: 0.7597 - val_accuracy: 0.8056 - lr: 0.0020\n","Epoch 329/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9654\n","Epoch 329: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 418ms/step - loss: 0.1002 - accuracy: 0.9654 - val_loss: 0.2398 - val_accuracy: 0.9261 - lr: 0.0025\n","Epoch 330/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9507\n","Epoch 330: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1327 - accuracy: 0.9507 - val_loss: 24.8027 - val_accuracy: 0.5938 - lr: 0.0030\n","Epoch 331/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9582\n","Epoch 331: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1172 - accuracy: 0.9582 - val_loss: 10.9654 - val_accuracy: 0.7133 - lr: 0.0035\n","Epoch 332/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9451\n","Epoch 332: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1580 - accuracy: 0.9451 - val_loss: 1.1657 - val_accuracy: 0.7326 - lr: 0.0040\n","Epoch 333/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9529\n","Epoch 333: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1435 - accuracy: 0.9529 - val_loss: 44.7140 - val_accuracy: 0.5734 - lr: 0.0040\n","Epoch 334/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9549\n","Epoch 334: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1215 - accuracy: 0.9549 - val_loss: 38.0571 - val_accuracy: 0.5506 - lr: 0.0034\n","Epoch 335/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9547\n","Epoch 335: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1303 - accuracy: 0.9547 - val_loss: 13.1132 - val_accuracy: 0.6811 - lr: 0.0029\n","Epoch 336/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9597\n","Epoch 336: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1155 - accuracy: 0.9597 - val_loss: 11.4274 - val_accuracy: 0.7242 - lr: 0.0025\n","Epoch 337/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9629\n","Epoch 337: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1083 - accuracy: 0.9629 - val_loss: 1.3937 - val_accuracy: 0.8061 - lr: 0.0021\n","Epoch 338/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9694\n","Epoch 338: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0961 - accuracy: 0.9694 - val_loss: 30.2378 - val_accuracy: 0.6766 - lr: 0.0018\n","Epoch 339/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9662\n","Epoch 339: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1008 - accuracy: 0.9662 - val_loss: 0.5293 - val_accuracy: 0.8363 - lr: 0.0015\n","Epoch 340/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9679\n","Epoch 340: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0912 - accuracy: 0.9679 - val_loss: 0.4412 - val_accuracy: 0.8547 - lr: 0.0013\n","Epoch 341/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.9692\n","Epoch 341: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0884 - accuracy: 0.9692 - val_loss: 0.3220 - val_accuracy: 0.8983 - lr: 0.0011\n","Epoch 342/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9717\n","Epoch 342: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0742 - accuracy: 0.9717 - val_loss: 0.2533 - val_accuracy: 0.9231 - lr: 9.2647e-04\n","Epoch 343/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9742\n","Epoch 343: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0733 - accuracy: 0.9742 - val_loss: 0.1468 - val_accuracy: 0.9568 - lr: 7.8750e-04\n","Epoch 344/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9772\n","Epoch 344: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 5.4545 - val_accuracy: 0.7932 - lr: 6.6937e-04\n","Epoch 345/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9777\n","Epoch 345: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0663 - accuracy: 0.9777 - val_loss: 0.7299 - val_accuracy: 0.9251 - lr: 5.6897e-04\n","Epoch 346/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9729\n","Epoch 346: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0738 - accuracy: 0.9729 - val_loss: 0.6263 - val_accuracy: 0.8676 - lr: 4.8362e-04\n","Epoch 347/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9795\n","Epoch 347: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0663 - accuracy: 0.9795 - val_loss: 0.4371 - val_accuracy: 0.8705 - lr: 4.1108e-04\n","Epoch 348/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9795\n","Epoch 348: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0680 - accuracy: 0.9795 - val_loss: 0.6543 - val_accuracy: 0.9172 - lr: 3.4942e-04\n","Epoch 349/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9775\n","Epoch 349: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0624 - accuracy: 0.9775 - val_loss: 0.1161 - val_accuracy: 0.9598 - lr: 2.9700e-04\n","Epoch 350/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9787\n","Epoch 350: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.1060 - val_accuracy: 0.9653 - lr: 2.5245e-04\n","Epoch 351/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9739\n","Epoch 351: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0765 - accuracy: 0.9739 - val_loss: 0.2618 - val_accuracy: 0.9241 - lr: 0.0010\n","Epoch 352/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9739\n","Epoch 352: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0854 - accuracy: 0.9739 - val_loss: 50.6659 - val_accuracy: 0.6091 - lr: 0.0015\n","Epoch 353/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9659\n","Epoch 353: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 418ms/step - loss: 0.0985 - accuracy: 0.9659 - val_loss: 0.3057 - val_accuracy: 0.9206 - lr: 0.0020\n","Epoch 354/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9674\n","Epoch 354: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0987 - accuracy: 0.9674 - val_loss: 3.4639 - val_accuracy: 0.6101 - lr: 0.0025\n","Epoch 355/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9634\n","Epoch 355: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 418ms/step - loss: 0.1099 - accuracy: 0.9634 - val_loss: 98.2261 - val_accuracy: 0.6200 - lr: 0.0030\n","Epoch 356/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.9539\n","Epoch 356: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 434ms/step - loss: 0.1354 - accuracy: 0.9539 - val_loss: 32.7270 - val_accuracy: 0.5883 - lr: 0.0035\n","Epoch 357/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9514\n","Epoch 357: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1425 - accuracy: 0.9514 - val_loss: 0.9939 - val_accuracy: 0.7530 - lr: 0.0040\n","Epoch 358/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9517\n","Epoch 358: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 442ms/step - loss: 0.1358 - accuracy: 0.9517 - val_loss: 92.8622 - val_accuracy: 0.5774 - lr: 0.0040\n","Epoch 359/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9589\n","Epoch 359: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1439 - accuracy: 0.9589 - val_loss: 41.9484 - val_accuracy: 0.6935 - lr: 0.0034\n","Epoch 360/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9569\n","Epoch 360: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 427ms/step - loss: 0.1187 - accuracy: 0.9569 - val_loss: 1.8627 - val_accuracy: 0.6796 - lr: 0.0029\n","Epoch 361/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9624\n","Epoch 361: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1190 - accuracy: 0.9624 - val_loss: 4.2131 - val_accuracy: 0.7966 - lr: 0.0025\n","Epoch 362/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9652\n","Epoch 362: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1003 - accuracy: 0.9652 - val_loss: 0.8204 - val_accuracy: 0.8378 - lr: 0.0021\n","Epoch 363/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9657\n","Epoch 363: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 425ms/step - loss: 0.1072 - accuracy: 0.9657 - val_loss: 0.2495 - val_accuracy: 0.9221 - lr: 0.0018\n","Epoch 364/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9712\n","Epoch 364: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0964 - accuracy: 0.9712 - val_loss: 0.1119 - val_accuracy: 0.9573 - lr: 0.0015\n","Epoch 365/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9729\n","Epoch 365: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0782 - accuracy: 0.9729 - val_loss: 0.6756 - val_accuracy: 0.8800 - lr: 0.0013\n","Epoch 366/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.9782\n","Epoch 366: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0721 - accuracy: 0.9782 - val_loss: 0.5428 - val_accuracy: 0.9122 - lr: 0.0011\n","Epoch 367/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9747\n","Epoch 367: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0756 - accuracy: 0.9747 - val_loss: 0.6726 - val_accuracy: 0.8899 - lr: 9.2647e-04\n","Epoch 368/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9742\n","Epoch 368: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 418ms/step - loss: 0.0706 - accuracy: 0.9742 - val_loss: 0.4421 - val_accuracy: 0.9023 - lr: 7.8750e-04\n","Epoch 369/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9772\n","Epoch 369: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0680 - accuracy: 0.9772 - val_loss: 3.2384 - val_accuracy: 0.8348 - lr: 6.6937e-04\n","Epoch 370/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9775\n","Epoch 370: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0628 - accuracy: 0.9775 - val_loss: 12.3357 - val_accuracy: 0.8150 - lr: 5.6897e-04\n","Epoch 371/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9785\n","Epoch 371: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 418ms/step - loss: 0.0653 - accuracy: 0.9785 - val_loss: 6.1134 - val_accuracy: 0.8318 - lr: 4.8362e-04\n","Epoch 372/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9785\n","Epoch 372: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0621 - accuracy: 0.9785 - val_loss: 0.5277 - val_accuracy: 0.8904 - lr: 4.1108e-04\n","Epoch 373/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9785\n","Epoch 373: val_loss did not improve from 0.08930\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0627 - accuracy: 0.9785 - val_loss: 0.1591 - val_accuracy: 0.9539 - lr: 3.4942e-04\n","Epoch 374/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9812\n","Epoch 374: val_loss did not improve from 0.08930\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0576 - accuracy: 0.9812 - val_loss: 0.1350 - val_accuracy: 0.9578 - lr: 2.9700e-04\n","Epoch 375/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9795\n","Epoch 375: val_loss improved from 0.08930 to 0.08443, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 31s 476ms/step - loss: 0.0608 - accuracy: 0.9795 - val_loss: 0.0844 - val_accuracy: 0.9697 - lr: 2.5245e-04\n","Epoch 376/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9777\n","Epoch 376: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 420ms/step - loss: 0.0653 - accuracy: 0.9777 - val_loss: 0.7238 - val_accuracy: 0.8274 - lr: 0.0010\n","Epoch 377/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9772\n","Epoch 377: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0644 - accuracy: 0.9772 - val_loss: 0.8892 - val_accuracy: 0.8383 - lr: 0.0015\n","Epoch 378/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9744\n","Epoch 378: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0840 - accuracy: 0.9744 - val_loss: 3.4501 - val_accuracy: 0.8155 - lr: 0.0020\n","Epoch 379/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9679\n","Epoch 379: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0949 - accuracy: 0.9679 - val_loss: 3.7301 - val_accuracy: 0.8259 - lr: 0.0025\n","Epoch 380/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9609\n","Epoch 380: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1168 - accuracy: 0.9609 - val_loss: 7.1693 - val_accuracy: 0.5774 - lr: 0.0030\n","Epoch 381/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9614\n","Epoch 381: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 420ms/step - loss: 0.1191 - accuracy: 0.9614 - val_loss: 0.7708 - val_accuracy: 0.8522 - lr: 0.0035\n","Epoch 382/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9512\n","Epoch 382: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1374 - accuracy: 0.9512 - val_loss: 49.2896 - val_accuracy: 0.5104 - lr: 0.0040\n","Epoch 383/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9512\n","Epoch 383: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1477 - accuracy: 0.9512 - val_loss: 5.5647 - val_accuracy: 0.7470 - lr: 0.0040\n","Epoch 384/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9594\n","Epoch 384: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1116 - accuracy: 0.9594 - val_loss: 83.2935 - val_accuracy: 0.6121 - lr: 0.0034\n","Epoch 385/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9612\n","Epoch 385: val_loss did not improve from 0.08443\n","63/63 [==============================] - 27s 418ms/step - loss: 0.1188 - accuracy: 0.9612 - val_loss: 16.3074 - val_accuracy: 0.6448 - lr: 0.0029\n","Epoch 386/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9617\n","Epoch 386: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1129 - accuracy: 0.9617 - val_loss: 0.6701 - val_accuracy: 0.8328 - lr: 0.0025\n","Epoch 387/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9684\n","Epoch 387: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0973 - accuracy: 0.9684 - val_loss: 2.6737 - val_accuracy: 0.6339 - lr: 0.0021\n","Epoch 388/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9622\n","Epoch 388: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 424ms/step - loss: 0.1045 - accuracy: 0.9622 - val_loss: 0.4371 - val_accuracy: 0.8814 - lr: 0.0018\n","Epoch 389/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9709\n","Epoch 389: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0921 - accuracy: 0.9709 - val_loss: 0.5269 - val_accuracy: 0.8398 - lr: 0.0015\n","Epoch 390/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9744\n","Epoch 390: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0810 - accuracy: 0.9744 - val_loss: 8.5969 - val_accuracy: 0.7098 - lr: 0.0013\n","Epoch 391/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9737\n","Epoch 391: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0843 - accuracy: 0.9737 - val_loss: 0.2329 - val_accuracy: 0.9271 - lr: 0.0011\n","Epoch 392/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9762\n","Epoch 392: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0707 - accuracy: 0.9762 - val_loss: 5.9484 - val_accuracy: 0.7783 - lr: 9.2647e-04\n","Epoch 393/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9762\n","Epoch 393: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0642 - accuracy: 0.9762 - val_loss: 0.5064 - val_accuracy: 0.8755 - lr: 7.8750e-04\n","Epoch 394/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9780\n","Epoch 394: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0631 - accuracy: 0.9780 - val_loss: 0.1366 - val_accuracy: 0.9583 - lr: 6.6937e-04\n","Epoch 395/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9790\n","Epoch 395: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0712 - accuracy: 0.9790 - val_loss: 0.1726 - val_accuracy: 0.9330 - lr: 5.6897e-04\n","Epoch 396/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9812\n","Epoch 396: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0520 - accuracy: 0.9812 - val_loss: 0.1030 - val_accuracy: 0.9613 - lr: 4.8362e-04\n","Epoch 397/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9830\n","Epoch 397: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0549 - accuracy: 0.9830 - val_loss: 0.0923 - val_accuracy: 0.9653 - lr: 4.1108e-04\n","Epoch 398/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9782\n","Epoch 398: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0585 - accuracy: 0.9782 - val_loss: 0.1345 - val_accuracy: 0.9618 - lr: 3.4942e-04\n","Epoch 399/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9800\n","Epoch 399: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.1070 - val_accuracy: 0.9643 - lr: 2.9700e-04\n","Epoch 400/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9795\n","Epoch 400: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0666 - accuracy: 0.9795 - val_loss: 0.0976 - val_accuracy: 0.9668 - lr: 2.5245e-04\n","Epoch 401/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9805\n","Epoch 401: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 435ms/step - loss: 0.0640 - accuracy: 0.9805 - val_loss: 0.2983 - val_accuracy: 0.9236 - lr: 0.0010\n","Epoch 402/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9757\n","Epoch 402: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0646 - accuracy: 0.9757 - val_loss: 18.9870 - val_accuracy: 0.7297 - lr: 0.0015\n","Epoch 403/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9734\n","Epoch 403: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0789 - accuracy: 0.9734 - val_loss: 1.0625 - val_accuracy: 0.7688 - lr: 0.0020\n","Epoch 404/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9722\n","Epoch 404: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0865 - accuracy: 0.9722 - val_loss: 0.6974 - val_accuracy: 0.8155 - lr: 0.0025\n","Epoch 405/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.9662\n","Epoch 405: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0991 - accuracy: 0.9662 - val_loss: 0.7938 - val_accuracy: 0.7728 - lr: 0.0030\n","Epoch 406/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9627\n","Epoch 406: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 418ms/step - loss: 0.1098 - accuracy: 0.9627 - val_loss: 1.0842 - val_accuracy: 0.7946 - lr: 0.0035\n","Epoch 407/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9527\n","Epoch 407: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1377 - accuracy: 0.9527 - val_loss: 2.5803 - val_accuracy: 0.6349 - lr: 0.0040\n","Epoch 408/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9554\n","Epoch 408: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1280 - accuracy: 0.9554 - val_loss: 1.4756 - val_accuracy: 0.6324 - lr: 0.0040\n","Epoch 409/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9587\n","Epoch 409: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 425ms/step - loss: 0.1264 - accuracy: 0.9587 - val_loss: 0.9764 - val_accuracy: 0.7272 - lr: 0.0034\n","Epoch 410/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9644\n","Epoch 410: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1086 - accuracy: 0.9644 - val_loss: 1.3205 - val_accuracy: 0.7520 - lr: 0.0029\n","Epoch 411/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9614\n","Epoch 411: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1081 - accuracy: 0.9614 - val_loss: 2.6348 - val_accuracy: 0.6801 - lr: 0.0025\n","Epoch 412/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9692\n","Epoch 412: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 436ms/step - loss: 0.0950 - accuracy: 0.9692 - val_loss: 87.3723 - val_accuracy: 0.5843 - lr: 0.0021\n","Epoch 413/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9717\n","Epoch 413: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0833 - accuracy: 0.9717 - val_loss: 6.5982 - val_accuracy: 0.7049 - lr: 0.0018\n","Epoch 414/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9744\n","Epoch 414: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0754 - accuracy: 0.9744 - val_loss: 1.4932 - val_accuracy: 0.8492 - lr: 0.0015\n","Epoch 415/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9767\n","Epoch 415: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0665 - accuracy: 0.9767 - val_loss: 0.3086 - val_accuracy: 0.9077 - lr: 0.0013\n","Epoch 416/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9757\n","Epoch 416: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0707 - accuracy: 0.9757 - val_loss: 0.1315 - val_accuracy: 0.9648 - lr: 0.0011\n","Epoch 417/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9775\n","Epoch 417: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0618 - accuracy: 0.9775 - val_loss: 0.5156 - val_accuracy: 0.8770 - lr: 9.2647e-04\n","Epoch 418/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9757\n","Epoch 418: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0685 - accuracy: 0.9757 - val_loss: 1.3562 - val_accuracy: 0.7158 - lr: 7.8750e-04\n","Epoch 419/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9790\n","Epoch 419: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0589 - accuracy: 0.9790 - val_loss: 0.5624 - val_accuracy: 0.8433 - lr: 6.6937e-04\n","Epoch 420/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9772\n","Epoch 420: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0632 - accuracy: 0.9772 - val_loss: 0.1273 - val_accuracy: 0.9524 - lr: 5.6897e-04\n","Epoch 421/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9800\n","Epoch 421: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 0.2075 - val_accuracy: 0.9033 - lr: 4.8362e-04\n","Epoch 422/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9810\n","Epoch 422: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.3482 - val_accuracy: 0.8983 - lr: 4.1108e-04\n","Epoch 423/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9790\n","Epoch 423: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0592 - accuracy: 0.9790 - val_loss: 1.1118 - val_accuracy: 0.7242 - lr: 3.4942e-04\n","Epoch 424/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9805\n","Epoch 424: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0566 - accuracy: 0.9805 - val_loss: 0.1104 - val_accuracy: 0.9618 - lr: 2.9700e-04\n","Epoch 425/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9840\n","Epoch 425: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0542 - accuracy: 0.9840 - val_loss: 0.0896 - val_accuracy: 0.9702 - lr: 2.5245e-04\n","Epoch 426/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9785\n","Epoch 426: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0646 - accuracy: 0.9785 - val_loss: 0.2710 - val_accuracy: 0.9142 - lr: 0.0010\n","Epoch 427/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9757\n","Epoch 427: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0739 - accuracy: 0.9757 - val_loss: 0.5366 - val_accuracy: 0.8695 - lr: 0.0015\n","Epoch 428/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9734\n","Epoch 428: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0839 - accuracy: 0.9734 - val_loss: 0.5702 - val_accuracy: 0.8284 - lr: 0.0020\n","Epoch 429/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9719\n","Epoch 429: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0786 - accuracy: 0.9719 - val_loss: 1.0974 - val_accuracy: 0.7877 - lr: 0.0025\n","Epoch 430/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9659\n","Epoch 430: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1067 - accuracy: 0.9659 - val_loss: 241.3898 - val_accuracy: 0.5561 - lr: 0.0030\n","Epoch 431/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9617\n","Epoch 431: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1156 - accuracy: 0.9617 - val_loss: 1.3429 - val_accuracy: 0.7411 - lr: 0.0035\n","Epoch 432/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9594\n","Epoch 432: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1198 - accuracy: 0.9594 - val_loss: 13.4463 - val_accuracy: 0.6860 - lr: 0.0040\n","Epoch 433/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9599\n","Epoch 433: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1212 - accuracy: 0.9599 - val_loss: 3.4474 - val_accuracy: 0.7044 - lr: 0.0040\n","Epoch 434/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9592\n","Epoch 434: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1187 - accuracy: 0.9592 - val_loss: 55.3218 - val_accuracy: 0.5481 - lr: 0.0034\n","Epoch 435/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9677\n","Epoch 435: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0959 - accuracy: 0.9677 - val_loss: 1.2831 - val_accuracy: 0.7510 - lr: 0.0029\n","Epoch 436/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9639\n","Epoch 436: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1002 - accuracy: 0.9639 - val_loss: 0.9189 - val_accuracy: 0.7247 - lr: 0.0025\n","Epoch 437/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9712\n","Epoch 437: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0811 - accuracy: 0.9712 - val_loss: 7.9580 - val_accuracy: 0.7083 - lr: 0.0021\n","Epoch 438/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9684\n","Epoch 438: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0826 - accuracy: 0.9684 - val_loss: 0.9022 - val_accuracy: 0.7892 - lr: 0.0018\n","Epoch 439/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9712\n","Epoch 439: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0780 - accuracy: 0.9712 - val_loss: 1.1022 - val_accuracy: 0.7842 - lr: 0.0015\n","Epoch 440/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9765\n","Epoch 440: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0635 - accuracy: 0.9765 - val_loss: 0.4361 - val_accuracy: 0.8775 - lr: 0.0013\n","Epoch 441/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9775\n","Epoch 441: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0622 - accuracy: 0.9775 - val_loss: 0.6173 - val_accuracy: 0.8328 - lr: 0.0011\n","Epoch 442/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9782\n","Epoch 442: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0607 - accuracy: 0.9782 - val_loss: 0.2266 - val_accuracy: 0.9355 - lr: 9.2647e-04\n","Epoch 443/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9780\n","Epoch 443: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0642 - accuracy: 0.9780 - val_loss: 0.1348 - val_accuracy: 0.9559 - lr: 7.8750e-04\n","Epoch 444/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9815\n","Epoch 444: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0552 - accuracy: 0.9815 - val_loss: 0.2098 - val_accuracy: 0.9340 - lr: 6.6937e-04\n","Epoch 445/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9837\n","Epoch 445: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0553 - accuracy: 0.9837 - val_loss: 0.1209 - val_accuracy: 0.9638 - lr: 5.6897e-04\n","Epoch 446/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9832\n","Epoch 446: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0491 - accuracy: 0.9832 - val_loss: 0.1125 - val_accuracy: 0.9742 - lr: 4.8362e-04\n","Epoch 447/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9800\n","Epoch 447: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0527 - accuracy: 0.9800 - val_loss: 0.1302 - val_accuracy: 0.9702 - lr: 4.1108e-04\n","Epoch 448/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9802\n","Epoch 448: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0605 - accuracy: 0.9802 - val_loss: 0.1739 - val_accuracy: 0.9678 - lr: 3.4942e-04\n","Epoch 449/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9810\n","Epoch 449: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0516 - accuracy: 0.9810 - val_loss: 0.1806 - val_accuracy: 0.9653 - lr: 2.9700e-04\n","Epoch 450/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9832\n","Epoch 450: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0475 - accuracy: 0.9832 - val_loss: 0.1755 - val_accuracy: 0.9707 - lr: 2.5245e-04\n","Epoch 451/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9802\n","Epoch 451: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0622 - accuracy: 0.9802 - val_loss: 0.5092 - val_accuracy: 0.8581 - lr: 0.0010\n","Epoch 452/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9805\n","Epoch 452: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0597 - accuracy: 0.9805 - val_loss: 0.1693 - val_accuracy: 0.9444 - lr: 0.0015\n","Epoch 453/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9732\n","Epoch 453: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0815 - accuracy: 0.9732 - val_loss: 9.9030 - val_accuracy: 0.7793 - lr: 0.0020\n","Epoch 454/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9719\n","Epoch 454: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0799 - accuracy: 0.9719 - val_loss: 2.6777 - val_accuracy: 0.6344 - lr: 0.0025\n","Epoch 455/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9684\n","Epoch 455: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0938 - accuracy: 0.9684 - val_loss: 12.1823 - val_accuracy: 0.5605 - lr: 0.0030\n","Epoch 456/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9634\n","Epoch 456: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0978 - accuracy: 0.9634 - val_loss: 0.7601 - val_accuracy: 0.8611 - lr: 0.0035\n","Epoch 457/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 0.9557\n","Epoch 457: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 418ms/step - loss: 0.1360 - accuracy: 0.9557 - val_loss: 7.5444 - val_accuracy: 0.6240 - lr: 0.0040\n","Epoch 458/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9592\n","Epoch 458: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1224 - accuracy: 0.9592 - val_loss: 53.8490 - val_accuracy: 0.6081 - lr: 0.0040\n","Epoch 459/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9597\n","Epoch 459: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1212 - accuracy: 0.9597 - val_loss: 0.7681 - val_accuracy: 0.7669 - lr: 0.0034\n","Epoch 460/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9627\n","Epoch 460: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1035 - accuracy: 0.9627 - val_loss: 100.1109 - val_accuracy: 0.6141 - lr: 0.0029\n","Epoch 461/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9687\n","Epoch 461: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0905 - accuracy: 0.9687 - val_loss: 40.1272 - val_accuracy: 0.6503 - lr: 0.0025\n","Epoch 462/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9727\n","Epoch 462: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0756 - accuracy: 0.9727 - val_loss: 0.8102 - val_accuracy: 0.7932 - lr: 0.0021\n","Epoch 463/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9699\n","Epoch 463: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0818 - accuracy: 0.9699 - val_loss: 1.2020 - val_accuracy: 0.7664 - lr: 0.0018\n","Epoch 464/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9722\n","Epoch 464: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0745 - accuracy: 0.9722 - val_loss: 0.7118 - val_accuracy: 0.8214 - lr: 0.0015\n","Epoch 465/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9800\n","Epoch 465: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0627 - accuracy: 0.9800 - val_loss: 7.7216 - val_accuracy: 0.7287 - lr: 0.0013\n","Epoch 466/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9772\n","Epoch 466: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0632 - accuracy: 0.9772 - val_loss: 0.1842 - val_accuracy: 0.9464 - lr: 0.0011\n","Epoch 467/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9772\n","Epoch 467: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0689 - accuracy: 0.9772 - val_loss: 0.2549 - val_accuracy: 0.8616 - lr: 9.2647e-04\n","Epoch 468/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9817\n","Epoch 468: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.2567 - val_accuracy: 0.8641 - lr: 7.8750e-04\n","Epoch 469/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9797\n","Epoch 469: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0545 - accuracy: 0.9797 - val_loss: 0.6143 - val_accuracy: 0.8438 - lr: 6.6937e-04\n","Epoch 470/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9825\n","Epoch 470: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.3405 - val_accuracy: 0.9231 - lr: 5.6897e-04\n","Epoch 471/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9835\n","Epoch 471: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0474 - accuracy: 0.9835 - val_loss: 0.1675 - val_accuracy: 0.9618 - lr: 4.8362e-04\n","Epoch 472/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9830\n","Epoch 472: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0508 - accuracy: 0.9830 - val_loss: 0.3040 - val_accuracy: 0.9072 - lr: 4.1108e-04\n","Epoch 473/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9850\n","Epoch 473: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0454 - accuracy: 0.9850 - val_loss: 0.8757 - val_accuracy: 0.8616 - lr: 3.4942e-04\n","Epoch 474/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9805\n","Epoch 474: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0611 - accuracy: 0.9805 - val_loss: 0.1723 - val_accuracy: 0.9678 - lr: 2.9700e-04\n","Epoch 475/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9830\n","Epoch 475: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0434 - accuracy: 0.9830 - val_loss: 0.1246 - val_accuracy: 0.9702 - lr: 2.5245e-04\n","Epoch 476/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9817\n","Epoch 476: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0503 - accuracy: 0.9817 - val_loss: 8.8444 - val_accuracy: 0.8080 - lr: 0.0010\n","Epoch 477/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9780\n","Epoch 477: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0599 - accuracy: 0.9780 - val_loss: 0.8205 - val_accuracy: 0.8165 - lr: 0.0015\n","Epoch 478/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9762\n","Epoch 478: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0764 - accuracy: 0.9762 - val_loss: 0.3771 - val_accuracy: 0.9038 - lr: 0.0020\n","Epoch 479/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9722\n","Epoch 479: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0899 - accuracy: 0.9722 - val_loss: 0.2846 - val_accuracy: 0.9464 - lr: 0.0025\n","Epoch 480/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9662\n","Epoch 480: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1029 - accuracy: 0.9662 - val_loss: 1.7679 - val_accuracy: 0.7535 - lr: 0.0030\n","Epoch 481/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9659\n","Epoch 481: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1002 - accuracy: 0.9659 - val_loss: 66.6075 - val_accuracy: 0.4137 - lr: 0.0035\n","Epoch 482/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9607\n","Epoch 482: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1249 - accuracy: 0.9607 - val_loss: 15.2366 - val_accuracy: 0.6726 - lr: 0.0040\n","Epoch 483/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9644\n","Epoch 483: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1176 - accuracy: 0.9644 - val_loss: 0.9769 - val_accuracy: 0.7356 - lr: 0.0040\n","Epoch 484/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9687\n","Epoch 484: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1003 - accuracy: 0.9687 - val_loss: 4.6295 - val_accuracy: 0.7882 - lr: 0.0034\n","Epoch 485/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9642\n","Epoch 485: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1035 - accuracy: 0.9642 - val_loss: 2.4219 - val_accuracy: 0.6086 - lr: 0.0029\n","Epoch 486/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9714\n","Epoch 486: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0896 - accuracy: 0.9714 - val_loss: 71.0853 - val_accuracy: 0.6429 - lr: 0.0025\n","Epoch 487/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9699\n","Epoch 487: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0961 - accuracy: 0.9699 - val_loss: 2.4197 - val_accuracy: 0.6776 - lr: 0.0021\n","Epoch 488/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9785\n","Epoch 488: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0661 - accuracy: 0.9785 - val_loss: 0.4429 - val_accuracy: 0.9261 - lr: 0.0018\n","Epoch 489/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9770\n","Epoch 489: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0685 - accuracy: 0.9770 - val_loss: 0.6603 - val_accuracy: 0.8889 - lr: 0.0015\n","Epoch 490/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9787\n","Epoch 490: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 427ms/step - loss: 0.0592 - accuracy: 0.9787 - val_loss: 16.5042 - val_accuracy: 0.7088 - lr: 0.0013\n","Epoch 491/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9800\n","Epoch 491: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0539 - accuracy: 0.9800 - val_loss: 0.4665 - val_accuracy: 0.8720 - lr: 0.0011\n","Epoch 492/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9795\n","Epoch 492: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0606 - accuracy: 0.9795 - val_loss: 0.2153 - val_accuracy: 0.9370 - lr: 9.2647e-04\n","Epoch 493/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9785\n","Epoch 493: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0617 - accuracy: 0.9785 - val_loss: 0.1303 - val_accuracy: 0.9588 - lr: 7.8750e-04\n","Epoch 494/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9847\n","Epoch 494: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0493 - accuracy: 0.9847 - val_loss: 1.2524 - val_accuracy: 0.8438 - lr: 6.6937e-04\n","Epoch 495/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9825\n","Epoch 495: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.3704 - val_accuracy: 0.8973 - lr: 5.6897e-04\n","Epoch 496/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9800\n","Epoch 496: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.1336 - val_accuracy: 0.9539 - lr: 4.8362e-04\n","Epoch 497/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9825\n","Epoch 497: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0496 - accuracy: 0.9825 - val_loss: 0.1496 - val_accuracy: 0.9405 - lr: 4.1108e-04\n","Epoch 498/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9877\n","Epoch 498: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 0.1807 - val_accuracy: 0.9201 - lr: 3.4942e-04\n","Epoch 499/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9830\n","Epoch 499: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0462 - accuracy: 0.9830 - val_loss: 0.1338 - val_accuracy: 0.9578 - lr: 2.9700e-04\n","Epoch 500/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9802\n","Epoch 500: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0567 - accuracy: 0.9802 - val_loss: 0.0934 - val_accuracy: 0.9722 - lr: 2.5245e-04\n","Epoch 501/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9837\n","Epoch 501: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 2.1484 - val_accuracy: 0.8041 - lr: 0.0010\n","Epoch 502/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9822\n","Epoch 502: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0540 - accuracy: 0.9822 - val_loss: 0.2317 - val_accuracy: 0.9330 - lr: 0.0015\n","Epoch 503/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9782\n","Epoch 503: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0700 - accuracy: 0.9782 - val_loss: 0.3680 - val_accuracy: 0.8700 - lr: 0.0020\n","Epoch 504/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9719\n","Epoch 504: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0847 - accuracy: 0.9719 - val_loss: 3.7056 - val_accuracy: 0.7812 - lr: 0.0025\n","Epoch 505/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.9729\n","Epoch 505: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0862 - accuracy: 0.9729 - val_loss: 0.4852 - val_accuracy: 0.8735 - lr: 0.0030\n","Epoch 506/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9639\n","Epoch 506: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1100 - accuracy: 0.9639 - val_loss: 2.1154 - val_accuracy: 0.6910 - lr: 0.0035\n","Epoch 507/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9622\n","Epoch 507: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 427ms/step - loss: 0.1118 - accuracy: 0.9622 - val_loss: 6.9144 - val_accuracy: 0.6131 - lr: 0.0040\n","Epoch 508/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9619\n","Epoch 508: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 423ms/step - loss: 0.1243 - accuracy: 0.9619 - val_loss: 64.6019 - val_accuracy: 0.5938 - lr: 0.0040\n","Epoch 509/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9629\n","Epoch 509: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0998 - accuracy: 0.9629 - val_loss: 0.7271 - val_accuracy: 0.7644 - lr: 0.0034\n","Epoch 510/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9642\n","Epoch 510: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 425ms/step - loss: 0.1040 - accuracy: 0.9642 - val_loss: 1.6811 - val_accuracy: 0.7396 - lr: 0.0029\n","Epoch 511/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9672\n","Epoch 511: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0947 - accuracy: 0.9672 - val_loss: 0.1781 - val_accuracy: 0.9350 - lr: 0.0025\n","Epoch 512/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9770\n","Epoch 512: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0637 - accuracy: 0.9770 - val_loss: 7.0683 - val_accuracy: 0.7168 - lr: 0.0021\n","Epoch 513/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9772\n","Epoch 513: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0714 - accuracy: 0.9772 - val_loss: 38.9102 - val_accuracy: 0.6825 - lr: 0.0018\n","Epoch 514/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9742\n","Epoch 514: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 419ms/step - loss: 0.0674 - accuracy: 0.9742 - val_loss: 1.5877 - val_accuracy: 0.7956 - lr: 0.0015\n","Epoch 515/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9785\n","Epoch 515: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0662 - accuracy: 0.9785 - val_loss: 1.5342 - val_accuracy: 0.7431 - lr: 0.0013\n","Epoch 516/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9787\n","Epoch 516: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0534 - accuracy: 0.9787 - val_loss: 23.7440 - val_accuracy: 0.7307 - lr: 0.0011\n","Epoch 517/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9822\n","Epoch 517: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0490 - accuracy: 0.9822 - val_loss: 0.2684 - val_accuracy: 0.9187 - lr: 9.2647e-04\n","Epoch 518/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9850\n","Epoch 518: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.0980 - val_accuracy: 0.9762 - lr: 7.8750e-04\n","Epoch 519/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9860\n","Epoch 519: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0437 - accuracy: 0.9860 - val_loss: 0.1259 - val_accuracy: 0.9668 - lr: 6.6937e-04\n","Epoch 520/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9825\n","Epoch 520: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 417ms/step - loss: 0.0521 - accuracy: 0.9825 - val_loss: 0.2183 - val_accuracy: 0.9435 - lr: 5.6897e-04\n","Epoch 521/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9815\n","Epoch 521: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0457 - accuracy: 0.9815 - val_loss: 0.3291 - val_accuracy: 0.9157 - lr: 4.8362e-04\n","Epoch 522/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9825\n","Epoch 522: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0578 - accuracy: 0.9825 - val_loss: 0.1312 - val_accuracy: 0.9678 - lr: 4.1108e-04\n","Epoch 523/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9867\n","Epoch 523: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0389 - accuracy: 0.9867 - val_loss: 0.1812 - val_accuracy: 0.9534 - lr: 3.4942e-04\n","Epoch 524/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9870\n","Epoch 524: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0506 - accuracy: 0.9870 - val_loss: 0.1240 - val_accuracy: 0.9697 - lr: 2.9700e-04\n","Epoch 525/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9812\n","Epoch 525: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0554 - accuracy: 0.9812 - val_loss: 0.1141 - val_accuracy: 0.9712 - lr: 2.5245e-04\n","Epoch 526/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9860\n","Epoch 526: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.1937 - val_accuracy: 0.9524 - lr: 0.0010\n","Epoch 527/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9817\n","Epoch 527: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0557 - accuracy: 0.9817 - val_loss: 3.5270 - val_accuracy: 0.8204 - lr: 0.0015\n","Epoch 528/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9719\n","Epoch 528: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0748 - accuracy: 0.9719 - val_loss: 0.3459 - val_accuracy: 0.9127 - lr: 0.0020\n","Epoch 529/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9712\n","Epoch 529: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0818 - accuracy: 0.9712 - val_loss: 0.4428 - val_accuracy: 0.9221 - lr: 0.0025\n","Epoch 530/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9702\n","Epoch 530: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1000 - accuracy: 0.9702 - val_loss: 4.1518 - val_accuracy: 0.4370 - lr: 0.0030\n","Epoch 531/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9692\n","Epoch 531: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0980 - accuracy: 0.9692 - val_loss: 392.4352 - val_accuracy: 0.5689 - lr: 0.0035\n","Epoch 532/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9589\n","Epoch 532: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1199 - accuracy: 0.9589 - val_loss: 6.4791 - val_accuracy: 0.5427 - lr: 0.0040\n","Epoch 533/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9624\n","Epoch 533: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 424ms/step - loss: 0.1150 - accuracy: 0.9624 - val_loss: 12.1863 - val_accuracy: 0.5942 - lr: 0.0040\n","Epoch 534/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9619\n","Epoch 534: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.1067 - accuracy: 0.9619 - val_loss: 106.7894 - val_accuracy: 0.5273 - lr: 0.0034\n","Epoch 535/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9689\n","Epoch 535: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0868 - accuracy: 0.9689 - val_loss: 2.8704 - val_accuracy: 0.6721 - lr: 0.0029\n","Epoch 536/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9722\n","Epoch 536: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 418ms/step - loss: 0.0901 - accuracy: 0.9722 - val_loss: 0.9796 - val_accuracy: 0.8408 - lr: 0.0025\n","Epoch 537/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9770\n","Epoch 537: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0718 - accuracy: 0.9770 - val_loss: 2.6084 - val_accuracy: 0.6920 - lr: 0.0021\n","Epoch 538/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9739\n","Epoch 538: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0764 - accuracy: 0.9739 - val_loss: 1.8799 - val_accuracy: 0.7649 - lr: 0.0018\n","Epoch 539/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9795\n","Epoch 539: val_loss did not improve from 0.08443\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0597 - accuracy: 0.9795 - val_loss: 0.4605 - val_accuracy: 0.9008 - lr: 0.0015\n","Epoch 540/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9780\n","Epoch 540: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0572 - accuracy: 0.9780 - val_loss: 10.2251 - val_accuracy: 0.7674 - lr: 0.0013\n","Epoch 541/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9840\n","Epoch 541: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0552 - accuracy: 0.9840 - val_loss: 0.1418 - val_accuracy: 0.9559 - lr: 0.0011\n","Epoch 542/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9790\n","Epoch 542: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0587 - accuracy: 0.9790 - val_loss: 0.4840 - val_accuracy: 0.8968 - lr: 9.2647e-04\n","Epoch 543/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9817\n","Epoch 543: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0568 - accuracy: 0.9817 - val_loss: 0.2821 - val_accuracy: 0.9117 - lr: 7.8750e-04\n","Epoch 544/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9852\n","Epoch 544: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 0.2265 - val_accuracy: 0.9191 - lr: 6.6937e-04\n","Epoch 545/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9832\n","Epoch 545: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0447 - accuracy: 0.9832 - val_loss: 0.1690 - val_accuracy: 0.9544 - lr: 5.6897e-04\n","Epoch 546/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9830\n","Epoch 546: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0493 - accuracy: 0.9830 - val_loss: 0.2255 - val_accuracy: 0.9425 - lr: 4.8362e-04\n","Epoch 547/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9880\n","Epoch 547: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0368 - accuracy: 0.9880 - val_loss: 0.1159 - val_accuracy: 0.9658 - lr: 4.1108e-04\n","Epoch 548/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9857\n","Epoch 548: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0436 - accuracy: 0.9857 - val_loss: 0.0977 - val_accuracy: 0.9663 - lr: 3.4942e-04\n","Epoch 549/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9877\n","Epoch 549: val_loss did not improve from 0.08443\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0401 - accuracy: 0.9877 - val_loss: 0.1066 - val_accuracy: 0.9643 - lr: 2.9700e-04\n","Epoch 550/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9867\n","Epoch 550: val_loss improved from 0.08443 to 0.08016, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 32s 478ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.0802 - val_accuracy: 0.9737 - lr: 2.5245e-04\n","Epoch 551/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9842\n","Epoch 551: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.6522 - val_accuracy: 0.8676 - lr: 0.0010\n","Epoch 552/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9752\n","Epoch 552: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0608 - accuracy: 0.9752 - val_loss: 0.7685 - val_accuracy: 0.8224 - lr: 0.0015\n","Epoch 553/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9782\n","Epoch 553: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0674 - accuracy: 0.9782 - val_loss: 1.5922 - val_accuracy: 0.8512 - lr: 0.0020\n","Epoch 554/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9772\n","Epoch 554: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0659 - accuracy: 0.9772 - val_loss: 1.0976 - val_accuracy: 0.8061 - lr: 0.0025\n","Epoch 555/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9684\n","Epoch 555: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0960 - accuracy: 0.9684 - val_loss: 3.1295 - val_accuracy: 0.6503 - lr: 0.0030\n","Epoch 556/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9689\n","Epoch 556: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 418ms/step - loss: 0.0973 - accuracy: 0.9689 - val_loss: 7.5785 - val_accuracy: 0.7138 - lr: 0.0035\n","Epoch 557/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9607\n","Epoch 557: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1200 - accuracy: 0.9607 - val_loss: 21.2067 - val_accuracy: 0.6493 - lr: 0.0040\n","Epoch 558/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9629\n","Epoch 558: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1112 - accuracy: 0.9629 - val_loss: 13.0641 - val_accuracy: 0.6136 - lr: 0.0040\n","Epoch 559/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.9632\n","Epoch 559: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.1171 - accuracy: 0.9632 - val_loss: 0.4188 - val_accuracy: 0.8616 - lr: 0.0034\n","Epoch 560/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9707\n","Epoch 560: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0898 - accuracy: 0.9707 - val_loss: 1.2819 - val_accuracy: 0.6558 - lr: 0.0029\n","Epoch 561/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9742\n","Epoch 561: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0770 - accuracy: 0.9742 - val_loss: 2.0445 - val_accuracy: 0.7128 - lr: 0.0025\n","Epoch 562/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9755\n","Epoch 562: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0768 - accuracy: 0.9755 - val_loss: 0.4461 - val_accuracy: 0.8571 - lr: 0.0021\n","Epoch 563/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9762\n","Epoch 563: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0674 - accuracy: 0.9762 - val_loss: 0.9662 - val_accuracy: 0.7738 - lr: 0.0018\n","Epoch 564/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9797\n","Epoch 564: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 440ms/step - loss: 0.0593 - accuracy: 0.9797 - val_loss: 0.2755 - val_accuracy: 0.9092 - lr: 0.0015\n","Epoch 565/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9785\n","Epoch 565: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0601 - accuracy: 0.9785 - val_loss: 0.9958 - val_accuracy: 0.8428 - lr: 0.0013\n","Epoch 566/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9825\n","Epoch 566: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0548 - accuracy: 0.9825 - val_loss: 37.2141 - val_accuracy: 0.6275 - lr: 0.0011\n","Epoch 567/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9822\n","Epoch 567: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.6469 - val_accuracy: 0.8938 - lr: 9.2647e-04\n","Epoch 568/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9837\n","Epoch 568: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0455 - accuracy: 0.9837 - val_loss: 1.6450 - val_accuracy: 0.8150 - lr: 7.8750e-04\n","Epoch 569/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9822\n","Epoch 569: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0521 - accuracy: 0.9822 - val_loss: 0.2705 - val_accuracy: 0.9390 - lr: 6.6937e-04\n","Epoch 570/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9825\n","Epoch 570: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0501 - accuracy: 0.9825 - val_loss: 0.6796 - val_accuracy: 0.8844 - lr: 5.6897e-04\n","Epoch 571/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9822\n","Epoch 571: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0472 - accuracy: 0.9822 - val_loss: 0.0821 - val_accuracy: 0.9712 - lr: 4.8362e-04\n","Epoch 572/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9865\n","Epoch 572: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0453 - accuracy: 0.9865 - val_loss: 0.1123 - val_accuracy: 0.9653 - lr: 4.1108e-04\n","Epoch 573/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9875\n","Epoch 573: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0445 - accuracy: 0.9875 - val_loss: 0.1145 - val_accuracy: 0.9658 - lr: 3.4942e-04\n","Epoch 574/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9880\n","Epoch 574: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0358 - accuracy: 0.9880 - val_loss: 0.1121 - val_accuracy: 0.9638 - lr: 2.9700e-04\n","Epoch 575/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9877\n","Epoch 575: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0426 - accuracy: 0.9877 - val_loss: 0.1475 - val_accuracy: 0.9563 - lr: 2.5245e-04\n","Epoch 576/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9840\n","Epoch 576: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0461 - accuracy: 0.9840 - val_loss: 1.4183 - val_accuracy: 0.8442 - lr: 0.0010\n","Epoch 577/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9812\n","Epoch 577: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0495 - accuracy: 0.9812 - val_loss: 0.7397 - val_accuracy: 0.8110 - lr: 0.0015\n","Epoch 578/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9775\n","Epoch 578: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0670 - accuracy: 0.9775 - val_loss: 0.5433 - val_accuracy: 0.8487 - lr: 0.0020\n","Epoch 579/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9742\n","Epoch 579: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0767 - accuracy: 0.9742 - val_loss: 42.4787 - val_accuracy: 0.6310 - lr: 0.0025\n","Epoch 580/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9657\n","Epoch 580: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0957 - accuracy: 0.9657 - val_loss: 2.9823 - val_accuracy: 0.6736 - lr: 0.0030\n","Epoch 581/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9649\n","Epoch 581: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1055 - accuracy: 0.9649 - val_loss: 2.0539 - val_accuracy: 0.7688 - lr: 0.0035\n","Epoch 582/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9642\n","Epoch 582: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1080 - accuracy: 0.9642 - val_loss: 1.1189 - val_accuracy: 0.7649 - lr: 0.0040\n","Epoch 583/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9634\n","Epoch 583: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1028 - accuracy: 0.9634 - val_loss: 16.3738 - val_accuracy: 0.6682 - lr: 0.0040\n","Epoch 584/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9672\n","Epoch 584: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0981 - accuracy: 0.9672 - val_loss: 82.9111 - val_accuracy: 0.5208 - lr: 0.0034\n","Epoch 585/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9719\n","Epoch 585: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 420ms/step - loss: 0.0823 - accuracy: 0.9719 - val_loss: 0.7883 - val_accuracy: 0.8447 - lr: 0.0029\n","Epoch 586/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9775\n","Epoch 586: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0671 - accuracy: 0.9775 - val_loss: 0.8610 - val_accuracy: 0.7932 - lr: 0.0025\n","Epoch 587/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9755\n","Epoch 587: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0690 - accuracy: 0.9755 - val_loss: 1.6224 - val_accuracy: 0.8428 - lr: 0.0021\n","Epoch 588/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9780\n","Epoch 588: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0637 - accuracy: 0.9780 - val_loss: 5.4289 - val_accuracy: 0.7331 - lr: 0.0018\n","Epoch 589/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9790\n","Epoch 589: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0597 - accuracy: 0.9790 - val_loss: 1.1346 - val_accuracy: 0.7738 - lr: 0.0015\n","Epoch 590/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9812\n","Epoch 590: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0589 - accuracy: 0.9812 - val_loss: 2.0836 - val_accuracy: 0.7440 - lr: 0.0013\n","Epoch 591/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9800\n","Epoch 591: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0543 - accuracy: 0.9800 - val_loss: 0.3057 - val_accuracy: 0.8993 - lr: 0.0011\n","Epoch 592/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9817\n","Epoch 592: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0500 - accuracy: 0.9817 - val_loss: 0.3231 - val_accuracy: 0.8586 - lr: 9.2647e-04\n","Epoch 593/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9842\n","Epoch 593: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0476 - accuracy: 0.9842 - val_loss: 0.4371 - val_accuracy: 0.9539 - lr: 7.8750e-04\n","Epoch 594/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9860\n","Epoch 594: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 0.3421 - val_accuracy: 0.9549 - lr: 6.6937e-04\n","Epoch 595/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9857\n","Epoch 595: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 2.3533 - val_accuracy: 0.8477 - lr: 5.6897e-04\n","Epoch 596/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9885\n","Epoch 596: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.1411 - val_accuracy: 0.9658 - lr: 4.8362e-04\n","Epoch 597/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9857\n","Epoch 597: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0477 - accuracy: 0.9857 - val_loss: 0.2576 - val_accuracy: 0.9122 - lr: 4.1108e-04\n","Epoch 598/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9860\n","Epoch 598: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.3199 - val_accuracy: 0.9405 - lr: 3.4942e-04\n","Epoch 599/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9887\n","Epoch 599: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.1137 - val_accuracy: 0.9678 - lr: 2.9700e-04\n","Epoch 600/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9872\n","Epoch 600: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 0.1198 - val_accuracy: 0.9613 - lr: 2.5245e-04\n","Epoch 601/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9857\n","Epoch 601: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.4605 - val_accuracy: 0.9380 - lr: 0.0010\n","Epoch 602/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9810\n","Epoch 602: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 418ms/step - loss: 0.0491 - accuracy: 0.9810 - val_loss: 0.6558 - val_accuracy: 0.8070 - lr: 0.0015\n","Epoch 603/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9767\n","Epoch 603: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0680 - accuracy: 0.9767 - val_loss: 0.7949 - val_accuracy: 0.8566 - lr: 0.0020\n","Epoch 604/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9739\n","Epoch 604: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0787 - accuracy: 0.9739 - val_loss: 0.7874 - val_accuracy: 0.7649 - lr: 0.0025\n","Epoch 605/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9722\n","Epoch 605: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0763 - accuracy: 0.9722 - val_loss: 0.4431 - val_accuracy: 0.8770 - lr: 0.0030\n","Epoch 606/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9667\n","Epoch 606: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1017 - accuracy: 0.9667 - val_loss: 15.6216 - val_accuracy: 0.7386 - lr: 0.0035\n","Epoch 607/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9687\n","Epoch 607: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.1002 - accuracy: 0.9687 - val_loss: 3.5775 - val_accuracy: 0.6270 - lr: 0.0040\n","Epoch 608/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9659\n","Epoch 608: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0953 - accuracy: 0.9659 - val_loss: 23.6428 - val_accuracy: 0.5357 - lr: 0.0040\n","Epoch 609/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9704\n","Epoch 609: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0988 - accuracy: 0.9704 - val_loss: 10.0957 - val_accuracy: 0.6801 - lr: 0.0034\n","Epoch 610/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9722\n","Epoch 610: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0808 - accuracy: 0.9722 - val_loss: 35.4793 - val_accuracy: 0.6835 - lr: 0.0029\n","Epoch 611/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9719\n","Epoch 611: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0890 - accuracy: 0.9719 - val_loss: 43.5241 - val_accuracy: 0.6508 - lr: 0.0025\n","Epoch 612/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9744\n","Epoch 612: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0766 - accuracy: 0.9744 - val_loss: 0.2334 - val_accuracy: 0.9425 - lr: 0.0021\n","Epoch 613/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9790\n","Epoch 613: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0653 - accuracy: 0.9790 - val_loss: 0.3648 - val_accuracy: 0.9157 - lr: 0.0018\n","Epoch 614/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9815\n","Epoch 614: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0549 - accuracy: 0.9815 - val_loss: 1.4309 - val_accuracy: 0.8041 - lr: 0.0015\n","Epoch 615/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9822\n","Epoch 615: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0634 - accuracy: 0.9822 - val_loss: 0.2665 - val_accuracy: 0.9187 - lr: 0.0013\n","Epoch 616/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9842\n","Epoch 616: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0496 - accuracy: 0.9842 - val_loss: 2.2239 - val_accuracy: 0.7986 - lr: 0.0011\n","Epoch 617/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9867\n","Epoch 617: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0477 - accuracy: 0.9867 - val_loss: 1.1178 - val_accuracy: 0.8433 - lr: 9.2647e-04\n","Epoch 618/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9857\n","Epoch 618: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 435ms/step - loss: 0.0401 - accuracy: 0.9857 - val_loss: 0.1811 - val_accuracy: 0.9539 - lr: 7.8750e-04\n","Epoch 619/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9847\n","Epoch 619: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 0.1914 - val_accuracy: 0.9534 - lr: 6.6937e-04\n","Epoch 620/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9885\n","Epoch 620: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 418ms/step - loss: 0.0383 - accuracy: 0.9885 - val_loss: 1.4262 - val_accuracy: 0.8502 - lr: 5.6897e-04\n","Epoch 621/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9870\n","Epoch 621: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.1735 - val_accuracy: 0.9415 - lr: 4.8362e-04\n","Epoch 622/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9832\n","Epoch 622: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0526 - accuracy: 0.9832 - val_loss: 1.0452 - val_accuracy: 0.8700 - lr: 4.1108e-04\n","Epoch 623/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9882\n","Epoch 623: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 0.4008 - val_accuracy: 0.8824 - lr: 3.4942e-04\n","Epoch 624/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9855\n","Epoch 624: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0372 - accuracy: 0.9855 - val_loss: 0.1119 - val_accuracy: 0.9727 - lr: 2.9700e-04\n","Epoch 625/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9850\n","Epoch 625: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0411 - accuracy: 0.9850 - val_loss: 0.1148 - val_accuracy: 0.9603 - lr: 2.5245e-04\n","Epoch 626/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9847\n","Epoch 626: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0509 - accuracy: 0.9847 - val_loss: 0.4540 - val_accuracy: 0.8810 - lr: 0.0010\n","Epoch 627/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9835\n","Epoch 627: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0494 - accuracy: 0.9835 - val_loss: 2.5760 - val_accuracy: 0.8155 - lr: 0.0015\n","Epoch 628/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9787\n","Epoch 628: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0626 - accuracy: 0.9787 - val_loss: 0.6598 - val_accuracy: 0.8333 - lr: 0.0020\n","Epoch 629/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9787\n","Epoch 629: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0692 - accuracy: 0.9787 - val_loss: 3.0128 - val_accuracy: 0.6974 - lr: 0.0025\n","Epoch 630/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9699\n","Epoch 630: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0885 - accuracy: 0.9699 - val_loss: 5.5769 - val_accuracy: 0.7232 - lr: 0.0030\n","Epoch 631/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9687\n","Epoch 631: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0949 - accuracy: 0.9687 - val_loss: 3.6551 - val_accuracy: 0.7093 - lr: 0.0035\n","Epoch 632/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9704\n","Epoch 632: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0947 - accuracy: 0.9704 - val_loss: 0.6639 - val_accuracy: 0.8189 - lr: 0.0040\n","Epoch 633/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9654\n","Epoch 633: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 422ms/step - loss: 0.1098 - accuracy: 0.9654 - val_loss: 2.1306 - val_accuracy: 0.6687 - lr: 0.0040\n","Epoch 634/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9669\n","Epoch 634: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0874 - accuracy: 0.9669 - val_loss: 1.5779 - val_accuracy: 0.6002 - lr: 0.0034\n","Epoch 635/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9697\n","Epoch 635: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0915 - accuracy: 0.9697 - val_loss: 4.0367 - val_accuracy: 0.6007 - lr: 0.0029\n","Epoch 636/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9737\n","Epoch 636: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0724 - accuracy: 0.9737 - val_loss: 0.3417 - val_accuracy: 0.9226 - lr: 0.0025\n","Epoch 637/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9762\n","Epoch 637: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 418ms/step - loss: 0.0729 - accuracy: 0.9762 - val_loss: 0.7064 - val_accuracy: 0.8507 - lr: 0.0021\n","Epoch 638/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9787\n","Epoch 638: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0637 - accuracy: 0.9787 - val_loss: 84.9733 - val_accuracy: 0.6632 - lr: 0.0018\n","Epoch 639/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9780\n","Epoch 639: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0600 - accuracy: 0.9780 - val_loss: 0.7616 - val_accuracy: 0.8413 - lr: 0.0015\n","Epoch 640/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9805\n","Epoch 640: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0586 - accuracy: 0.9805 - val_loss: 0.2572 - val_accuracy: 0.9157 - lr: 0.0013\n","Epoch 641/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9817\n","Epoch 641: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 0.6881 - val_accuracy: 0.8309 - lr: 0.0011\n","Epoch 642/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9832\n","Epoch 642: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 3.8410 - val_accuracy: 0.8080 - lr: 9.2647e-04\n","Epoch 643/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9812\n","Epoch 643: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0567 - accuracy: 0.9812 - val_loss: 0.2676 - val_accuracy: 0.9330 - lr: 7.8750e-04\n","Epoch 644/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9850\n","Epoch 644: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 432ms/step - loss: 0.0418 - accuracy: 0.9850 - val_loss: 0.2623 - val_accuracy: 0.9097 - lr: 6.6937e-04\n","Epoch 645/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9862\n","Epoch 645: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 0.2391 - val_accuracy: 0.9519 - lr: 5.6897e-04\n","Epoch 646/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9892\n","Epoch 646: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0371 - accuracy: 0.9892 - val_loss: 0.6778 - val_accuracy: 0.8497 - lr: 4.8362e-04\n","Epoch 647/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9855\n","Epoch 647: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0460 - accuracy: 0.9855 - val_loss: 0.1124 - val_accuracy: 0.9707 - lr: 4.1108e-04\n","Epoch 648/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9897\n","Epoch 648: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0373 - accuracy: 0.9897 - val_loss: 0.4841 - val_accuracy: 0.8819 - lr: 3.4942e-04\n","Epoch 649/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9860\n","Epoch 649: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.0915 - val_accuracy: 0.9737 - lr: 2.9700e-04\n","Epoch 650/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9857\n","Epoch 650: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0380 - accuracy: 0.9857 - val_loss: 0.3746 - val_accuracy: 0.8988 - lr: 2.5245e-04\n","Epoch 651/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9857\n","Epoch 651: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 438ms/step - loss: 0.0387 - accuracy: 0.9857 - val_loss: 0.8429 - val_accuracy: 0.8681 - lr: 0.0010\n","Epoch 652/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9830\n","Epoch 652: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0513 - accuracy: 0.9830 - val_loss: 0.6747 - val_accuracy: 0.8284 - lr: 0.0015\n","Epoch 653/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9742\n","Epoch 653: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0695 - accuracy: 0.9742 - val_loss: 102.8057 - val_accuracy: 0.5417 - lr: 0.0020\n","Epoch 654/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9800\n","Epoch 654: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0610 - accuracy: 0.9800 - val_loss: 7.2180 - val_accuracy: 0.7113 - lr: 0.0025\n","Epoch 655/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9729\n","Epoch 655: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0850 - accuracy: 0.9729 - val_loss: 0.8657 - val_accuracy: 0.8606 - lr: 0.0030\n","Epoch 656/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9732\n","Epoch 656: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0810 - accuracy: 0.9732 - val_loss: 0.3311 - val_accuracy: 0.8953 - lr: 0.0035\n","Epoch 657/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9667\n","Epoch 657: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1023 - accuracy: 0.9667 - val_loss: 67.6590 - val_accuracy: 0.5759 - lr: 0.0040\n","Epoch 658/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9652\n","Epoch 658: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1072 - accuracy: 0.9652 - val_loss: 0.8129 - val_accuracy: 0.7961 - lr: 0.0040\n","Epoch 659/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9702\n","Epoch 659: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0903 - accuracy: 0.9702 - val_loss: 4.2002 - val_accuracy: 0.6022 - lr: 0.0034\n","Epoch 660/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9729\n","Epoch 660: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0795 - accuracy: 0.9729 - val_loss: 3.3195 - val_accuracy: 0.6776 - lr: 0.0029\n","Epoch 661/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9755\n","Epoch 661: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0769 - accuracy: 0.9755 - val_loss: 1.4067 - val_accuracy: 0.6835 - lr: 0.0025\n","Epoch 662/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9770\n","Epoch 662: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0723 - accuracy: 0.9770 - val_loss: 0.3198 - val_accuracy: 0.9246 - lr: 0.0021\n","Epoch 663/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9770\n","Epoch 663: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0634 - accuracy: 0.9770 - val_loss: 1.0632 - val_accuracy: 0.7852 - lr: 0.0018\n","Epoch 664/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9812\n","Epoch 664: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0547 - accuracy: 0.9812 - val_loss: 0.1381 - val_accuracy: 0.9643 - lr: 0.0015\n","Epoch 665/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9805\n","Epoch 665: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0549 - accuracy: 0.9805 - val_loss: 0.5329 - val_accuracy: 0.9182 - lr: 0.0013\n","Epoch 666/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9830\n","Epoch 666: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0511 - accuracy: 0.9830 - val_loss: 0.2316 - val_accuracy: 0.9405 - lr: 0.0011\n","Epoch 667/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9870\n","Epoch 667: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 0.1426 - val_accuracy: 0.9598 - lr: 9.2647e-04\n","Epoch 668/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9832\n","Epoch 668: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0477 - accuracy: 0.9832 - val_loss: 1.4844 - val_accuracy: 0.8467 - lr: 7.8750e-04\n","Epoch 669/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9877\n","Epoch 669: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0388 - accuracy: 0.9877 - val_loss: 0.1461 - val_accuracy: 0.9494 - lr: 6.6937e-04\n","Epoch 670/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9835\n","Epoch 670: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0465 - accuracy: 0.9835 - val_loss: 0.1571 - val_accuracy: 0.9598 - lr: 5.6897e-04\n","Epoch 671/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9862\n","Epoch 671: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 0.3866 - val_accuracy: 0.9325 - lr: 4.8362e-04\n","Epoch 672/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9837\n","Epoch 672: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.2111 - val_accuracy: 0.9360 - lr: 4.1108e-04\n","Epoch 673/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9857\n","Epoch 673: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0370 - accuracy: 0.9857 - val_loss: 0.1610 - val_accuracy: 0.9578 - lr: 3.4942e-04\n","Epoch 674/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9892\n","Epoch 674: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.1480 - val_accuracy: 0.9499 - lr: 2.9700e-04\n","Epoch 675/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9870\n","Epoch 675: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0432 - accuracy: 0.9870 - val_loss: 0.1916 - val_accuracy: 0.9271 - lr: 2.5245e-04\n","Epoch 676/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9887\n","Epoch 676: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 0.1412 - val_accuracy: 0.9598 - lr: 0.0010\n","Epoch 677/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9812\n","Epoch 677: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0543 - accuracy: 0.9812 - val_loss: 0.3635 - val_accuracy: 0.9494 - lr: 0.0015\n","Epoch 678/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9812\n","Epoch 678: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0593 - accuracy: 0.9812 - val_loss: 165.4785 - val_accuracy: 0.6260 - lr: 0.0020\n","Epoch 679/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9787\n","Epoch 679: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0658 - accuracy: 0.9787 - val_loss: 5.1960 - val_accuracy: 0.6240 - lr: 0.0025\n","Epoch 680/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9752\n","Epoch 680: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0706 - accuracy: 0.9752 - val_loss: 29.2166 - val_accuracy: 0.6091 - lr: 0.0030\n","Epoch 681/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9717\n","Epoch 681: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0893 - accuracy: 0.9717 - val_loss: 2.7525 - val_accuracy: 0.6652 - lr: 0.0035\n","Epoch 682/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9699\n","Epoch 682: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0913 - accuracy: 0.9699 - val_loss: 278.1924 - val_accuracy: 0.5561 - lr: 0.0040\n","Epoch 683/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9689\n","Epoch 683: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0972 - accuracy: 0.9689 - val_loss: 0.8839 - val_accuracy: 0.7763 - lr: 0.0040\n","Epoch 684/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9739\n","Epoch 684: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0832 - accuracy: 0.9739 - val_loss: 9.0339 - val_accuracy: 0.6443 - lr: 0.0034\n","Epoch 685/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9792\n","Epoch 685: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0678 - accuracy: 0.9792 - val_loss: 0.3771 - val_accuracy: 0.9132 - lr: 0.0029\n","Epoch 686/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9755\n","Epoch 686: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0749 - accuracy: 0.9755 - val_loss: 61.7709 - val_accuracy: 0.6186 - lr: 0.0025\n","Epoch 687/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9807\n","Epoch 687: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0652 - accuracy: 0.9807 - val_loss: 0.1587 - val_accuracy: 0.9499 - lr: 0.0021\n","Epoch 688/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9775\n","Epoch 688: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0648 - accuracy: 0.9775 - val_loss: 0.5430 - val_accuracy: 0.8264 - lr: 0.0018\n","Epoch 689/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9845\n","Epoch 689: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0445 - accuracy: 0.9845 - val_loss: 49.0367 - val_accuracy: 0.6969 - lr: 0.0015\n","Epoch 690/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9827\n","Epoch 690: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0514 - accuracy: 0.9827 - val_loss: 20.9649 - val_accuracy: 0.7604 - lr: 0.0013\n","Epoch 691/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9857\n","Epoch 691: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0407 - accuracy: 0.9857 - val_loss: 0.2169 - val_accuracy: 0.9573 - lr: 0.0011\n","Epoch 692/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9847\n","Epoch 692: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0416 - accuracy: 0.9847 - val_loss: 0.1087 - val_accuracy: 0.9668 - lr: 9.2647e-04\n","Epoch 693/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9860\n","Epoch 693: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0405 - accuracy: 0.9860 - val_loss: 0.5811 - val_accuracy: 0.9291 - lr: 7.8750e-04\n","Epoch 694/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9855\n","Epoch 694: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0469 - accuracy: 0.9855 - val_loss: 0.1119 - val_accuracy: 0.9638 - lr: 6.6937e-04\n","Epoch 695/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9857\n","Epoch 695: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 0.2182 - val_accuracy: 0.9425 - lr: 5.6897e-04\n","Epoch 696/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9890\n","Epoch 696: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.1509 - val_accuracy: 0.9618 - lr: 4.8362e-04\n","Epoch 697/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9897\n","Epoch 697: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0281 - accuracy: 0.9897 - val_loss: 0.4655 - val_accuracy: 0.9117 - lr: 4.1108e-04\n","Epoch 698/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9887\n","Epoch 698: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0298 - accuracy: 0.9887 - val_loss: 0.2464 - val_accuracy: 0.9097 - lr: 3.4942e-04\n","Epoch 699/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9870\n","Epoch 699: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0358 - accuracy: 0.9870 - val_loss: 0.1114 - val_accuracy: 0.9712 - lr: 2.9700e-04\n","Epoch 700/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9897\n","Epoch 700: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 0.0967 - val_accuracy: 0.9707 - lr: 2.5245e-04\n","Epoch 701/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9865\n","Epoch 701: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.7239 - val_accuracy: 0.8353 - lr: 0.0010\n","Epoch 702/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9840\n","Epoch 702: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0502 - accuracy: 0.9840 - val_loss: 1.6898 - val_accuracy: 0.8145 - lr: 0.0015\n","Epoch 703/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9802\n","Epoch 703: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0568 - accuracy: 0.9802 - val_loss: 0.4299 - val_accuracy: 0.9127 - lr: 0.0020\n","Epoch 704/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9795\n","Epoch 704: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0706 - accuracy: 0.9795 - val_loss: 1.2558 - val_accuracy: 0.7183 - lr: 0.0025\n","Epoch 705/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9719\n","Epoch 705: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0866 - accuracy: 0.9719 - val_loss: 2.4509 - val_accuracy: 0.7733 - lr: 0.0030\n","Epoch 706/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9709\n","Epoch 706: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0869 - accuracy: 0.9709 - val_loss: 10.3720 - val_accuracy: 0.6270 - lr: 0.0035\n","Epoch 707/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9704\n","Epoch 707: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0894 - accuracy: 0.9704 - val_loss: 2.5097 - val_accuracy: 0.6939 - lr: 0.0040\n","Epoch 708/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9619\n","Epoch 708: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.1142 - accuracy: 0.9619 - val_loss: 98.0969 - val_accuracy: 0.5074 - lr: 0.0040\n","Epoch 709/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9664\n","Epoch 709: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0973 - accuracy: 0.9664 - val_loss: 3.9615 - val_accuracy: 0.6270 - lr: 0.0034\n","Epoch 710/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9739\n","Epoch 710: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0796 - accuracy: 0.9739 - val_loss: 70.3746 - val_accuracy: 0.6558 - lr: 0.0029\n","Epoch 711/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9780\n","Epoch 711: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0711 - accuracy: 0.9780 - val_loss: 0.9156 - val_accuracy: 0.8274 - lr: 0.0025\n","Epoch 712/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9765\n","Epoch 712: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0689 - accuracy: 0.9765 - val_loss: 0.5710 - val_accuracy: 0.8790 - lr: 0.0021\n","Epoch 713/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9787\n","Epoch 713: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0624 - accuracy: 0.9787 - val_loss: 1.4118 - val_accuracy: 0.7316 - lr: 0.0018\n","Epoch 714/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9830\n","Epoch 714: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0516 - accuracy: 0.9830 - val_loss: 0.3488 - val_accuracy: 0.9097 - lr: 0.0015\n","Epoch 715/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9837\n","Epoch 715: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0493 - accuracy: 0.9837 - val_loss: 2.3779 - val_accuracy: 0.7832 - lr: 0.0013\n","Epoch 716/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9895\n","Epoch 716: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0371 - accuracy: 0.9895 - val_loss: 1.5590 - val_accuracy: 0.8090 - lr: 0.0011\n","Epoch 717/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9810\n","Epoch 717: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 0.6127 - val_accuracy: 0.8472 - lr: 9.2647e-04\n","Epoch 718/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9805\n","Epoch 718: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 438ms/step - loss: 0.0502 - accuracy: 0.9805 - val_loss: 0.0945 - val_accuracy: 0.9712 - lr: 7.8750e-04\n","Epoch 719/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9907\n","Epoch 719: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0329 - accuracy: 0.9907 - val_loss: 0.1232 - val_accuracy: 0.9633 - lr: 6.6937e-04\n","Epoch 720/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9857\n","Epoch 720: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0403 - accuracy: 0.9857 - val_loss: 0.1901 - val_accuracy: 0.9439 - lr: 5.6897e-04\n","Epoch 721/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9882\n","Epoch 721: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.3206 - val_accuracy: 0.9196 - lr: 4.8362e-04\n","Epoch 722/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9877\n","Epoch 722: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 432ms/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.1107 - val_accuracy: 0.9732 - lr: 4.1108e-04\n","Epoch 723/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9895\n","Epoch 723: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 429ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.2177 - val_accuracy: 0.9325 - lr: 3.4942e-04\n","Epoch 724/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9867\n","Epoch 724: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 445ms/step - loss: 0.0350 - accuracy: 0.9867 - val_loss: 0.0959 - val_accuracy: 0.9727 - lr: 2.9700e-04\n","Epoch 725/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9877\n","Epoch 725: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0327 - accuracy: 0.9877 - val_loss: 0.1614 - val_accuracy: 0.9489 - lr: 2.5245e-04\n","Epoch 726/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9857\n","Epoch 726: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0414 - accuracy: 0.9857 - val_loss: 0.5773 - val_accuracy: 0.8507 - lr: 0.0010\n","Epoch 727/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9800\n","Epoch 727: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 33.6750 - val_accuracy: 0.7138 - lr: 0.0015\n","Epoch 728/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9830\n","Epoch 728: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0468 - accuracy: 0.9830 - val_loss: 23.4940 - val_accuracy: 0.6726 - lr: 0.0020\n","Epoch 729/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9732\n","Epoch 729: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0717 - accuracy: 0.9732 - val_loss: 69.7205 - val_accuracy: 0.6860 - lr: 0.0025\n","Epoch 730/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9775\n","Epoch 730: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0603 - accuracy: 0.9775 - val_loss: 1.0063 - val_accuracy: 0.8105 - lr: 0.0030\n","Epoch 731/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9742\n","Epoch 731: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0787 - accuracy: 0.9742 - val_loss: 1.7934 - val_accuracy: 0.7381 - lr: 0.0035\n","Epoch 732/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9709\n","Epoch 732: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 429ms/step - loss: 0.0892 - accuracy: 0.9709 - val_loss: 2.4596 - val_accuracy: 0.6577 - lr: 0.0040\n","Epoch 733/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9709\n","Epoch 733: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 427ms/step - loss: 0.0898 - accuracy: 0.9709 - val_loss: 1.1004 - val_accuracy: 0.8358 - lr: 0.0040\n","Epoch 734/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9692\n","Epoch 734: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0853 - accuracy: 0.9692 - val_loss: 35.0785 - val_accuracy: 0.6781 - lr: 0.0034\n","Epoch 735/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9752\n","Epoch 735: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 429ms/step - loss: 0.0723 - accuracy: 0.9752 - val_loss: 2.3247 - val_accuracy: 0.7108 - lr: 0.0029\n","Epoch 736/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9780\n","Epoch 736: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0751 - accuracy: 0.9780 - val_loss: 1.5063 - val_accuracy: 0.7664 - lr: 0.0025\n","Epoch 737/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9797\n","Epoch 737: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0628 - accuracy: 0.9797 - val_loss: 5.1221 - val_accuracy: 0.7302 - lr: 0.0021\n","Epoch 738/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9835\n","Epoch 738: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0611 - accuracy: 0.9835 - val_loss: 0.5284 - val_accuracy: 0.8428 - lr: 0.0018\n","Epoch 739/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9805\n","Epoch 739: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0530 - accuracy: 0.9805 - val_loss: 0.1605 - val_accuracy: 0.9514 - lr: 0.0015\n","Epoch 740/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9827\n","Epoch 740: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0537 - accuracy: 0.9827 - val_loss: 0.7405 - val_accuracy: 0.8125 - lr: 0.0013\n","Epoch 741/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9860\n","Epoch 741: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 0.7435 - val_accuracy: 0.8854 - lr: 0.0011\n","Epoch 742/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9882\n","Epoch 742: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.6956 - val_accuracy: 0.8348 - lr: 9.2647e-04\n","Epoch 743/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9867\n","Epoch 743: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 429ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.2075 - val_accuracy: 0.9464 - lr: 7.8750e-04\n","Epoch 744/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9867\n","Epoch 744: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 0.7112 - val_accuracy: 0.8581 - lr: 6.6937e-04\n","Epoch 745/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9910\n","Epoch 745: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.2035 - val_accuracy: 0.9648 - lr: 5.6897e-04\n","Epoch 746/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9877\n","Epoch 746: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 428ms/step - loss: 0.0401 - accuracy: 0.9877 - val_loss: 0.1378 - val_accuracy: 0.9653 - lr: 4.8362e-04\n","Epoch 747/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9877\n","Epoch 747: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 429ms/step - loss: 0.0357 - accuracy: 0.9877 - val_loss: 0.1454 - val_accuracy: 0.9598 - lr: 4.1108e-04\n","Epoch 748/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9902\n","Epoch 748: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 428ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.1167 - val_accuracy: 0.9683 - lr: 3.4942e-04\n","Epoch 749/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9887\n","Epoch 749: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 0.3538 - val_accuracy: 0.8993 - lr: 2.9700e-04\n","Epoch 750/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9885\n","Epoch 750: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 428ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.3300 - val_accuracy: 0.8998 - lr: 2.5245e-04\n","Epoch 751/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9875\n","Epoch 751: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0380 - accuracy: 0.9875 - val_loss: 2.2954 - val_accuracy: 0.8834 - lr: 0.0010\n","Epoch 752/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9820\n","Epoch 752: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0613 - accuracy: 0.9820 - val_loss: 11.9549 - val_accuracy: 0.7966 - lr: 0.0015\n","Epoch 753/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9822\n","Epoch 753: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0530 - accuracy: 0.9822 - val_loss: 0.6100 - val_accuracy: 0.8666 - lr: 0.0020\n","Epoch 754/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9820\n","Epoch 754: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0567 - accuracy: 0.9820 - val_loss: 1.5214 - val_accuracy: 0.7728 - lr: 0.0025\n","Epoch 755/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9777\n","Epoch 755: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 427ms/step - loss: 0.0720 - accuracy: 0.9777 - val_loss: 2.2170 - val_accuracy: 0.6751 - lr: 0.0030\n","Epoch 756/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9765\n","Epoch 756: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0760 - accuracy: 0.9765 - val_loss: 1.1207 - val_accuracy: 0.7951 - lr: 0.0035\n","Epoch 757/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9707\n","Epoch 757: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 428ms/step - loss: 0.0919 - accuracy: 0.9707 - val_loss: 1.2025 - val_accuracy: 0.6880 - lr: 0.0040\n","Epoch 758/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9652\n","Epoch 758: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 429ms/step - loss: 0.1059 - accuracy: 0.9652 - val_loss: 209.5039 - val_accuracy: 0.4608 - lr: 0.0040\n","Epoch 759/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9729\n","Epoch 759: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0852 - accuracy: 0.9729 - val_loss: 27.1098 - val_accuracy: 0.6483 - lr: 0.0034\n","Epoch 760/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9752\n","Epoch 760: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0712 - accuracy: 0.9752 - val_loss: 34.3684 - val_accuracy: 0.6230 - lr: 0.0029\n","Epoch 761/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9782\n","Epoch 761: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0652 - accuracy: 0.9782 - val_loss: 0.4329 - val_accuracy: 0.8810 - lr: 0.0025\n","Epoch 762/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9835\n","Epoch 762: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0495 - accuracy: 0.9835 - val_loss: 2.6729 - val_accuracy: 0.6969 - lr: 0.0021\n","Epoch 763/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9815\n","Epoch 763: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0561 - accuracy: 0.9815 - val_loss: 0.5717 - val_accuracy: 0.8690 - lr: 0.0018\n","Epoch 764/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9805\n","Epoch 764: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0529 - accuracy: 0.9805 - val_loss: 0.2923 - val_accuracy: 0.9345 - lr: 0.0015\n","Epoch 765/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9852\n","Epoch 765: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 428ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.5834 - val_accuracy: 0.8725 - lr: 0.0013\n","Epoch 766/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9847\n","Epoch 766: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.2687 - val_accuracy: 0.9311 - lr: 0.0011\n","Epoch 767/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9860\n","Epoch 767: val_loss did not improve from 0.08016\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0437 - accuracy: 0.9860 - val_loss: 0.3836 - val_accuracy: 0.9430 - lr: 9.2647e-04\n","Epoch 768/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9857\n","Epoch 768: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 429ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 2.1928 - val_accuracy: 0.8289 - lr: 7.8750e-04\n","Epoch 769/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9875\n","Epoch 769: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.8842 - val_accuracy: 0.9390 - lr: 6.6937e-04\n","Epoch 770/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9882\n","Epoch 770: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.8176 - val_accuracy: 0.8735 - lr: 5.6897e-04\n","Epoch 771/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9910\n","Epoch 771: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.3374 - val_accuracy: 0.9211 - lr: 4.8362e-04\n","Epoch 772/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9890\n","Epoch 772: val_loss did not improve from 0.08016\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0397 - accuracy: 0.9890 - val_loss: 0.1279 - val_accuracy: 0.9588 - lr: 4.1108e-04\n","Epoch 773/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9900\n","Epoch 773: val_loss improved from 0.08016 to 0.07864, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 32s 480ms/step - loss: 0.0263 - accuracy: 0.9900 - val_loss: 0.0786 - val_accuracy: 0.9742 - lr: 3.4942e-04\n","Epoch 774/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9900\n","Epoch 774: val_loss improved from 0.07864 to 0.07824, saving model to /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","63/63 [==============================] - 33s 482ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.0782 - val_accuracy: 0.9782 - lr: 2.9700e-04\n","Epoch 775/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9890\n","Epoch 775: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.1785 - val_accuracy: 0.9315 - lr: 2.5245e-04\n","Epoch 776/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9875\n","Epoch 776: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 438ms/step - loss: 0.0386 - accuracy: 0.9875 - val_loss: 0.4905 - val_accuracy: 0.8552 - lr: 0.0010\n","Epoch 777/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9835\n","Epoch 777: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 0.4066 - val_accuracy: 0.9301 - lr: 0.0015\n","Epoch 778/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9822\n","Epoch 778: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.5618 - val_accuracy: 0.9127 - lr: 0.0020\n","Epoch 779/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9760\n","Epoch 779: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0731 - accuracy: 0.9760 - val_loss: 0.4302 - val_accuracy: 0.9241 - lr: 0.0025\n","Epoch 780/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9787\n","Epoch 780: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0700 - accuracy: 0.9787 - val_loss: 1.1985 - val_accuracy: 0.8170 - lr: 0.0030\n","Epoch 781/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9752\n","Epoch 781: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0810 - accuracy: 0.9752 - val_loss: 1.7115 - val_accuracy: 0.7088 - lr: 0.0035\n","Epoch 782/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9702\n","Epoch 782: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0872 - accuracy: 0.9702 - val_loss: 1.3405 - val_accuracy: 0.8725 - lr: 0.0040\n","Epoch 783/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9692\n","Epoch 783: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0949 - accuracy: 0.9692 - val_loss: 4.2730 - val_accuracy: 0.6885 - lr: 0.0040\n","Epoch 784/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9765\n","Epoch 784: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 427ms/step - loss: 0.0821 - accuracy: 0.9765 - val_loss: 1.1407 - val_accuracy: 0.7748 - lr: 0.0034\n","Epoch 785/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9762\n","Epoch 785: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0795 - accuracy: 0.9762 - val_loss: 0.5865 - val_accuracy: 0.8408 - lr: 0.0029\n","Epoch 786/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9775\n","Epoch 786: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0670 - accuracy: 0.9775 - val_loss: 6.2308 - val_accuracy: 0.7793 - lr: 0.0025\n","Epoch 787/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9822\n","Epoch 787: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 427ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 3.0368 - val_accuracy: 0.7183 - lr: 0.0021\n","Epoch 788/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9830\n","Epoch 788: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0489 - accuracy: 0.9830 - val_loss: 1.1032 - val_accuracy: 0.9048 - lr: 0.0018\n","Epoch 789/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9822\n","Epoch 789: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0556 - accuracy: 0.9822 - val_loss: 0.5382 - val_accuracy: 0.8750 - lr: 0.0015\n","Epoch 790/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9842\n","Epoch 790: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 0.3015 - val_accuracy: 0.9583 - lr: 0.0013\n","Epoch 791/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9877\n","Epoch 791: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0415 - accuracy: 0.9877 - val_loss: 0.3358 - val_accuracy: 0.8993 - lr: 0.0011\n","Epoch 792/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9840\n","Epoch 792: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0472 - accuracy: 0.9840 - val_loss: 1.4071 - val_accuracy: 0.8140 - lr: 9.2647e-04\n","Epoch 793/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9880\n","Epoch 793: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0410 - accuracy: 0.9880 - val_loss: 13.5549 - val_accuracy: 0.8001 - lr: 7.8750e-04\n","Epoch 794/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9835\n","Epoch 794: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0427 - accuracy: 0.9835 - val_loss: 0.9714 - val_accuracy: 0.8452 - lr: 6.6937e-04\n","Epoch 795/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9877\n","Epoch 795: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0335 - accuracy: 0.9877 - val_loss: 0.5241 - val_accuracy: 0.8934 - lr: 5.6897e-04\n","Epoch 796/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9895\n","Epoch 796: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0373 - accuracy: 0.9895 - val_loss: 0.1512 - val_accuracy: 0.9653 - lr: 4.8362e-04\n","Epoch 797/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9890\n","Epoch 797: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.1087 - val_accuracy: 0.9712 - lr: 4.1108e-04\n","Epoch 798/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9922\n","Epoch 798: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 0.2175 - val_accuracy: 0.9325 - lr: 3.4942e-04\n","Epoch 799/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9905\n","Epoch 799: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.1161 - val_accuracy: 0.9658 - lr: 2.9700e-04\n","Epoch 800/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9860\n","Epoch 800: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0369 - accuracy: 0.9860 - val_loss: 0.1134 - val_accuracy: 0.9678 - lr: 2.5245e-04\n","Epoch 801/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9870\n","Epoch 801: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0451 - accuracy: 0.9870 - val_loss: 0.2939 - val_accuracy: 0.9301 - lr: 0.0010\n","Epoch 802/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9860\n","Epoch 802: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0412 - accuracy: 0.9860 - val_loss: 0.7757 - val_accuracy: 0.8671 - lr: 0.0015\n","Epoch 803/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9815\n","Epoch 803: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 439ms/step - loss: 0.0583 - accuracy: 0.9815 - val_loss: 2.6345 - val_accuracy: 0.7535 - lr: 0.0020\n","Epoch 804/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9837\n","Epoch 804: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0520 - accuracy: 0.9837 - val_loss: 2.7553 - val_accuracy: 0.7574 - lr: 0.0025\n","Epoch 805/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9782\n","Epoch 805: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0712 - accuracy: 0.9782 - val_loss: 1.3365 - val_accuracy: 0.7684 - lr: 0.0030\n","Epoch 806/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9765\n","Epoch 806: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 427ms/step - loss: 0.0782 - accuracy: 0.9765 - val_loss: 1.5491 - val_accuracy: 0.6141 - lr: 0.0035\n","Epoch 807/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9697\n","Epoch 807: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1031 - accuracy: 0.9697 - val_loss: 2502.2981 - val_accuracy: 0.5456 - lr: 0.0040\n","Epoch 808/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9699\n","Epoch 808: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0975 - accuracy: 0.9699 - val_loss: 2.4908 - val_accuracy: 0.6513 - lr: 0.0040\n","Epoch 809/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.9739\n","Epoch 809: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 427ms/step - loss: 0.0809 - accuracy: 0.9739 - val_loss: 14.5810 - val_accuracy: 0.7956 - lr: 0.0034\n","Epoch 810/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9724\n","Epoch 810: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 429ms/step - loss: 0.0747 - accuracy: 0.9724 - val_loss: 3.3344 - val_accuracy: 0.6741 - lr: 0.0029\n","Epoch 811/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9782\n","Epoch 811: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0648 - accuracy: 0.9782 - val_loss: 0.8388 - val_accuracy: 0.7847 - lr: 0.0025\n","Epoch 812/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9800\n","Epoch 812: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0563 - accuracy: 0.9800 - val_loss: 0.3074 - val_accuracy: 0.9286 - lr: 0.0021\n","Epoch 813/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9807\n","Epoch 813: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0590 - accuracy: 0.9807 - val_loss: 0.8071 - val_accuracy: 0.8646 - lr: 0.0018\n","Epoch 814/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9845\n","Epoch 814: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0464 - accuracy: 0.9845 - val_loss: 0.3521 - val_accuracy: 0.9043 - lr: 0.0015\n","Epoch 815/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9840\n","Epoch 815: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 1.4437 - val_accuracy: 0.7803 - lr: 0.0013\n","Epoch 816/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9872\n","Epoch 816: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0352 - accuracy: 0.9872 - val_loss: 0.3349 - val_accuracy: 0.9350 - lr: 0.0011\n","Epoch 817/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9860\n","Epoch 817: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0496 - accuracy: 0.9860 - val_loss: 0.1127 - val_accuracy: 0.9712 - lr: 9.2647e-04\n","Epoch 818/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9862\n","Epoch 818: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0424 - accuracy: 0.9862 - val_loss: 0.1255 - val_accuracy: 0.9692 - lr: 7.8750e-04\n","Epoch 819/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9905\n","Epoch 819: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0337 - accuracy: 0.9905 - val_loss: 0.2030 - val_accuracy: 0.9504 - lr: 6.6937e-04\n","Epoch 820/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9897\n","Epoch 820: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0338 - accuracy: 0.9897 - val_loss: 0.1867 - val_accuracy: 0.9563 - lr: 5.6897e-04\n","Epoch 821/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9902\n","Epoch 821: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.5951 - val_accuracy: 0.9251 - lr: 4.8362e-04\n","Epoch 822/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9907\n","Epoch 822: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0326 - accuracy: 0.9907 - val_loss: 0.4453 - val_accuracy: 0.9439 - lr: 4.1108e-04\n","Epoch 823/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9920\n","Epoch 823: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 427ms/step - loss: 0.0314 - accuracy: 0.9920 - val_loss: 0.1363 - val_accuracy: 0.9524 - lr: 3.4942e-04\n","Epoch 824/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9902\n","Epoch 824: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.1293 - val_accuracy: 0.9712 - lr: 2.9700e-04\n","Epoch 825/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9897\n","Epoch 825: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 0.0838 - val_accuracy: 0.9752 - lr: 2.5245e-04\n","Epoch 826/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9870\n","Epoch 826: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0344 - accuracy: 0.9870 - val_loss: 1.0033 - val_accuracy: 0.8309 - lr: 0.0010\n","Epoch 827/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9872\n","Epoch 827: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.2274 - val_accuracy: 0.9315 - lr: 0.0015\n","Epoch 828/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9852\n","Epoch 828: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0517 - accuracy: 0.9852 - val_loss: 8.3294 - val_accuracy: 0.7574 - lr: 0.0020\n","Epoch 829/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9785\n","Epoch 829: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0577 - accuracy: 0.9785 - val_loss: 0.4382 - val_accuracy: 0.8795 - lr: 0.0025\n","Epoch 830/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9815\n","Epoch 830: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 37.7420 - val_accuracy: 0.6979 - lr: 0.0030\n","Epoch 831/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9752\n","Epoch 831: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0645 - accuracy: 0.9752 - val_loss: 3.4687 - val_accuracy: 0.7639 - lr: 0.0035\n","Epoch 832/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9692\n","Epoch 832: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0924 - accuracy: 0.9692 - val_loss: 1.1361 - val_accuracy: 0.8150 - lr: 0.0040\n","Epoch 833/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9732\n","Epoch 833: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0890 - accuracy: 0.9732 - val_loss: 47.5345 - val_accuracy: 0.6756 - lr: 0.0040\n","Epoch 834/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9732\n","Epoch 834: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0844 - accuracy: 0.9732 - val_loss: 1.1626 - val_accuracy: 0.8021 - lr: 0.0034\n","Epoch 835/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9739\n","Epoch 835: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0825 - accuracy: 0.9739 - val_loss: 0.4085 - val_accuracy: 0.8993 - lr: 0.0029\n","Epoch 836/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9817\n","Epoch 836: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0555 - accuracy: 0.9817 - val_loss: 85.1019 - val_accuracy: 0.6389 - lr: 0.0025\n","Epoch 837/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9760\n","Epoch 837: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0742 - accuracy: 0.9760 - val_loss: 1.0615 - val_accuracy: 0.8313 - lr: 0.0021\n","Epoch 838/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9805\n","Epoch 838: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0586 - accuracy: 0.9805 - val_loss: 0.2292 - val_accuracy: 0.9340 - lr: 0.0018\n","Epoch 839/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9820\n","Epoch 839: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0550 - accuracy: 0.9820 - val_loss: 0.7897 - val_accuracy: 0.8110 - lr: 0.0015\n","Epoch 840/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9840\n","Epoch 840: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0465 - accuracy: 0.9840 - val_loss: 1.9209 - val_accuracy: 0.7708 - lr: 0.0013\n","Epoch 841/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9862\n","Epoch 841: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0355 - accuracy: 0.9862 - val_loss: 0.5891 - val_accuracy: 0.8522 - lr: 0.0011\n","Epoch 842/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9872\n","Epoch 842: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.5502 - val_accuracy: 0.8973 - lr: 9.2647e-04\n","Epoch 843/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9857\n","Epoch 843: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0328 - accuracy: 0.9857 - val_loss: 1.9007 - val_accuracy: 0.8165 - lr: 7.8750e-04\n","Epoch 844/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9860\n","Epoch 844: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.5544 - val_accuracy: 0.8720 - lr: 6.6937e-04\n","Epoch 845/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9892\n","Epoch 845: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0324 - accuracy: 0.9892 - val_loss: 0.2985 - val_accuracy: 0.9415 - lr: 5.6897e-04\n","Epoch 846/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9892\n","Epoch 846: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.1032 - val_accuracy: 0.9767 - lr: 4.8362e-04\n","Epoch 847/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9897\n","Epoch 847: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 0.1909 - val_accuracy: 0.9479 - lr: 4.1108e-04\n","Epoch 848/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9907\n","Epoch 848: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 0.1424 - val_accuracy: 0.9608 - lr: 3.4942e-04\n","Epoch 849/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9892\n","Epoch 849: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0307 - accuracy: 0.9892 - val_loss: 0.1063 - val_accuracy: 0.9762 - lr: 2.9700e-04\n","Epoch 850/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9902\n","Epoch 850: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 0.1415 - val_accuracy: 0.9549 - lr: 2.5245e-04\n","Epoch 851/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9862\n","Epoch 851: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0360 - accuracy: 0.9862 - val_loss: 4.7343 - val_accuracy: 0.8423 - lr: 0.0010\n","Epoch 852/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9847\n","Epoch 852: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 0.1306 - val_accuracy: 0.9618 - lr: 0.0015\n","Epoch 853/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9830\n","Epoch 853: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0477 - accuracy: 0.9830 - val_loss: 1.9242 - val_accuracy: 0.8929 - lr: 0.0020\n","Epoch 854/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9835\n","Epoch 854: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0462 - accuracy: 0.9835 - val_loss: 0.5201 - val_accuracy: 0.8934 - lr: 0.0025\n","Epoch 855/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9775\n","Epoch 855: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0723 - accuracy: 0.9775 - val_loss: 2.3641 - val_accuracy: 0.6657 - lr: 0.0030\n","Epoch 856/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9742\n","Epoch 856: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0863 - accuracy: 0.9742 - val_loss: 3.7735 - val_accuracy: 0.6806 - lr: 0.0035\n","Epoch 857/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9719\n","Epoch 857: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0903 - accuracy: 0.9719 - val_loss: 4.4288 - val_accuracy: 0.7222 - lr: 0.0040\n","Epoch 858/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9712\n","Epoch 858: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.1036 - accuracy: 0.9712 - val_loss: 0.7481 - val_accuracy: 0.7609 - lr: 0.0040\n","Epoch 859/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9749\n","Epoch 859: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0818 - accuracy: 0.9749 - val_loss: 7.2431 - val_accuracy: 0.5938 - lr: 0.0034\n","Epoch 860/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9780\n","Epoch 860: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0676 - accuracy: 0.9780 - val_loss: 0.7035 - val_accuracy: 0.7852 - lr: 0.0029\n","Epoch 861/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9797\n","Epoch 861: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0614 - accuracy: 0.9797 - val_loss: 5.2983 - val_accuracy: 0.5868 - lr: 0.0025\n","Epoch 862/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9822\n","Epoch 862: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0596 - accuracy: 0.9822 - val_loss: 30.2273 - val_accuracy: 0.7138 - lr: 0.0021\n","Epoch 863/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9807\n","Epoch 863: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0574 - accuracy: 0.9807 - val_loss: 79.6293 - val_accuracy: 0.6528 - lr: 0.0018\n","Epoch 864/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9822\n","Epoch 864: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0508 - accuracy: 0.9822 - val_loss: 1.2741 - val_accuracy: 0.8378 - lr: 0.0015\n","Epoch 865/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9865\n","Epoch 865: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 428ms/step - loss: 0.0361 - accuracy: 0.9865 - val_loss: 0.2155 - val_accuracy: 0.9281 - lr: 0.0013\n","Epoch 866/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9855\n","Epoch 866: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0404 - accuracy: 0.9855 - val_loss: 1.2658 - val_accuracy: 0.8368 - lr: 0.0011\n","Epoch 867/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9877\n","Epoch 867: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0424 - accuracy: 0.9877 - val_loss: 0.1936 - val_accuracy: 0.9648 - lr: 9.2647e-04\n","Epoch 868/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9855\n","Epoch 868: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0403 - accuracy: 0.9855 - val_loss: 0.1469 - val_accuracy: 0.9702 - lr: 7.8750e-04\n","Epoch 869/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9905\n","Epoch 869: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 428ms/step - loss: 0.0309 - accuracy: 0.9905 - val_loss: 0.2954 - val_accuracy: 0.9499 - lr: 6.6937e-04\n","Epoch 870/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9912\n","Epoch 870: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.1526 - val_accuracy: 0.9554 - lr: 5.6897e-04\n","Epoch 871/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9902\n","Epoch 871: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 428ms/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 0.1446 - val_accuracy: 0.9707 - lr: 4.8362e-04\n","Epoch 872/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9885\n","Epoch 872: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 427ms/step - loss: 0.0368 - accuracy: 0.9885 - val_loss: 0.1963 - val_accuracy: 0.9454 - lr: 4.1108e-04\n","Epoch 873/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9895\n","Epoch 873: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0371 - accuracy: 0.9895 - val_loss: 0.1234 - val_accuracy: 0.9643 - lr: 3.4942e-04\n","Epoch 874/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9902\n","Epoch 874: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 428ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.1471 - val_accuracy: 0.9697 - lr: 2.9700e-04\n","Epoch 875/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9910\n","Epoch 875: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0266 - accuracy: 0.9910 - val_loss: 0.1702 - val_accuracy: 0.9668 - lr: 2.5245e-04\n","Epoch 876/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9877\n","Epoch 876: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0353 - accuracy: 0.9877 - val_loss: 0.4900 - val_accuracy: 0.8705 - lr: 0.0010\n","Epoch 877/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9830\n","Epoch 877: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0491 - accuracy: 0.9830 - val_loss: 31.3834 - val_accuracy: 0.7376 - lr: 0.0015\n","Epoch 878/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9857\n","Epoch 878: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 427ms/step - loss: 0.0389 - accuracy: 0.9857 - val_loss: 51.5756 - val_accuracy: 0.6860 - lr: 0.0020\n","Epoch 879/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9795\n","Epoch 879: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0571 - accuracy: 0.9795 - val_loss: 1.7357 - val_accuracy: 0.7857 - lr: 0.0025\n","Epoch 880/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9817\n","Epoch 880: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0613 - accuracy: 0.9817 - val_loss: 354.2378 - val_accuracy: 0.6230 - lr: 0.0030\n","Epoch 881/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9732\n","Epoch 881: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0825 - accuracy: 0.9732 - val_loss: 27.1764 - val_accuracy: 0.7550 - lr: 0.0035\n","Epoch 882/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9714\n","Epoch 882: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0864 - accuracy: 0.9714 - val_loss: 138.0804 - val_accuracy: 0.6652 - lr: 0.0040\n","Epoch 883/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9694\n","Epoch 883: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 428ms/step - loss: 0.0846 - accuracy: 0.9694 - val_loss: 75.3477 - val_accuracy: 0.6558 - lr: 0.0040\n","Epoch 884/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9742\n","Epoch 884: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0776 - accuracy: 0.9742 - val_loss: 2.7352 - val_accuracy: 0.6553 - lr: 0.0034\n","Epoch 885/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9757\n","Epoch 885: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0678 - accuracy: 0.9757 - val_loss: 1.6862 - val_accuracy: 0.7535 - lr: 0.0029\n","Epoch 886/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9792\n","Epoch 886: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0584 - accuracy: 0.9792 - val_loss: 1.8053 - val_accuracy: 0.7044 - lr: 0.0025\n","Epoch 887/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9792\n","Epoch 887: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0597 - accuracy: 0.9792 - val_loss: 0.8215 - val_accuracy: 0.8323 - lr: 0.0021\n","Epoch 888/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9832\n","Epoch 888: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0590 - accuracy: 0.9832 - val_loss: 0.4095 - val_accuracy: 0.8755 - lr: 0.0018\n","Epoch 889/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9832\n","Epoch 889: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.2302 - val_accuracy: 0.9504 - lr: 0.0015\n","Epoch 890/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9850\n","Epoch 890: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 428ms/step - loss: 0.0478 - accuracy: 0.9850 - val_loss: 64.9966 - val_accuracy: 0.7589 - lr: 0.0013\n","Epoch 891/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9857\n","Epoch 891: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 36.4607 - val_accuracy: 0.7644 - lr: 0.0011\n","Epoch 892/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9877\n","Epoch 892: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0344 - accuracy: 0.9877 - val_loss: 0.2663 - val_accuracy: 0.9425 - lr: 9.2647e-04\n","Epoch 893/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9905\n","Epoch 893: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 0.2612 - val_accuracy: 0.9390 - lr: 7.8750e-04\n","Epoch 894/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9875\n","Epoch 894: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 427ms/step - loss: 0.0309 - accuracy: 0.9875 - val_loss: 0.2464 - val_accuracy: 0.9479 - lr: 6.6937e-04\n","Epoch 895/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9867\n","Epoch 895: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.5065 - val_accuracy: 0.8963 - lr: 5.6897e-04\n","Epoch 896/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9885\n","Epoch 896: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 427ms/step - loss: 0.0404 - accuracy: 0.9885 - val_loss: 0.6798 - val_accuracy: 0.8800 - lr: 4.8362e-04\n","Epoch 897/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9892\n","Epoch 897: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.4565 - val_accuracy: 0.9187 - lr: 4.1108e-04\n","Epoch 898/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9892\n","Epoch 898: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0331 - accuracy: 0.9892 - val_loss: 0.5165 - val_accuracy: 0.9454 - lr: 3.4942e-04\n","Epoch 899/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9912\n","Epoch 899: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.5780 - val_accuracy: 0.9182 - lr: 2.9700e-04\n","Epoch 900/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9917\n","Epoch 900: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0307 - accuracy: 0.9917 - val_loss: 0.1527 - val_accuracy: 0.9568 - lr: 2.5245e-04\n","Epoch 901/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9890\n","Epoch 901: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.6069 - val_accuracy: 0.8502 - lr: 0.0010\n","Epoch 902/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9857\n","Epoch 902: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0448 - accuracy: 0.9857 - val_loss: 0.4163 - val_accuracy: 0.9221 - lr: 0.0015\n","Epoch 903/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9842\n","Epoch 903: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0489 - accuracy: 0.9842 - val_loss: 0.7498 - val_accuracy: 0.9420 - lr: 0.0020\n","Epoch 904/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9817\n","Epoch 904: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0535 - accuracy: 0.9817 - val_loss: 88.4365 - val_accuracy: 0.6915 - lr: 0.0025\n","Epoch 905/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9805\n","Epoch 905: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0648 - accuracy: 0.9805 - val_loss: 45.6469 - val_accuracy: 0.6984 - lr: 0.0030\n","Epoch 906/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9749\n","Epoch 906: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0776 - accuracy: 0.9749 - val_loss: 3.6962 - val_accuracy: 0.6930 - lr: 0.0035\n","Epoch 907/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9702\n","Epoch 907: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0817 - accuracy: 0.9702 - val_loss: 0.4648 - val_accuracy: 0.8963 - lr: 0.0040\n","Epoch 908/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9719\n","Epoch 908: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0908 - accuracy: 0.9719 - val_loss: 0.9142 - val_accuracy: 0.8065 - lr: 0.0040\n","Epoch 909/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9749\n","Epoch 909: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 424ms/step - loss: 0.0772 - accuracy: 0.9749 - val_loss: 4.2149 - val_accuracy: 0.5878 - lr: 0.0034\n","Epoch 910/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9747\n","Epoch 910: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0772 - accuracy: 0.9747 - val_loss: 1.0833 - val_accuracy: 0.8874 - lr: 0.0029\n","Epoch 911/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9815\n","Epoch 911: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0554 - accuracy: 0.9815 - val_loss: 4.3803 - val_accuracy: 0.7867 - lr: 0.0025\n","Epoch 912/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9822\n","Epoch 912: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0585 - accuracy: 0.9822 - val_loss: 0.5139 - val_accuracy: 0.8760 - lr: 0.0021\n","Epoch 913/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9832\n","Epoch 913: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0535 - accuracy: 0.9832 - val_loss: 0.2338 - val_accuracy: 0.9395 - lr: 0.0018\n","Epoch 914/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9830\n","Epoch 914: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0406 - accuracy: 0.9830 - val_loss: 0.1983 - val_accuracy: 0.9430 - lr: 0.0015\n","Epoch 915/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9840\n","Epoch 915: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0525 - accuracy: 0.9840 - val_loss: 0.5093 - val_accuracy: 0.9385 - lr: 0.0013\n","Epoch 916/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9847\n","Epoch 916: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0437 - accuracy: 0.9847 - val_loss: 0.5526 - val_accuracy: 0.9375 - lr: 0.0011\n","Epoch 917/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9865\n","Epoch 917: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0381 - accuracy: 0.9865 - val_loss: 1.7315 - val_accuracy: 0.8938 - lr: 9.2647e-04\n","Epoch 918/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9895\n","Epoch 918: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.1043 - val_accuracy: 0.9792 - lr: 7.8750e-04\n","Epoch 919/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9890\n","Epoch 919: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0298 - accuracy: 0.9890 - val_loss: 0.1516 - val_accuracy: 0.9578 - lr: 6.6937e-04\n","Epoch 920/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9902\n","Epoch 920: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 0.1676 - val_accuracy: 0.9509 - lr: 5.6897e-04\n","Epoch 921/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9880\n","Epoch 921: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 427ms/step - loss: 0.0296 - accuracy: 0.9880 - val_loss: 0.3241 - val_accuracy: 0.9727 - lr: 4.8362e-04\n","Epoch 922/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9902\n","Epoch 922: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0269 - accuracy: 0.9902 - val_loss: 0.3159 - val_accuracy: 0.9469 - lr: 4.1108e-04\n","Epoch 923/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9922\n","Epoch 923: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 426ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0868 - val_accuracy: 0.9722 - lr: 3.4942e-04\n","Epoch 924/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9897\n","Epoch 924: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 426ms/step - loss: 0.0273 - accuracy: 0.9897 - val_loss: 0.0876 - val_accuracy: 0.9752 - lr: 2.9700e-04\n","Epoch 925/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9892\n","Epoch 925: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0358 - accuracy: 0.9892 - val_loss: 0.2152 - val_accuracy: 0.9425 - lr: 2.5245e-04\n","Epoch 926/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9905\n","Epoch 926: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 420ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.1457 - val_accuracy: 0.9673 - lr: 0.0010\n","Epoch 927/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9882\n","Epoch 927: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 1.0712 - val_accuracy: 0.9003 - lr: 0.0015\n","Epoch 928/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9850\n","Epoch 928: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0436 - accuracy: 0.9850 - val_loss: 0.4988 - val_accuracy: 0.8805 - lr: 0.0020\n","Epoch 929/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9865\n","Epoch 929: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0444 - accuracy: 0.9865 - val_loss: 1.1095 - val_accuracy: 0.7862 - lr: 0.0025\n","Epoch 930/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9770\n","Epoch 930: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0697 - accuracy: 0.9770 - val_loss: 82.6474 - val_accuracy: 0.7257 - lr: 0.0030\n","Epoch 931/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9772\n","Epoch 931: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 435ms/step - loss: 0.0762 - accuracy: 0.9772 - val_loss: 0.4792 - val_accuracy: 0.9216 - lr: 0.0035\n","Epoch 932/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9777\n","Epoch 932: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0646 - accuracy: 0.9777 - val_loss: 404.1923 - val_accuracy: 0.5451 - lr: 0.0040\n","Epoch 933/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9767\n","Epoch 933: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0754 - accuracy: 0.9767 - val_loss: 17.4250 - val_accuracy: 0.7609 - lr: 0.0040\n","Epoch 934/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9752\n","Epoch 934: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0767 - accuracy: 0.9752 - val_loss: 327.5671 - val_accuracy: 0.5670 - lr: 0.0034\n","Epoch 935/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9810\n","Epoch 935: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0666 - accuracy: 0.9810 - val_loss: 122.9211 - val_accuracy: 0.6399 - lr: 0.0029\n","Epoch 936/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9790\n","Epoch 936: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0585 - accuracy: 0.9790 - val_loss: 31.0851 - val_accuracy: 0.7713 - lr: 0.0025\n","Epoch 937/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9835\n","Epoch 937: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0503 - accuracy: 0.9835 - val_loss: 12.8794 - val_accuracy: 0.7902 - lr: 0.0021\n","Epoch 938/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9877\n","Epoch 938: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0427 - accuracy: 0.9877 - val_loss: 0.2861 - val_accuracy: 0.9276 - lr: 0.0018\n","Epoch 939/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9870\n","Epoch 939: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.2978 - val_accuracy: 0.9608 - lr: 0.0015\n","Epoch 940/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9860\n","Epoch 940: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0398 - accuracy: 0.9860 - val_loss: 0.2083 - val_accuracy: 0.9489 - lr: 0.0013\n","Epoch 941/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9877\n","Epoch 941: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0404 - accuracy: 0.9877 - val_loss: 0.5011 - val_accuracy: 0.8705 - lr: 0.0011\n","Epoch 942/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9852\n","Epoch 942: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0368 - accuracy: 0.9852 - val_loss: 0.2717 - val_accuracy: 0.9182 - lr: 9.2647e-04\n","Epoch 943/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9895\n","Epoch 943: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0422 - accuracy: 0.9895 - val_loss: 0.1710 - val_accuracy: 0.9534 - lr: 7.8750e-04\n","Epoch 944/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9877\n","Epoch 944: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 421ms/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.2873 - val_accuracy: 0.9167 - lr: 6.6937e-04\n","Epoch 945/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9860\n","Epoch 945: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0387 - accuracy: 0.9860 - val_loss: 1.4902 - val_accuracy: 0.8557 - lr: 5.6897e-04\n","Epoch 946/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9905\n","Epoch 946: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.3336 - val_accuracy: 0.9519 - lr: 4.8362e-04\n","Epoch 947/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9910\n","Epoch 947: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 0.3455 - val_accuracy: 0.8760 - lr: 4.1108e-04\n","Epoch 948/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9897\n","Epoch 948: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 0.2438 - val_accuracy: 0.9157 - lr: 3.4942e-04\n","Epoch 949/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9892\n","Epoch 949: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.2335 - val_accuracy: 0.9514 - lr: 2.9700e-04\n","Epoch 950/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9912\n","Epoch 950: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0260 - accuracy: 0.9912 - val_loss: 0.3729 - val_accuracy: 0.9380 - lr: 2.5245e-04\n","Epoch 951/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9935\n","Epoch 951: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.6726 - val_accuracy: 0.9578 - lr: 0.0010\n","Epoch 952/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9885\n","Epoch 952: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 11.5426 - val_accuracy: 0.8254 - lr: 0.0015\n","Epoch 953/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9882\n","Epoch 953: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0422 - accuracy: 0.9882 - val_loss: 377.9453 - val_accuracy: 0.6280 - lr: 0.0020\n","Epoch 954/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9802\n","Epoch 954: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0595 - accuracy: 0.9802 - val_loss: 2.4867 - val_accuracy: 0.8160 - lr: 0.0025\n","Epoch 955/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9805\n","Epoch 955: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0556 - accuracy: 0.9805 - val_loss: 47.5502 - val_accuracy: 0.6781 - lr: 0.0030\n","Epoch 956/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9752\n","Epoch 956: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0805 - accuracy: 0.9752 - val_loss: 0.5787 - val_accuracy: 0.8661 - lr: 0.0035\n","Epoch 957/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9729\n","Epoch 957: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 417ms/step - loss: 0.0817 - accuracy: 0.9729 - val_loss: 1.4233 - val_accuracy: 0.7584 - lr: 0.0040\n","Epoch 958/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9737\n","Epoch 958: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0833 - accuracy: 0.9737 - val_loss: 1.0121 - val_accuracy: 0.8016 - lr: 0.0040\n","Epoch 959/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9767\n","Epoch 959: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0659 - accuracy: 0.9767 - val_loss: 237.8517 - val_accuracy: 0.6845 - lr: 0.0034\n","Epoch 960/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9767\n","Epoch 960: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0668 - accuracy: 0.9767 - val_loss: 4.7719 - val_accuracy: 0.8006 - lr: 0.0029\n","Epoch 961/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9830\n","Epoch 961: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0537 - accuracy: 0.9830 - val_loss: 0.3041 - val_accuracy: 0.9112 - lr: 0.0025\n","Epoch 962/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9820\n","Epoch 962: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0607 - accuracy: 0.9820 - val_loss: 1.3720 - val_accuracy: 0.7922 - lr: 0.0021\n","Epoch 963/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9820\n","Epoch 963: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0542 - accuracy: 0.9820 - val_loss: 0.2925 - val_accuracy: 0.8859 - lr: 0.0018\n","Epoch 964/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9860\n","Epoch 964: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0468 - accuracy: 0.9860 - val_loss: 0.6725 - val_accuracy: 0.9573 - lr: 0.0015\n","Epoch 965/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9865\n","Epoch 965: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.1948 - val_accuracy: 0.9365 - lr: 0.0013\n","Epoch 966/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9905\n","Epoch 966: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.2732 - val_accuracy: 0.9221 - lr: 0.0011\n","Epoch 967/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9895\n","Epoch 967: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0353 - accuracy: 0.9895 - val_loss: 24.3945 - val_accuracy: 0.8279 - lr: 9.2647e-04\n","Epoch 968/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9887\n","Epoch 968: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 425ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 5.9744 - val_accuracy: 0.8512 - lr: 7.8750e-04\n","Epoch 969/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9907\n","Epoch 969: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 434ms/step - loss: 0.0249 - accuracy: 0.9907 - val_loss: 0.5434 - val_accuracy: 0.9583 - lr: 6.6937e-04\n","Epoch 970/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9920\n","Epoch 970: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 2.2174 - val_accuracy: 0.9435 - lr: 5.6897e-04\n","Epoch 971/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9920\n","Epoch 971: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 41.7557 - val_accuracy: 0.7986 - lr: 4.8362e-04\n","Epoch 972/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9890\n","Epoch 972: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.2622 - val_accuracy: 0.9767 - lr: 4.1108e-04\n","Epoch 973/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9922\n","Epoch 973: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0263 - accuracy: 0.9922 - val_loss: 0.2130 - val_accuracy: 0.9752 - lr: 3.4942e-04\n","Epoch 974/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9905\n","Epoch 974: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0294 - accuracy: 0.9905 - val_loss: 0.2204 - val_accuracy: 0.9782 - lr: 2.9700e-04\n","Epoch 975/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9920\n","Epoch 975: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.6046 - val_accuracy: 0.9653 - lr: 2.5245e-04\n","Epoch 976/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9890\n","Epoch 976: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 425ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 1.6075 - val_accuracy: 0.9489 - lr: 0.0010\n","Epoch 977/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9872\n","Epoch 977: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0350 - accuracy: 0.9872 - val_loss: 169.6543 - val_accuracy: 0.7009 - lr: 0.0015\n","Epoch 978/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9867\n","Epoch 978: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0455 - accuracy: 0.9867 - val_loss: 646.1118 - val_accuracy: 0.6215 - lr: 0.0020\n","Epoch 979/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9815\n","Epoch 979: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0619 - accuracy: 0.9815 - val_loss: 2.4915 - val_accuracy: 0.7029 - lr: 0.0025\n","Epoch 980/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9822\n","Epoch 980: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0575 - accuracy: 0.9822 - val_loss: 635.6428 - val_accuracy: 0.6096 - lr: 0.0030\n","Epoch 981/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9762\n","Epoch 981: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0718 - accuracy: 0.9762 - val_loss: 0.6612 - val_accuracy: 0.8621 - lr: 0.0035\n","Epoch 982/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9732\n","Epoch 982: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 420ms/step - loss: 0.0896 - accuracy: 0.9732 - val_loss: 0.2623 - val_accuracy: 0.9261 - lr: 0.0040\n","Epoch 983/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9792\n","Epoch 983: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0686 - accuracy: 0.9792 - val_loss: 130.0660 - val_accuracy: 0.5878 - lr: 0.0040\n","Epoch 984/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9797\n","Epoch 984: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0668 - accuracy: 0.9797 - val_loss: 3.3983 - val_accuracy: 0.8021 - lr: 0.0034\n","Epoch 985/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9767\n","Epoch 985: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0746 - accuracy: 0.9767 - val_loss: 372.9222 - val_accuracy: 0.6329 - lr: 0.0029\n","Epoch 986/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9772\n","Epoch 986: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0625 - accuracy: 0.9772 - val_loss: 160.4082 - val_accuracy: 0.6543 - lr: 0.0025\n","Epoch 987/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9825\n","Epoch 987: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 2.8387 - val_accuracy: 0.8299 - lr: 0.0021\n","Epoch 988/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9850\n","Epoch 988: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 421ms/step - loss: 0.0477 - accuracy: 0.9850 - val_loss: 0.7619 - val_accuracy: 0.8517 - lr: 0.0018\n","Epoch 989/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9835\n","Epoch 989: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 423ms/step - loss: 0.0449 - accuracy: 0.9835 - val_loss: 1.8180 - val_accuracy: 0.7946 - lr: 0.0015\n","Epoch 990/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9847\n","Epoch 990: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.5488 - val_accuracy: 0.8770 - lr: 0.0013\n","Epoch 991/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9855\n","Epoch 991: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 422ms/step - loss: 0.0383 - accuracy: 0.9855 - val_loss: 0.1822 - val_accuracy: 0.9484 - lr: 0.0011\n","Epoch 992/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9907\n","Epoch 992: val_loss did not improve from 0.07824\n","63/63 [==============================] - 29s 419ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.7255 - val_accuracy: 0.9529 - lr: 9.2647e-04\n","Epoch 993/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9872\n","Epoch 993: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.1412 - val_accuracy: 0.9529 - lr: 7.8750e-04\n","Epoch 994/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9907\n","Epoch 994: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 419ms/step - loss: 0.0243 - accuracy: 0.9907 - val_loss: 0.1286 - val_accuracy: 0.9658 - lr: 6.6937e-04\n","Epoch 995/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9915\n","Epoch 995: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.2873 - val_accuracy: 0.9216 - lr: 5.6897e-04\n","Epoch 996/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9905\n","Epoch 996: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 423ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.6318 - val_accuracy: 0.8973 - lr: 4.8362e-04\n","Epoch 997/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9900\n","Epoch 997: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.2375 - val_accuracy: 0.9390 - lr: 4.1108e-04\n","Epoch 998/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9917\n","Epoch 998: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 424ms/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.1696 - val_accuracy: 0.9658 - lr: 3.4942e-04\n","Epoch 999/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9900\n","Epoch 999: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.1099 - val_accuracy: 0.9762 - lr: 2.9700e-04\n","Epoch 1000/1000\n","63/63 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9907\n","Epoch 1000: val_loss did not improve from 0.07824\n","63/63 [==============================] - 28s 422ms/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 0.1381 - val_accuracy: 0.9673 - lr: 2.5245e-04\n","Best Model Results: /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","8/8 [==============================] - 5s 182ms/step - loss: 0.0946 - accuracy: 0.9802\n","loss 0.09462543576955795\n","acc 0.9801587462425232\n","Finished: /content/drive/MyDrive/output/JP30N14-45\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["work_on_keffnet(show_model=False, run_fit=True, test_results=True)"]},{"cell_type":"markdown","metadata":{"id":"qm50d5uZxkvA"},"source":["# Test Results"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"sGjwYVi6TNN_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647403373942,"user_tz":180,"elapsed":11005,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"90292f98-d7d1-4db6-d419-bfda8b657787"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running: /content/drive/MyDrive/output/JP30N14-45\n","Best Model Results: /content/drive/MyDrive/output/JP30N14-45-best_result.hdf5\n","8/8 [==============================] - 4s 67ms/step - loss: 0.0946 - accuracy: 0.9802\n","loss 0.09462543576955795\n","acc 0.9801587462425232\n","Finished: /content/drive/MyDrive/output/JP30N14-45\n"]}],"source":["work_on_keffnet(show_model=False, run_fit=False, test_results=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"qYPjSr31VdXG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647403391897,"user_tz":180,"elapsed":17962,"user":{"displayName":"Joao Schuler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10970916006391371112"}},"outputId":"f18cba81-4c66-47d2-995b-fa746c950eae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running: /content/drive/MyDrive/output/JP30N14-45\n","Test Original\n","              precision    recall  f1-score   support\n","\n","           0     0.9841    0.9841    0.9841        63\n","           1     0.9538    0.9841    0.9688        63\n","           2     0.9508    0.9206    0.9355        63\n","           3     0.9538    0.9841    0.9688        63\n","           4     1.0000    0.9683    0.9839        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.9802       504\n","   macro avg     0.9803    0.9802    0.9801       504\n","weighted avg     0.9803    0.9802    0.9801       504\n","\n","Test Flip X\n","              precision    recall  f1-score   support\n","\n","           0     0.9836    0.9524    0.9677        63\n","           1     0.9538    0.9841    0.9688        63\n","           2     0.9194    0.9048    0.9120        63\n","           3     0.9394    0.9841    0.9612        63\n","           4     1.0000    0.9683    0.9839        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.9742       504\n","   macro avg     0.9745    0.9742    0.9742       504\n","weighted avg     0.9745    0.9742    0.9742       504\n","\n","Test Original + Flip X\n","              precision    recall  f1-score   support\n","\n","           0     0.9836    0.9524    0.9677        63\n","           1     0.9688    0.9841    0.9764        63\n","           2     0.9194    0.9048    0.9120        63\n","           3     0.9394    0.9841    0.9612        63\n","           4     1.0000    0.9841    0.9920        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.9762       504\n","   macro avg     0.9764    0.9762    0.9762       504\n","weighted avg     0.9764    0.9762    0.9762       504\n","\n","Test Flip Y\n","              precision    recall  f1-score   support\n","\n","           0     0.9839    0.9683    0.9760        63\n","           1     1.0000    0.9683    0.9839        63\n","           2     0.9062    0.9206    0.9134        63\n","           3     0.9254    0.9841    0.9538        63\n","           4     1.0000    0.9683    0.9839        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.9762       504\n","   macro avg     0.9769    0.9762    0.9764       504\n","weighted avg     0.9769    0.9762    0.9764       504\n","\n","Test Original + Flip Y\n","              precision    recall  f1-score   support\n","\n","           0     0.9839    0.9683    0.9760        63\n","           1     0.9688    0.9841    0.9764        63\n","           2     0.9344    0.9048    0.9194        63\n","           3     0.9254    0.9841    0.9538        63\n","           4     1.0000    0.9683    0.9839        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.9762       504\n","   macro avg     0.9766    0.9762    0.9762       504\n","weighted avg     0.9766    0.9762    0.9762       504\n","\n","Test Original + Flip X + Flip Y\n","              precision    recall  f1-score   support\n","\n","           0     0.9836    0.9524    0.9677        63\n","           1     0.9841    0.9841    0.9841        63\n","           2     0.9194    0.9048    0.9120        63\n","           3     0.9254    0.9841    0.9538        63\n","           4     1.0000    0.9841    0.9920        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.9762       504\n","   macro avg     0.9766    0.9762    0.9762       504\n","weighted avg     0.9766    0.9762    0.9762       504\n","\n","Cropped and Resized\n","Cropped shape: (504, 192, 192, 3)\n","              precision    recall  f1-score   support\n","\n","           0     0.9692    1.0000    0.9844        63\n","           1     0.9688    0.9841    0.9764        63\n","           2     0.9516    0.9365    0.9440        63\n","           3     0.9841    0.9841    0.9841        63\n","           4     1.0000    0.9683    0.9839        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    0.9841    0.9920        63\n","           7     0.9844    1.0000    0.9921        63\n","\n","    accuracy                         0.9821       504\n","   macro avg     0.9823    0.9821    0.9821       504\n","weighted avg     0.9823    0.9821    0.9821       504\n","\n","Original + Cropped Resized\n","              precision    recall  f1-score   support\n","\n","           0     0.9688    0.9841    0.9764        63\n","           1     0.9688    0.9841    0.9764        63\n","           2     0.9355    0.9206    0.9280        63\n","           3     0.9688    0.9841    0.9764        63\n","           4     1.0000    0.9683    0.9839        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.9802       504\n","   macro avg     0.9802    0.9802    0.9801       504\n","weighted avg     0.9802    0.9802    0.9801       504\n","\n","Original + Flip X + Cropped Resized\n","              precision    recall  f1-score   support\n","\n","           0     0.9841    0.9841    0.9841        63\n","           1     0.9688    0.9841    0.9764        63\n","           2     0.9500    0.9048    0.9268        63\n","           3     0.9394    0.9841    0.9612        63\n","           4     1.0000    0.9841    0.9920        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.9802       504\n","   macro avg     0.9803    0.9802    0.9801       504\n","weighted avg     0.9803    0.9802    0.9801       504\n","\n","Test Black and White\n","              precision    recall  f1-score   support\n","\n","           0     0.4667    0.2222    0.3011        63\n","           1     0.0000    0.0000    0.0000        63\n","           2     0.0000    0.0000    0.0000        63\n","           3     0.6486    0.7619    0.7007        63\n","           4     0.2480    1.0000    0.3975        63\n","           5     0.2105    0.0635    0.0976        63\n","           6     0.6184    0.7460    0.6763        63\n","           7     0.6863    0.5556    0.6140        63\n","\n","    accuracy                         0.4187       504\n","   macro avg     0.3598    0.4187    0.3484       504\n","weighted avg     0.3598    0.4187    0.3484       504\n","\n","Test Original + Black and White\n","              precision    recall  f1-score   support\n","\n","           0     0.9821    0.8730    0.9244        63\n","           1     1.0000    0.5714    0.7273        63\n","           2     1.0000    0.6825    0.8113        63\n","           3     0.9167    0.8730    0.8943        63\n","           4     0.5207    1.0000    0.6848        63\n","           5     1.0000    0.9841    0.9920        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.8730       504\n","   macro avg     0.9274    0.8730    0.8793       504\n","weighted avg     0.9274    0.8730    0.8793       504\n","\n","Test Original + Flip X + Flip Y + BW\n","              precision    recall  f1-score   support\n","\n","           0     0.9836    0.9524    0.9677        63\n","           1     0.9841    0.9841    0.9841        63\n","           2     0.9194    0.9048    0.9120        63\n","           3     0.9394    0.9841    0.9612        63\n","           4     1.0000    1.0000    1.0000        63\n","           5     1.0000    1.0000    1.0000        63\n","           6     1.0000    1.0000    1.0000        63\n","           7     1.0000    1.0000    1.0000        63\n","\n","    accuracy                         0.9782       504\n","   macro avg     0.9783    0.9782    0.9781       504\n","weighted avg     0.9783    0.9782    0.9781       504\n","\n","Finished: /content/drive/MyDrive/output/JP30N14-45\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["work_on_keffnet(show_model=False, run_fit=False, test_results=False, calc_f1=True)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"JP30N14 - kEffNet - colorectal - RAM - 4xVal - 4ch - 1000epochs.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}